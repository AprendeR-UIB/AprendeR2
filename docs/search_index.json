[
["index.html", "AprendeR: Parte II Presentación", " AprendeR: Parte II The AprendeR team 2019-03-11 Presentación Esto es una edición preliminar en línea de la 2a parte del libro “AprendeR”. El libro está escrito en R Markdown, usando RStudio como editor de texto y el paquete bookdown para convertir los ficheros markdown en un libro. Este trabajo se publica bajo licencia Atribución-No Comercial-SinDerivadas 4.0 "],
["chap-distr.html", "Lección 1 Distribuciones de probabilidad 1.1 Ejercicios", " Lección 1 Distribuciones de probabilidad R conoce los tipos de distribución de probabilidad más importantes, incluyendo las que mostramos en la tabla siguiente: \\[ \\begin{array}{lll} \\hline \\textbf{Distribución} &amp; {\\textbf{Nombre en R}} &amp; {\\textbf{Parámetros}}\\\\ \\hline \\mbox{Binomial} &amp;{\\texttt{binom}} &amp; \\mbox{tamaño de la muestra $n$, probabilidad $p$}\\\\ \\mbox{Geométrica} &amp; {\\texttt{geom}} &amp; \\mbox{$p$}\\\\ \\mbox{Hipergeométrica} &amp; {\\texttt{hyper}} &amp; \\mbox{tamaño de la población $N$, número poblacional}\\\\[-0.75ex] &amp; &amp; \\mbox{de éxitos $M$, tamaño de la muestra $n$}\\\\ \\mbox{Poisson} &amp; {\\texttt{pois}} &amp; \\mbox{esperanza $\\lambda$}\\\\ \\mbox{Uniforme} &amp; {\\texttt{unif}} &amp; \\mbox{mínimo, máximo}\\\\ \\mbox{Exponencial} &amp; {\\texttt{exp}} &amp; \\lambda\\\\ \\mbox{Normal} &amp; {\\texttt{norm}} &amp; \\mbox{media $\\mu$, desviación típica $\\sigma$}\\\\ \\mbox{Khi cuadrado} &amp; {\\texttt{chisq}} &amp; \\mbox{número de grados de libertad $df$}\\\\ \\mbox{t de Student} &amp; {\\texttt{t}} &amp; \\mbox{número de grados de libertad $df$}\\\\ \\mbox{F de Fisher} &amp; {\\texttt{f}} &amp; \\mbox{los dos números de grados de libertad} \\\\ \\hline \\end{array} \\] Para cada una de estas distribuciones, R sabe calcular cuatro funciones, que se obtienen añadiendo un prefijo al nombre de la distribución: La función de densidad, con el prefijo d. La función de distribución de probabilidad, con el prefijo p; esta función dispone además del parámetro lower.tail que igualado a FALSE calcula la función de distribución de cola superior: la probabilidad de que una variable aleatoria con esta distribución de probabilidad tome un valor estrictamente mayor que uno dado. Los cuantiles, con el prefijo q. Vectores de números aleatorios con esta distribución, con el prefijo r. La función correspondiente se aplica entonces al valor sobre el que queremos calcular la función y a los parámetros de la distribución (en este orden, y los parámetros en el orden en que los damos en la tabla anterior, cuando hay más de uno). Por ejemplo, sea \\(X\\) una variable aleatoria binomial \\(B(20,0.3)\\), es decir, de tamaño \\(n=20\\) y probabilidad \\(p=0.3\\), y sean \\(f_X\\) su función de densidad y \\(F_X\\) su función de distribución. Calculemos algunos valores de funciones asociadas a esta variable aleatoria. \\(f_X(5)=P(X=5)\\): dbinom(5,20,0.3) ## [1] 0.1788631 Comprobémoslo, recordando que si \\(X\\sim B(n,k)\\), entonces \\(P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}\\): choose(20,5)*0.3^5*0.7^15 ## [1] 0.1788631 \\(f_X(8)=P(X=8)\\): dbinom(8,20,0.3) ## [1] 0.1143967 \\(F_X(5)=P(X{\\leqslant}5)\\): pbinom(5,20,0.3) ## [1] 0.4163708 Comprobémoslo, usando que \\(P(X{\\leqslant}5)=\\sum_{k=0}^5 P(X=k)\\): sum(dbinom(0:5,20,0.3)) ## [1] 0.4163708 \\(F_X(8)=P(X{\\leqslant}8)\\): pbinom(8,20,0.3) ## [1] 0.8866685 \\(P(X&gt;8)\\) pbinom(8,20,0.3,lower.tail=FALSE) ## [1] 0.1133315 En efecto: 1-pbinom(8,20,0.3) ## [1] 0.1133315 El cuantil de orden \\(0.5\\) de \\(X\\), o sea, su mediana: el valor \\(x\\) más pequeño tal que \\(P(X{\\leqslant}x){\\geqslant}0.5\\) qbinom(0.5,20,0.3) ## [1] 6 Comprobemos que \\(P(X{\\leqslant}6){\\geqslant}0.5\\) y en cambio \\(P(X{\\leqslant}5)&lt; 0.5\\): pbinom(6,20,0.3) ## [1] 0.6080098 pbinom(5,20,0.3) ## [1] 0.4163708 El cuantil de orden \\(0.25\\) de \\(X\\), es decir, su primer cuartil: qbinom(0.25,20,0.3) ## [1] 5 Un vector aleatorio de 10 valores generado con la variable aleatoria \\(X\\): rbinom(10,20,0.3) ## [1] 8 9 4 7 9 6 7 4 7 9 Dos vectores aleatorios más, de 10 valores cada uno, generados con la variable aleatoria \\(X\\): rbinom(10,20,0.3) ## [1] 4 6 5 5 3 9 7 6 4 7 rbinom(10,20,0.3) ## [1] 7 6 7 5 7 5 4 7 8 7 Del mismo modo, si estamos trabajando con una variable aleatoria \\(Y\\) de Poisson con parámetro \\(\\lambda=5\\): \\(P(Y=8)\\): dpois(8,5) ## [1] 0.06527804 \\(P(Y{\\leqslant}8)\\): ppois(8,5) ## [1] 0.9319064 El cuantil de orden 0.6 de \\(Y\\): qpois(0.6,5) ## [1] 5 Un vector aleatorio de 20 valores generado con la variable aleatoria \\(Y\\): rpois(20,5) ## [1] 9 5 3 7 7 4 6 8 2 8 4 4 5 6 7 11 8 4 3 1 Si no entramos ningún parámetro en las funciones asociadas a la distribución normal, R entiende que se trata de la normal estándar (con media \\(\\mu=0\\) y desviación típica \\(\\sigma=1\\)): por ejemplo, las dos instrucciones siguientes nos dan el valor \\(f_Z(0.3)\\) de la función densidad de una normal estándar \\(Z\\) aplicada a 0.3 (que no es igual a \\(P(Z=0.3)\\)): dnorm(0.3) ## [1] 0.3813878 dnorm(0.3,0,1) ## [1] 0.3813878 Las funciones densidad y distribución de una variable aleatoria se pueden dibujar con la función curve. Así, la función siguiente dibuja la gráfica de la densidad de una variable normal estándard de la Figura 1.1: curve(dnorm(x,0,1.5),-5,5,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;&quot;) Figura 1.1: Función densidad de una variable N(0,1). De manera similar, la función siguiente dibuja la gráfica de la función de distribución de una variable normal estándard de la Figura 1.2: curve(pnorm(x,0,1.5),-5,5,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;&quot;) Figura 1.2: Función distribución de una variable N(0,1). 1.1 Ejercicios Test (1) Sea \\(f\\) la función de densidad de una variable aleatoria normal con \\(\\mu=0.2\\) y \\(\\sigma=1.2\\). Dad el valor de \\(f(0.5)\\) redondeado a 4 cifras decimales. (2) Sea \\(X\\) una variable aleatoria normal con \\(\\mu=0.2\\) y \\(\\sigma=1.2\\). Dad el valor de \\(P(3{\\leqslant}X{\\leqslant}7)\\) redondeado a 4 cifras decimales. (3) Sea \\(X\\) una variable aleatoria \\(B(10,0.2)\\). Dad el valor de \\(P(3{\\leqslant}X{\\leqslant}7)\\) redondeado a 4 cifras decimales. (4) Dad una instrucción que calcule la mediana de una lista de 20 números aleatorios generados con distribución \\(B(10,0.2)\\). No deis el resultado, solo la instrucción. Respuestas al test (1) 0.3222 (Lo hemos calculado con round(dnorm(0.5,0.2,1.2),4)) (2) 0.0098 (Lo hemos calculado con round(pnorm(7,0.2,1.2)-pnorm(3,0.2,1.2),4)) (3) 0.3221 (Lo hemos calculado con round(pbinom(7,10,0.2)-pbinom(2,10,0.2),4). También se obtiene el resultado correcto con round(sum(dbinom(3:7,10,0.2)),4). En cambio, con round(pbinom(7,10,0.2)-pbinom(3,10,0.2),4) no se obtiene el resultado correcto: da 0.1208. Pensad por qué aquí hay que restar pbinom(2,10,0.2) y en la pregunta anterior restábamos pnorm(3,0.2,1.2).) (4) median(rbinom(20,10,0.2)) (También sería correcto median(rbinom(20,size=10,prob=0.2)), pero no es necesario dar los nombres de los parámetros si entráis sus valores en el orden correcto, y por eso no los hemos explicado.) "],
["chap-muestreo.html", "Lección 2 Conceptos básicos de muestreo 2.1 Tipos de muestreo 2.2 Muestreo aleatorio con R 2.3 Guía rápida 2.4 Ejercicios", " Lección 2 Conceptos básicos de muestreo En todo estudio estadístico hemos de distinguir entre población, que es un conjunto de sujetos con una o varias características que podemos medir y deseamos estudiar, y muestra, un subconjunto de una población. Por ejemplo, si quisiéramos estudiar alguna característica de los estudiantes de grado de la UIB, entenderíamos que estos forman la población de interés, y si entonces escogiéramos al azar 10 estudiantes de cada grado, obtendríamos una muestra de esta población. Pero también podríamos considerar los estudiantes de grado de la UIB como una muestra de la población de los estudiantes universitarios españoles: depende del estudio que queramos realizar. Recordad que, cuando disponemos de un conjunto de datos obtenidos midiendo una o varias características sobre los sujetos de una muestra, podemos llevar a cabo dos tipos de análisis estadístico: Exploratorio o descriptivo: su objetivo es resumir, representar y explicar los datos de la muestra. Para llevarlo a cabo, se usan técnicas de estadística descriptiva como las que hemos descrito en lecciones anteriores. Inferencial o confirmatorio: su objetivo es deducir (inferir), a partir de los datos de la muestra, información significativa sobre el total de la población. A menudo esta inferencia pasa por contrastar una hipótesis sobre alguna propiedad de la población. Las técnicas que se usan en los análisis inferenciales forman la estadística inferencial. Por ejemplo, supongamos que hemos tomado una muestra de estudiantes de la UIB y sabemos sus calificaciones en un semestre concreto y sus números de hermanos. En un estudio exploratorio simplemente describiríamos estos datos mediante estadísticos y gráficos, mientras que usaríamos técnicas de estadística inferencial para deducir información sobre la población de todos los estudiantes de la UIB a partir de esta muestra: ¿Cuál estimamos que ha sido la nota media de los estudiantes de la UIB en el semestre en cuestión? La distribución de los números de hermanos en estudiantes de la UIB, ¿es similar a la del conjunto de la población española? ¿Es verdad que los estudiantes de la UIB con más hermanos tienen tendencia a tener mejores notas? Un estudio inferencial suele desglosarse en los pasos siguientes: Establecer la característica que se desea estimar o la hipótesis que se desea contrastar. Determinar la información (los datos) que se necesita para hacerlo. Diseñar un experimento que permita recoger estos datos; este paso incluye: Decidir qué tipo de muestra se va a tomar y su tamaño. Elegir las técnicas adecuadas para realizar las inferencias deseadas a partir de la muestra que se tomará. Tomar una muestra y medir los datos deseados sobre los individuos que la forman. Aplicar las técnicas de inferencia elegidas con el software adecuado. Obtener conclusiones. Si las conclusiones son fiables y suficientes, redactar un informe; en caso contrario, volver a empezar. En la próxima sección nos centraremos en las técnicas de muestreo: los métodos generales para seleccionar muestras representativas de una población que tenemos a nuestra disposición en el tercer paso de la lista anterior. 2.1 Tipos de muestreo Existen muchos tipos de muestreo, cada uno de los cuales proporciona una muestra representativa de la población en algún sentido. A continuación describimos de forma breve algunas de estas técnicas. Muestreo aleatorio con y sin reposición Un muestreo aleatorio consiste en seleccionar una muestra de la población de manera que todas las muestras del mismo tamaño sean equiprobables; es decir, que si fijamos el número de individuos de la muestra, cualquier conjunto de ese número de individuos tenga la misma probabilidad de ser seleccionado. Hay dos tipos básicos de muestreo aleatorio que vale la pena distinguir. Para ilustrarlos, supongamos que disponemos de una urna con 100 bolas numeradas del 1 al 100, de la que queremos extraer una muestra de 15 bolas. La Figura 2.1 representa dicha urna. Figura 2.1: Una urna de 100 bolas Una manera de hacerlo sería repetir 15 veces el proceso de sacar una bola de la urna, anotar su número y devolverla a la urna. El tipo de muestra obtenida de esta manera recibe el nombre de muestra aleatoria con reposición, o simple (una m.a.s., para abreviar). Observad que con este procedimiento una misma bola puede aparecer varias veces en una muestra, y que todos los subconjuntos de 15 bolas “con posibles repeticiones” tienen la misma probabilidad de obtenerse. Un posible resultado serían las bolas azules de la Figura 2.2; la bola azul más oscuro ha sido escogida dos veces en la muestra. Figura 2.2: Una muestra aleatoria simple Otra manera de extraer nuestra muestra sería repetir 15 veces el proceso de sacar una bola de la urna pero ahora sin devolverla. Esto es equivalente a extraer de golpe 15 bolas de la urna. Estas muestras no tienen bolas repetidas, y cualquier selección de 15 bolas diferentes tiene la misma probabilidad de ser la obtenida. En este caso se habla de una muestra aleatoria sin reposición. Un posible resultado serían las bolas azules de la Figura 2.3. Figura 2.3: Una muestra aleatoria sin reposición Cuando el tamaño de la población es muy grande en relación a la muestra, la probabilidad de que haya repeticiones en una muestra aleatoria simple es muy pequeña. Esto nos permite entender en este caso que los muestreos aleatorios con y sin reposición son equivalentes en el sentido siguiente: puesto que si la población es muy, muy grande, un muestreo con reposición daría muy probablemente una muestra con todos sus elementos diferentes, si tomamos directamente la muestra sin reposición podemos aceptar que permitíamos repeticiones, pero que no se han dado, y que por tanto es simple. A modo de ejemplo, vamos a calcular la probabilidad de al menos una repetición en muestras aleatorias simples de diferentes tamaños de una población de 12,000 individuos (aproximadamente, el número de estudiantes de la UIB) y representar estas probabilidades en un gráfico. Recordad que la probabilidad de que los sujetos de una muestra aleatoria simple de tamaño \\(n\\) tomada de una población de \\(N\\) individuos no sean todos diferentes es \\[ 1-\\frac{N(N-1)(N-2)\\cdots (N-n+1)}{N^n}. \\] Esta probabilidad es la que calcula la función f(N,n) del bloque de código siguiente, y su gráfica es la de la Figura 2.4. La curva negra representa las probabilidades deseadas. Hemos añadido al gráfico una línea horizontal que marca la probabilidad 0.01 y que muestra que la probabilidad de alguna repetición en una m.a.s. de 16 o menos estudiantes de la UIB es inferior al 1%: en más de 99 de cada 100 veces que tomemos una m.a.s. de a lo sumo 16 estudiantes, nos saldrán todos diferentes f=function(N,n){1-prod((N:(N-n+1))/N)} prob=sapply(1:200,f,N=12000) plot(1:200,prob,type=&quot;l&quot;,lwd=2,xlab=&quot;n&quot;,ylab=&quot;probabilidad&quot;, main=&quot;&quot;,xaxp=c(0,200,20),yaxp=c(0,1,10)) abline(h=0.01,col=&quot;red&quot;) text(160,0.04,labels=&quot;probabilidad 0.01&quot;,col=&quot;red&quot;,cex=0.7) Figura 2.4: Probabilidad de repetición en una m.a.s. de n estudiantes de la UIB Así, por ejemplo, una muestra aleatoria de 10 estudiantes diferentes de la UIB podría haberse obtenido perfectamente tomando los estudiantes con reposición, porque la probabilidad de alguna repetición en una m.a.s. como esta es muy pequeña: 0.004. En cambio, es difícil de creer que una muestra aleatoria de 200 estudiantes diferentes de la UIB sea simple, porque la probabilidad de alguna repetición en una m.a.s. como esta es grande: 0.811. La mayoría de técnicas de estadística inferencial que se pueden usar para muestras aleatorias simples se pueden considerar igualmente válidas para muestras aleatorias sin reposición si el tamaño de la población es muy grande en relación al de la muestra (por dar una regla, digamos que, al menos, unas 1000 veces mayor). Si el tamaño de la población es relativamente pequeño por comparación a la muestra, algunas de estas técnicas se pueden salvar aplicando correcciones adecuadas para compensar la pequeñez de la población, y otras directamente pierden toda validez. En todo caso, conviene ser consciente de que si queremos tomar una muestra aleatoria con o sin reposición de una población, es necesario disponer de una lista completa de todos sus individuos para poder sortear a quién vamos a seleccionar. Esto no siempre es posible. ¿Alguien tiene la lista completa de, pongamos, todos los diabéticos de España? ¿Que incluya los que no saben que lo son? Por lo tanto, en la vida real no siempre podemos tomar muestras aleatorias en el sentido que hemos explicado. Muestreo sistemático Una manera muy sencilla de obtener una muestra de una población cuando disponemos de una lista ordenada de sus individuos es tomarlos a intervalos constantes: cada quinto individuo, cada décimo individuo. Podemos añadir una componente aleatoria escogiendo al azar el primer individuo que elegimos, y a partir del cual empezamos a contar. Así, por ejemplo, si de una clase de 100 estudiantes quisiéramos escoger una muestra de 10, podríamos elegir un estudiante al azar, y a partir de él, por orden alfabético, elegir el décimo estudiante, el vigésimo, el trigésimo, etc.; si al llegar al final de la lista de clase no hubiéramos completado la muestra, volveríamos al principio de la misma. A esta técnica se la llama muestreo sistemático, aleatorio si además el primer sujeto se escoge de manera aleatoria. Por ejemplo, la Figura 2.5 describe una muestra aleatoria sistemática de 15 bolas de nuestra urna de 100 bolas: hemos empezado a escoger por la bola roja oscura, que ha sido elegida al azar, y a partir de ella hemos tomado 1 de cada 7 bolas, volviendo al principio cuando hemos llegado al final de la lista de bolas Figura 2.5: Una muestra aleatoria sistemática Cuando no disponemos de una lista de toda la población pero sí que tenemos una manera de acceder de manera ordenada a sujetos de la misma (por ejemplo, enfermos que acuden a un hospital), podemos realizar un muestreo sistemático tomando los sujetos a intervalos constantes a medida que los encontramos y hasta completar el tamaño deseado de la muestra. Por ejemplo, para escoger una muestra de 10 estudiantes de la UIB, podríamos escoger cada décimo estudiante que entrase en un edificio del Campus por una puerta concreta hasta llegar a los 10. Cuando el orden de los individuos de la población en la lista es aleatorio, el muestreo sistemático aleatorio es equivalente al muestreo aleatorio sin reposición. Pero en general este no es el caso, y se pueden producir sesgos. Por poner un caso extremo, si una clase de 100 estudiantes estuviera formada por 50 parejas de hermanos y tomáramos una muestra sistemática de 50 estudiantes, eligiéndolos por orden alfabético de los apellidos uno sí, uno no, es seguro que no aparecería ninguna pareja de hermanos en la muestra (porque dos hermanos son siempre consecutivos en la lista, y en nuestra muestra no habría ningún par de sujetos consecutivos). En cambio, la probabilidad de que una muestra aleatoria sin reposición del mismo tamaño contuviera una pareja de hermanos es prácticamente 1; en concreto esta probabilidad sería \\[ \\frac{100\\times 98\\times 96\\times\\cdots\\times 2}{100\\times 99\\times 98\\times\\cdots\\times 51}=\\frac{2^{50}\\cdot 50!^2}{100!}=0.999999999999989. \\] Muestreo aleatorio estratificado Este tipo de muestreo se utiliza cuando la población está clasificada en estratos que son de interés para la propiedad estudiada. En este caso, se toma una muestra aleatoria de cada estrato y se unen en una muestra global. A este proceso se le llama muestreo aleatorio estratificado. Normalmente, se impone que la composición por estratos de la muestra global mantenga las proporciones de la población original; es decir, que el tamaño de la muestra de cada estrato represente el mismo porcentaje del total de la muestra que el estrato correspondiente en la población completa. Por ejemplo, los estratos podrían ser grupos de edad, y entonces la muestra de cada grupo de edad se tomaría proporcional a la fracción que representa dicho grupo de edad en la población total. O podrían ser los sexos anatómicos, y procuraríamos que nuestra muestra estuviera formada por un 50% de hombres y un 50% de mujeres. O, en las Islas Baleares, los estratos podrían ser las islas, de manera que el número de representantes de cada isla en la muestra fuera proporcional a su población relativa dentro del conjunto total de la comunidad autónoma. Por continuar con nuestra urna de 100 bolas, supongamos que contiene 40 bolas de un color y 60 de otro color según muestra la Figura 2.6. Figura 2.6: Nuestra urna ahora tiene 2 estratos Para tomar una muestra aleatoria estratificada de 15 bolas, considerando como estratos los dos colores, tomaríamos una muestra aleatoria de 6 bolas del primer color y una muestra aleatoria de 9 bolas del segundo color. De esta manera, los porcentajes de colores en la muestra serían los mismos que en la urna. La Figura 2.7 describe una muestra obtenida de esta manera. Figura 2.7: Una muestra aleatoria estratificada En todo caso, el muestreo por estratos solo es necesario si esperamos que las características de la propiedad poblacional que queremos estudiar varíen según el estrato. Por ejemplo, si queremos tomar una muestra para estimar la altura media de los españoles adultos y no creemos que la altura de un español adulto dependa de su provincia de origen, no hay ninguna necesidad de esforzarse en tomar una muestra de cada provincia de manera que todas las provincias estén representadas proporcionalmente en la muestra. Muestreo por conglomerados El proceso de obtener y estudiar una muestra aleatoria en algunos casos es caro o difícil, incluso aunque dispongamos de la lista completa de la población. Imaginemos que quisiéramos estudiar los hábitos de alimentación de los estudiantes de Primaria de Baleares. Para ello, previo permiso de la autoridad competente, tendríamos que seleccionar una muestra representativa de los escolares de Baleares. Seguramente podríamos disponer de su lista completa y por lo tanto podríamos tomar una muestra aleatoria, pero entonces acceder a las niñas y niños que la formasen seguramente significaría contactar con unos pocos alumnos de muchos centros de primaria, lo que volvería el proceso lento y costoso. Y eso si la Conselleria d’Educació nos facilitase la lista completa de alumnos. Una alternativa posible sería, en vez de extraer una muestra aleatoria de todos los estudiantes de Primaria, escoger primero al azar unas pocas aulas de primaria de colegios de las Baleares, a las que llamamos en este contexto conglomerados (clusters), y formar entonces nuestra muestra con todos los alumnos de estas aulas. Y es que es mucho más sencillo poseer la lista completa de estudiantes de unas pocas aulas que conseguir la lista completa de todos los estudiantes de todos los colegios, y mucho más barato ir a unos pocos colegios concretos que ir a todos los colegios de las Islas a entrevistar a unos pocos estudiantes en cada centro. Por poner otro ejemplo, efectuamos también un muestreo por conglomerados cuando para medir algunas características de los ejemplares de una planta en un bosque concreto, cuadriculamos la superficie del bosque, escogemos una muestra aleatoria de sectores de la cuadrícula (serían los conglomerados de este ejemplo) y estudiamos las plantas de interés contenidas en los sectores elegidas. Volviendo de nuevo a nuestra urna, supongamos que sus 100 bolas se agrupan en 20 conglomerados de 5 bolas cada uno según las franjas verticales de la Figura 2.8 (donde mantenemos la clasificación en dos colores para poder comparar el resultado del muestreo por conglomerados con el estratificado). Figura 2.8: Nuestra urna ahora tiene 2 estratos y 20 conglomerados Para obtener una muestra aleatoria por conglomerados de tamaño 15, escogeríamos al azar 3 conglomerados y la muestra estaría formada por sus bolas. La Figura 2.9 describe una muestra obtenida de esta manera: los conglomerados escogidos están marcados en azul. Figura 2.9: Una muestra aleatoria por conglomerados Observad la diferencia entre el muestreo estratificado y el muestreo por conglomerados: En una muestra estratificada se escoge una muestra aleatoria de cada estrato existente. En una muestra por conglomerados se escogen algunos conglomerados al azar y se incluye en la muestra todos sus elementos. Muestreos no aleatorios Cuando la selección de la muestra no es aleatoria, se habla de muestreo no aleatorio. En realidad es el tipo más frecuente de muestreo porque casi siempre nos tenemos que conformar con los sujetos disponibles. Por ejemplo, en la UIB, para estimar la opinión que de un profesor tienen los alumnos de una clase, se consulta solo a los estudiantes que voluntariamente rellenan la encuesta de opinión, que de ninguna manera forman una muestra aleatoria: el perfil del estudiante que contesta voluntariamente una encuesta de este tipo está muy definido y no viene determinado por el azar. En este caso se trataría de una muestra autoseleccionada. Otro tipo de muestras no aleatorias son las oportunistas. Este es el caso, por ejemplo, si para estimar la opinión que de un profesor tienen los alumnos de una asignatura se visita un día la clase y se pasa la encuesta a los estudiantes que ese día asistieron a clase. De nuevo, puede que los alumnos presentes no sean representativos del alumnado de la asignatura (pueden ser los más aplicados, o los que no tienen la gripe, o a los que la asignatura no les coincide con otra). Veamos otros ejemplos de muestreo oportunista. Supongamos que queremos estudiar una característica de los animales de una determinada especie en un hábitat, y la medimos en los animales que capturamos. Estos ejemplares no tienen por qué ser representativos de la población: a lo mejor son los menos espabilados. O imaginad que tenéis una bolsa con bolas de diferentes tamaños. Si las removéis bien, las pequeñas tenderán a ir a parar al fondo y las grandes a quedar en la parte superior. Por lo tanto, si tomáis una muestra de la capa superior (que será lo más cómodo), no será representativa del total de la bolsa. La Figura 2.10 describe una muestra oportunista de nuestra urna: sus 15 primeras bolas. Aunque toda muestra de un mismo tamaño tiene la misma probabilidad de obtenerse por medio de un muestreo aleatorio sin reposición, es difícil de creer que esta muestra sea aleatoria; basta que calculéis cuál es la probabilidad de que en una muestra aleatoria de 15 bolas de nuestra urna todas tengan el mismo color: \\[ \\frac{40\\times 39\\times \\cdots\\times 26+60\\times 59\\times \\cdots\\times 46}{100\\times 99\\times \\cdots\\times 86}=0.00021 \\] Figura 2.10: Una muestra oportunista Las técnicas de estadística inferencial no se pueden aplicar a muestras no aleatorias, pero normalmente son las únicas que podemos conseguir. En este caso, lo que se suele hacer es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, es representativa de la población y podría haber sido aleatoria. Por ejemplo, la muestra oportunista anterior de nuestra urna no es de ninguna manera representativa de su contenido por lo que refiere al color de las bolas. Muestreo polietápico En el ejemplo de los estudiantes de Primaria, la muestra final de estudiantes ha estado formada por todos los individuos de las aulas elegidas. Otra opción podría haber sido, tras seleccionar la muestra aleatoria de conglomerados, tomar de alguna manera una muestra aleatoria de cada uno de ellos. Por ejemplo, algunos estudios poblacionales a nivel estatal se realizan solamente en algunas provincias escogidas aleatoriamente, en las que luego se encuesta una muestra aleatoria de habitantes. Este sería un ejemplo de muestreo polietápico, en el que la muestra no se obtiene en un solo paso, sino mediante diversas elecciones sucesivas. La Figura 2.11 muestra un ejemplo sencillo de muestreo polietápico de nuestra urna: hemos elegido al azar 5 conglomerados (marcados en azul) y de cada uno de ellos hemos elegido 3 bolas al azar sin reposición. Figura 2.11: Una muestra polietápica Otro ejemplo enrevesado (pero real) de muestreo polietápico sería, para elegir una muestra de adolescentes de una ciudad grande, escoger en primer lugar 4 secciones censales al azar; a continuación, escoger al azar 10 manzanas de cada una de estas secciones censales y una esquina de cada manzana; finalmente, recorrer cada manzana en sentido horario a partir de la esquina seleccionada y visitar un portal de cada tres, entrevistando todos los habitantes de 13 a 19 años en las casas o fincas visitadas. En este proceso, hemos realizado tres muestreos aleatorios sin reposición (de secciones censales, de manzanas y de esquinas) y un muestreo sistemático (los portales). Si además los adolescentes que estudiamos al final no son todos los que viven en los portales seleccionados sino solo los que encontramos en casa el día que los visitamos, este muestreo oportunista significaría un cuarto paso en la formación de la muestra. Existen otros tipos de muestreo, solo hemos explicado los más comunes. En cualquier caso, lo importante es recordar que el estudio estadístico que se realice a posteriori deberá ser diferente según el tipo de muestreo usado. Por ejemplo, no se pueden usar las mismas técnicas para analizar una muestra aleatoria simple que una muestra por conglomerados. 2.2 Muestreo aleatorio con R En este curso estudiaremos las propiedades de las diferentes técnicas de estimación solamente para el caso de muestreo aleatorio simple, es decir, al azar y con reposición, o al azar sin reposición si la población es muy, muy grande en comparación con la muestra. Recordemos que un método de selección al azar de muestras de tamaño \\(n\\) (es decir, formadas por \\(n\\) individuos) de una cierta población produce muestras aleatorias simples (m.a.s.) cuando todas las muestras posibles de \\(n\\) individuos (con posibles repeticiones) tienen la misma probabilidad de ser elegidas. El tener una m.a.s. de una población junto con un tamaño muestral adecuado \\(n\\) nos asegurará que la estimación que hagamos sea muy probablemente correcta. La manera más sencilla de llevar a cabo un muestreo aleatorio simple es numerar todos los individuos de una población y sortearlos eligiendo números de uno en uno como si se tratase de una lotería, por ejemplo con algún generador de números aleatorios. Esto se puede llevar a cabo fácilmente con R. R dispone de un generador de muestras aleatorias de un vector. La función básica es sample(x, n, replace=...) donde: x es un vector o un número natural \\(x\\), en cuyo caso R entiende que representa el vector 1,2,…,\\(x\\); n es el tamaño de la muestra que deseamos extraer; el parámetro replace puede igualarse a TRUE, y será una muestra aleatoria con reposición, es decir, simple, o a FALSE, y será una muestra aleatoria sin reposición. Este último es su valor por defecto, por lo que no es necesario especificarlo si se quiere obtener una muestra sin reposición. Los dos primeros parámetros han de entrarse en este orden o igualados a los parámetros x y size, respectivamente. Así, por ejemplo, para obtener una m.a.s. de 15 números entre 1 y 100, podemos entrar: sample(100,15,replace=TRUE) ## [1] 47 42 86 16 53 41 53 41 44 20 56 66 72 55 17 Naturalmente, y como ya nos encontramos en la Lección 1 cuando generábamos vectores aleatorios con una distribución dada, cada ejecución de sample con los mismos parámetros puede dar lugar a muestras diferentes, y todas ellas tienen la misma probabilidad de aparecer: sample(100,15,replace=TRUE) ## [1] 83 8 16 1 33 24 25 96 13 29 73 74 14 99 24 sample(100,15,replace=TRUE) ## [1] 74 63 2 54 24 54 89 35 64 51 67 68 11 97 63 sample(100,15,replace=TRUE) ## [1] 58 43 68 6 20 6 55 77 44 43 88 6 96 29 53 Veamos cómo extraer una m.a.s de una tabla de datos. Recordemos el data frame iris, que recoge medidas de pétalos y sépalos de 150 flores de tres especies de iris. str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Si queremos extraer una m.a.s. de 15 ejemplares (filas) de esta tabla de datos, podemos generar con sample una m.a.s. de índices de filas de la tabla (recordad que dim aplicado a un dataframe nos da un vector con sus dimensiones, es decir, sus números de filas y de columnas, en este orden; por lo tanto, dim(iris)[1] es el número de filas de iris): x=sample(dim(iris)[1],15,replace=TRUE) y a continuación crear un data frame que contenga solo estas filas: muestra_iris=iris[x,] muestra_iris ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 10 4.9 3.1 1.5 0.1 setosa ## 127 6.2 2.8 4.8 1.8 virginica ## 62 5.9 3.0 4.2 1.5 versicolor ## 73 6.3 2.5 4.9 1.5 versicolor ## 99 5.1 2.5 3.0 1.1 versicolor ## 140 6.9 3.1 5.4 2.1 virginica ## 12 4.8 3.4 1.6 0.2 setosa ## 26 5.0 3.0 1.6 0.2 setosa ## 139 6.0 3.0 4.8 1.8 virginica ## 30 4.7 3.2 1.6 0.2 setosa ## 119 7.7 2.6 6.9 2.3 virginica ## 50 5.0 3.3 1.4 0.2 setosa ## 97 5.7 2.9 4.2 1.3 versicolor ## 93 5.8 2.6 4.0 1.2 versicolor ## 111 6.5 3.2 5.1 2.0 virginica Si solo quisiéramos una muestra aleatoria de longitudes de pétalos, podríamos aplicar directamente la función sample al vector correspondiente: muestra_long_pet=sample(iris$Petal.Length,15,replace=TRUE) muestra_long_pet ## [1] 1.6 5.5 6.1 4.4 4.5 6.7 4.4 5.7 5.9 4.0 4.4 4.0 5.5 3.5 6.1 El hecho de que funciones como sample o los generadores de vectores aleatorios con una cierta distribución de probabilidad fijada, como rnorm o rbinom, produzcan… pues eso, vectores aleatorios, puede tener inconvenientes a la hora de reproducir una simulación. R permite “fijar” el resultado de una función aleatoria con la instrucción set.seed. Sin entrar en detalles sobre cómo funcionan, los diferentes algoritmos que usa R para generar números aleatorios usan una semilla de aleatoriedad, que se modifica después de la ejecución del algoritmo, y por eso cada vez dan un resultado distinto. Pero, para una semilla fija, el algoritmo da el mismo resultado siempre. Lo que hace la función set.seed es igualar esta semilla al valor que le entramos. Si tras aplicar esta función a un número concreto ejecutamos una instrucción que genere un vector aleatorio de una longitud fija con una distribución fija, el resultado será siempre el mismo. Veamos un ejemplo de su efecto, generando muestras aleatorias simples de 10 longitudes de pétalos de flores iris con diferentes semillas de aleatoriedad: sample(iris$Petal.Length,10,replace=TRUE) ## [1] 5.1 5.7 4.1 1.5 1.4 4.3 1.4 4.1 1.7 4.0 set.seed(20) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.4 5.3 1.3 3.5 5.7 5.2 1.1 1.5 1.4 4.5 set.seed(20) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.4 5.3 1.3 3.5 5.7 5.2 1.1 1.5 1.4 4.5 sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.3 5.0 1.4 5.3 1.4 4.1 1.5 1.3 1.6 6.7 set.seed(10) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 4.8 1.6 3.6 5.6 1.4 1.4 1.3 1.3 4.0 3.6 set.seed(10) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 4.8 1.6 3.6 5.6 1.4 1.4 1.3 1.3 4.0 3.6 Ejecutado inmediatamente después de set.seed(20), sample(iris$Petal.Length,10,replace=TRUE) siempre da lo mismo. Y ejecutado después de set.seed(10), sample(iris$Petal.Length,10,replace=TRUE) vuelve a dar siempre lo mismo, pero diferente de con set.seed(20). La función set.seed no solo fija el resultado de la primera instrucción tras ella que genere un vector aleatorio, sino que, como fija la semilla de aleatoriedad y las funciones posteriores la modificarán de manera determinista, también fija los resultados de todas las instrucciones siguientes que generen vectores aleatorios. set.seed(100) sample(10,3) ## [1] 4 3 5 sample(10,3) ## [1] 1 5 4 sample(10,3) ## [1] 9 4 5 set.seed(100) sample(10,3) ## [1] 4 3 5 sample(10,3) ## [1] 1 5 4 sample(10,3) ## [1] 9 4 5 Si queréis volver a “reiniciar” la semilla de la aleatoriedad tras haber usado un set.seed, podéis usar set.seed(NULL). set.seed(100) sample(10,3) ## [1] 4 3 5 set.seed(NULL) sample(10,3) ## [1] 2 6 9 set.seed(100) sample(10,3) ## [1] 4 3 5 set.seed(NULL) sample(10,3) ## [1] 5 8 6 A veces querremos tomar diversas muestras aleatorias de una misma población y calcular algo sobre ellas. Para hacerlo podemos usar la función replicate. La sintaxis básica es replicate(n, instrucción) donde n es el número de repeticiones de la instrucción. Por ejemplo, para tomar 10 muestras aleatorias simples de 15 longitudes de pétalos de flores iris, podemos hacer: muestras=replicate(10, sample(iris$Petal.Length,15,replace=TRUE)) muestras ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 4.0 5.5 5.6 4.6 3.9 1.5 4.5 4.5 1.5 5.2 ## [2,] 1.4 6.9 4.4 4.2 4.0 1.4 5.8 5.1 1.4 4.1 ## [3,] 4.8 5.7 1.2 1.5 1.3 1.3 4.3 5.6 4.0 1.5 ## [4,] 5.8 1.1 1.7 1.7 1.5 1.5 1.0 1.5 4.5 5.7 ## [5,] 1.5 3.9 3.9 6.7 4.0 5.6 4.5 1.6 1.6 4.4 ## [6,] 1.2 4.8 1.4 5.5 4.2 3.7 3.9 5.0 5.6 4.2 ## [7,] 6.7 3.7 4.4 4.8 1.5 3.9 5.6 1.6 6.0 4.9 ## [8,] 6.0 4.2 4.5 1.7 1.5 1.3 3.9 4.9 5.2 5.6 ## [9,] 6.9 4.0 5.6 4.7 1.5 1.4 4.1 1.3 5.1 1.5 ## [10,] 1.3 1.6 4.1 4.5 1.3 1.4 1.6 4.9 1.4 4.9 ## [11,] 1.4 4.3 5.6 5.5 5.7 1.4 1.4 4.5 4.1 1.3 ## [12,] 1.7 5.3 4.8 1.5 5.1 1.5 1.4 3.6 1.5 5.8 ## [13,] 1.7 4.6 4.9 5.6 1.3 5.0 1.4 5.5 3.7 3.3 ## [14,] 5.4 3.5 1.3 1.7 1.4 5.8 1.4 5.5 5.1 4.3 ## [15,] 1.3 4.4 4.9 4.9 5.8 4.5 1.9 1.3 4.7 6.1 Observad que R ha organizado los 10 vectores generados con el replicate como columnas de una matriz. Si solo nos hubiera interesado calcular las medias, redondeadas a 2 cifras decimales, de 10 muestras aleatorias simples de 15 longitudes de pétalos de flores iris, podríamos haber hecho medias=replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) medias ## [1] 3.55 3.11 3.77 4.00 4.04 3.71 3.53 4.08 3.15 4.31 En este caso, como el resultado de la instrucción que iteramos es un solo número, los resultados del replicate forman un vector. ¿Y si quisiéramos la media y la desviación típica muestral de 10 muestras de estas? No podemos usar sin más dos replicate, como en replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 3.95 4.08 3.46 4.22 4.01 5.05 4.13 3.51 5.13 4.15 replicate(10,round(sd(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 1.58 1.75 1.70 1.60 2.11 1.59 2.19 2.11 2.03 1.73 porque es muy probable que el conjunto de muestras de las que hemos calculado la media en el primer replicate sea diferente del conjunto de muestras de las que hemos calculado la desviación típica en el segundo replicate. Lo más adecuado es definir una función que calcule un vector con estos dos valores, y luego usarla dentro de un único replicate. info=function(x){round(c(mean(x),sd(x)),2)} info_lp=replicate(10,info(sample(iris$Petal.Length,15,replace=TRUE))) info_lp ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 3.63 3.49 3.70 3.40 3.48 4.53 3.46 3.26 3.96 2.69 ## [2,] 1.68 1.86 1.71 1.47 1.76 1.45 1.97 1.90 1.75 1.59 En este último caso, R ha organizado la información obtenida como columnas de una matriz: la primera fila son las medias y la segunda las desviaciones típicas. Naturalmente, la función set.seed permite “fijar” el resultado de un replicate que incluya la generación de números aleatorios: set.seed(1000) replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 3.63 3.18 4.05 4.59 4.13 2.51 3.61 3.31 3.63 3.96 set.seed(1000) replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 3.63 3.18 4.05 4.59 4.13 2.51 3.61 3.31 3.63 3.96 Un último comentario sobre la función sample. Aunque aquí la vamos a usar principalmente para tomar muestras aleatorias en las que todos los sujetos de la población tengan la misma probabilidad de ser escogidos, también podemos emplearla para obtener muestras en las que diferentes sujetos puedan tener probabilidades diferentes de salir. Estas probabilidades se especifican con el parámetro prob igualado a un vector de probabilidades (o de pesos proporcionales a probabilidades) de la misma longitud que el vector x al cual apliquemos sample. De esta manera, la primera entrada de prob representa la probabilidad del primer elemento de x, la segunda entrada de prob representa la probabilidad del segundo elemento de x, etc. Por ejemplo, si queremos tomar una muestra aleatoria de tamaño 10 del vector \\((1,2,3)\\) de manera que cada elemento de este vector tenga probabilidad de ser escogido proporcional a su valor (es decir, el 2 tiene el doble de probabilidades de aparecer en la muestra que el 1, y el 3, el triple), podemos usar: sample(1:3,10,prob=1:3) ## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when &#39;replace = FALSE&#39; ¡Ups! Para tomar una muestra de 10 elementos de una población de 3 sujetos, habrá que permitir repeticiones sample(1:3,10,replace=TRUE,prob=1:3) ## [1] 3 2 2 2 1 3 2 2 2 1 Para terminar esta lección, damos una función sencilla para efectuar muestreos sistemáticos aleatorios. El objetivo es, dado un vector de longitud \\(N\\), obtener una muestra de tamaño \\(n\\). Lo que haremos será tomar el cociente por exceso \\(k=\\lceil N/n\\rceil\\) de \\(N\\) entre \\(n\\) para determinar el período con el que tenemos que tomar los elementos de manera que todos los elementos puedan ser escogidos. A continuación elegimos al azar un elemento del vector con sample y a partir de él generamos una progresión aritmética de \\(n\\) elementos y paso \\(k\\), volviendo al inicio del vector si llegamos al final sin haber completado la muestra (lo que especificamos tomando los valores de la progresión aritmética módulo \\(N\\)). sist.sample=function(N,n){ k=ceiling(N/n) x0=sample(N,1) seq(x0,length.out=n,by=k)%%N } Por ejemplo, una muestra sistemática de 10 flores iris se podría obtener de la manera siguiente: x=sist.sample(dim(iris)[1],10) #Los índices de la muestra sistemática muestra_sist_iris=iris[x,] #La muestra de la tabla iris muestra_sist_iris ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 132 7.9 3.8 6.4 2.0 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 12 4.8 3.4 1.6 0.2 setosa ## 27 5.0 3.4 1.6 0.4 setosa ## 42 4.5 2.3 1.3 0.3 setosa ## 57 6.3 3.3 4.7 1.6 versicolor ## 72 6.1 2.8 4.0 1.3 versicolor ## 87 6.7 3.1 4.7 1.5 versicolor ## 102 5.8 2.7 5.1 1.9 virginica ## 117 6.5 3.0 5.5 1.8 virginica Como 150/10=15, podemos observar que los índices avanzan de 15 en 15 a partir del que ha sido escogido al azar en primer lugar. 2.3 Guía rápida sample(x, n) genera una muestra aleatoria de tamaño n del vector x. Si x es un número natural \\(x\\), representa el vector 1,2,…,\\(x\\). Dispone de los dos parámetros siguientes: replace, que igualado a TRUE produce muestras con reposición e igualado a FALSE (su valor por defecto) produce muestras sin reposición. prob, que permite especificar las probabilidades de aparición de los diferentes elementos de x (por defecto, son todas la misma). set.seed permite fijar la semilla de aleatoriedad. replicate(n,expresión) evalúa n veces la expresión, y organiza los resultados como las columnas de una matriz (o un vector, si el resultado de cada expresión es unidimensional). 2.4 Ejercicios Test (1) Queremos escoger 100 estudiantes de grado de la UIB para preguntarles cuántas horas semanales estudian. Como creemos que el tipo de estudio cursado influye en este dato, clasificamos los estudiantes según el centro (facultad o escuela) en el que están matriculados, y tomaremos una muestra al azar de cada centro, por sorteo a partir de la lista de todos los matriculados en ese centro y de manera que el tamaño de la muestra de cada centro sea proporcional al número de matriculados en el mismo. ¿De qué tipo de muestreo se tratará? Muestreo aleatorio simple Muestreo aleatorio estratificado Muestreo aleatorio sin reposición Muestreo aleatorio por conglomerados Muestreo aleatorio sistemático Ninguno de los anteriores (2) Con una sola instrucción, calculad la media de una muestra aleatoria sin reposición de 15 elementos escogidos de un vector numérico llamado \\(X\\). (3) Con una sola instrucción, extraed un subdataframe del dataframe iris formado por una muestra aleatoria sin reposición de 40 filas, y llamadlo muestra. Y antes de contestar, comprobad que funciona. (4) Con una sola instrucción, calculad un vector formado por las medias de 100 muestras aleatorias sin reposición de 20 elementos cada una escogidos de un vector numérico llamado \\(X\\) y llamadlo medias. Respuestas al test (1) b (2) mean(sample(X,15)) (También sería correcto sum(sample(X,15))/15. Y en ambos casos también sería correcto añadiendo dentro de la función sample el parámetro replace=FALSE, que hemos omitido porque es el valor por defecto de replace.) (3) muestra=iris[sample(dim(iris)[1],40),] (También sería correcto consultar antes el número de filas con str o tail, ver que son 150, y responder muestra=iris[sample(150,40),]. Hay otras respuestas correctas, no las damos para no liaros. Además, y como antes, también sería correcto añadir replace=FALSE.) (4) medias=replicate(100,mean(sample(X,20))) (¿Ya os hemos dicho que también sería correcto con replace=FALSE?) "],
["chap-estimacion.html", "Lección 3 Estimación puntual 3.1 Estimación máximo verosímil 3.2 Guía rápida 3.3 Ejercicios", " Lección 3 Estimación puntual En un estudio inferencial, una vez tomada la muestra y obtenidos los datos sobre sus miembros, el siguiente paso es inferir, es decir, deducir información sobre la población a partir de estos datos. Dicha información se puede deducir de dos formas: Suponiendo que conocemos el modelo al que se ajusta la población: es decir, suponiendo que conocemos el tipo de distribución de la variable aleatoria que modela la característica de la población en la que estamos interesados, pero desconocemos uno o varios parámetros de los que depende dicha distribución (observad que si lo sabemos todo sobre esta distribución, ya no hace falta tomar muestras para inferir algo sobre ella). Así, podemos saber (o suponer) que las longitudes de los ejemplares adultos de una cierta especie se distribuyen según una variable aleatoria normal, pero desconocer sus parámetros \\(\\mu\\) (media) y \\(\\sigma\\) (desviación típica), y usar este conocimiento para inferir información sobre dichas longitudes a partir de las de una muestra: por ejemplo, para estimar con un cierto margen de error su longitud media. Si estamos en este caso, hablaremos de estimación paramétrica. Suponiendo que desconocemos qué tipo de distribución tiene la variable aleatoria que modela la característica que nos interesa (aunque a veces necesitaremos saber algo de esta distribución; por ejemplo, si es simétrica o no). En este caso, hablaremos de estimación no paramétrica. En ambos casos, existen tres vías para obtener información sobre los parámetros de la distribución (conocida o desconocida) de la variable aleatoria que nos interesa: Estimación puntual. Se trata de obtener expresiones matemáticas, llamadas estimadores puntuales, que aplicadas a los valores de una muestra nos dan una aproximación (el término exacto es una estimación) del valor de dicho parámetro para la población. A modo de ejemplo, la media aritmética de los datos \\(x_1,\\ldots,x_n\\) de una muestra aleatoria, \\[ \\overline{x}=\\frac{x_1+\\cdots +x_n}{n}, \\] es un estimador del valor medio (valor esperado, esperanza) de la variable aleatoria de la que hemos extraído la muestra. Estimación por intervalos de confianza. Se trata de obtener intervalos que contengan con probabilidad alta el parámetro objeto de estudio. Trataremos este tema en la Lección 4. Contraste de hipótesis. Grosso modo, se establecen dos hipótesis opuestas sobre el parámetro o, más en general, sobre la distribución de la variable aleatoria, y se contrastan para intentar decidir cuál es la verdadera. Los estudiaremos en próximas lecciones. En esta lección hablaremos de la estimación puntual. Para empezar, es obvio que no toda fórmula matemática sirve para estimar de manera sensata el valor de un parámetro. Por ejemplo, si queréis estimar la media de las alturas de los habitantes de una población y disponéis de una muestra aleatoria de las mismas, no tomáis la raíz cuadrada de la altura máxima en la muestra como estimación de la altura media de la población, ¿verdad? Lo que habéis hecho toda la vida, y seguiréis haciendo en este curso, ha sido calcular la media de las alturas en la muestra y dar ese valor como estimación de la altura media poblacional. Y es lo correcto, porque la media muestral es siempre un estimador insesgado de la media poblacional y muy a menudo es además su estimador máximo verosímil, Veamos qué significan estas propiedades. Insesgado: Los valores de un estimador sobre muestras aleatorias de una población forman una variable aleatoria con una distribución de probabilidad propia, llamada genéricamente muestral. Decimos entonces que un estimador es insesgado cuando su valor esperado coincide con el valor del parámetro poblacional que se quiere estimar. Por ejemplo, si se toman muestras aleatorias con o sin reposición, la media muestral es siempre un estimador insesgado del valor medio poblacional: su valor esperado es el valor medio poblacional. Máximo verosímil: Cada muestra aleatoria de una población tiene una probabilidad de obtenerse que no solo depende de la muestra, sino también de la distribución de probabilidad de la variable aleatoria poblacional. Si la distribución poblacional es de un tipo concreto (Bernoulli, normal, …), esta probabilidad depende de sus parámetros. Decimos entonces que un estimador es máximo verosímil cuando el resultado que da sobre cada muestra aleatoria es el valor del parámetro poblacional que maximiza la probabilidad de obtenerla. Por ejemplo, si lanzamos una moneda al aire \\(n\\) veces y calculamos la proporción de veces que obtenemos cara, esa proporción muestral \\(\\widehat{p}\\) es el estimador máximo verosímil de la probabilidad \\(p\\) de obtener cara con esa moneda. Esto quiere decir que, de entre todas las distribuciones binomiales \\(B(n,p)\\) que pueden modelar el número de caras que obtenemos al lanzar \\(n\\) veces nuestra moneda, aquella que asigna mayor probabilidad al número de caras que hemos obtenido es la que tiene como parámetro \\(p\\) la frecuencia relativa de caras \\(\\widehat{p}\\) que hemos observado. Para algunas distribuciones, el método de estimación por máxima verosimilitud de sus parámetros da lugar a fórmulas cerradas más o menos sencillas, pero en otros casos nos tenemos que conformar con un valor aproximado obtenido mediante algún método numérico. 3.1 Estimación máximo verosímil A continuación recordamos una lista de los estimadores máximo verosímiles de los parámetros de las distribuciones más comunes a partir de una muestra aleatoria simple: Para la familia Bernoulli, el estimador máximo verosímil del parámetro \\(p\\) es la proporción muestral de éxitos \\(\\widehat{p}\\). Este estimador es además insesgado. Para la familia Poisson, el estimador máximo verosímil del parámetro \\(\\lambda\\) es la media muestral \\(\\overline{X}\\). Este estimador es de nuevo insesgado. Para la familia geométrica, el estimador máximo verosímil del parámetro \\(p\\) es \\({1}/{\\overline{X}}\\). Este estimador es sesgado. Para la familia exponencial, el estimador máximo verosímil del parámetro \\(\\lambda\\) también es \\({1}/{\\overline{X}}\\). Este estimador también es sesgado. Para la familia normal, los estimadores máximo verosímiles de la media \\(\\mu\\), la desviación típica \\(\\sigma\\) y la varianza \\(\\sigma^2\\) son, respectivamente, la media muestral \\(\\overline{X}\\), la desviación típica “verdadera” \\(S_X\\) y la varianza “verdadera” \\(S_X^2\\). Además, \\(\\overline{X}\\) es un estimador insesgado de \\(\\mu\\). La varianza verdadera \\(S_X^2\\) no es un estimador insesgado de \\(\\sigma^2\\), pero sí que lo es la varianza muestral \\(\\widetilde{S}^2\\). Y ninguna de las dos desviaciones típicas, ni la “verdadera” \\(S_X\\) ni la muestral \\(\\widetilde{S}_X\\), es un estimador insesgado de \\(\\sigma\\); si necesitáis un estimador insesgado de la desviación típica de una variable aleatoria normal a partir de una muestra aleatoria simple, lo podéis encontrar en la correspondiente entrada de la Wikipedia. No obstante, el beneficio de usar este estimador insesgado no suele compensar lo complicado de su cálculo. Cuando se estima algún parámetro de una distribución a partir de una muestra, es conveniente aportar el error típico, o estándar, como medida de la finura de la estimación. Recordemos que el error típico de un estimador es la desviación típica de su distribución muestral, y que el error típico de una estimación a partir de una muestra es la estimación del error típico del estimador usando dicha muestra. Veamos un ejemplo sencillo. Supongamos que tenemos una muestra aleatoria simple de tamaño \\(n\\) de una variable \\(X\\) que sigue una distribución Bernoulli de probabilidad poblacional \\(p\\) desconocida que queremos estimar. Por ejemplo, puede ser que tengamos una moneda posiblemente trucada, la hayamos lanzado 100 veces al aire y hayamos anotado los resultados (1, cara, 0, cruz), y a partir de este experimento queramos estimar la probabilidad de sacar cara con esta moneda. O que hayamos anotado para 100 individuos de una población elegidos al azar si tienen o no una determinada enfermedad (1 significa que sí, 0 que no) y a partir de esta muestra deseemos estimar la prevalencia de la enfermedad en la población, es decir, la proporción real de enfermos, que coincide con la probabilidad de que un individuo elegido al azar tenga dicha enfermedad. Tomemos, para fijar ideas, la siguiente muestra de tamaño 100: x=c(0,1,1,1,0,0,0,0,0,0,0,0,1,1,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,1,0,1,0,0,0, 0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0, 1,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0) En este caso, podemos estimar \\(p\\) mediante la proporción muestral de éxitos \\(\\widehat{p}\\), que coincide con la media muestral. El error típico de este estimador es \\(\\sqrt{p(1-p)/n}\\), y el error típico de una estimación concreta es \\(\\sqrt{\\widehat{p}(1-\\widehat{p})/n}\\). Por lo tanto, a mano podemos estimar \\(p\\) y calcular el error típico de dicha estimación de la manera siguiente: n=length(x) #Tamaño de la muestra estim.p=mean(x) #Proporción muestral estim.p ## [1] 0.22 error.tip.p=sqrt(estim.p*(1-estim.p)/n) #Error típico de la estimación error.tip.p ## [1] 0.04142463 De esta manera, estimamos que \\(p\\)=0.22 con un error típico de 0.04. Con R podemos estimar un parámetro de una distribución por el método de máxima verosimilitud a partir de una muestra y además obtener el error típico de dicha estimación usando la función fitdistr del paquete MASS. Esta función calcula los estimadores máximo verosímiles de los parámetros de la mayoría de las familias de distribuciones disponibles en R. Su sintaxis básica es fitdistr(x, densfun=..., start=...) donde x es la muestra, un vector numérico. El valor de densfun ha de ser el nombre de la familia de distribuciones; se tiene que entrar entre comillas y puede tomar, entre otros, los valores siguientes: &quot;chi-squared&quot;, &quot;exponential&quot;, &quot;f&quot;, &quot;geometric&quot;, &quot;lognormal&quot;, &quot;normal&quot; y &quot;poisson&quot;. La lista de distribuciones a las que se puede aplicar, que podéis consultar en la Ayuda de la función, no incluye la Bernoulli ni la binomial. Si fitdistr no dispone de una fórmula cerrada para el estimador máximo verosímil de algún parámetro, usa un algoritmo numérico para aproximarlo que requiere de un valor inicial para arrancar. Este valor (o valores) se puede especificar igualando el parámetro start a una list con cada parámetro a estimar igualado a un valor inicial. Para algunas distribuciones, como la &quot;t&quot;, fitdistr sabe tomar valores iniciales razonables, y no es necesario especificar el parámetro start. Pero para otras distribuciones, como por ejemplo la &quot;chi-squared&quot;, es obligatorio especificarlo. Para las distribuciones que disponen de fórmula cerrada, como la &quot;normal&quot; o la &quot;poisson&quot;, se tiene que omitir el parámetro start. Como no podemos usar fitdistr para estimar el parámetro \\(p\\) de una Bernoulli (los autores del paquete debieron de considerar que era más fácil estimarlo directamente), vamos a usarla en otro ejemplo. Consideremos la siguiente muestra y de 100 valores generados con distribución de Poisson de parámetro \\(\\lambda=10\\): set.seed(100) y=rpois(100,10) set.seed(NULL) y ## [1] 8 10 9 12 10 11 8 12 7 11 11 12 7 10 9 8 11 7 6 12 10 12 7 ## [24] 7 10 6 7 15 9 9 7 8 15 11 12 5 14 4 7 14 8 14 10 4 9 8 ## [47] 11 11 10 12 7 14 7 9 10 3 10 7 9 21 14 6 13 3 10 6 3 13 9 ## [70] 12 8 11 10 11 11 8 6 17 7 8 10 12 15 12 13 10 9 12 8 11 12 4 ## [93] 10 8 5 8 8 10 8 11 Vamos a estimar el parámetro \\(\\lambda\\) de una distribución Poisson que haya generado este vector: library(MASS) fitdistr(y, densfun=&quot;poisson&quot;) ## lambda ## 9.5600000 ## (0.3091925) El resultado dice que el valor estimado de \\(\\lambda\\) es 9.56, con un error típico estimado de 0.31. Veámoslo directamente: el estimador máximo verosímil de \\(\\lambda\\) es la media aritmética \\(\\overline{X}\\) y el error típico de este estimador es \\(\\sqrt{\\lambda}/\\sqrt{n}\\) (recordad que la desviación típica de una Poisson de parámetro \\(\\lambda\\) es \\(\\sqrt{\\lambda}\\) y que el error típico de la media muestral es la desviación típica poblacional dividida por la raíz cuadrada del tamaño de la muestra), por lo que el error típico de una estimación es \\(\\sqrt{\\overline{X}}/\\sqrt{n}\\). mean(y) ## [1] 9.56 sqrt(mean(y)/length(y)) ## [1] 0.3091925 También podemos estimar la media y la desviación típica de una variable normal que hubiera producido esta muestra. fitdistr(y, densfun=&quot;normal&quot;) ## mean sd ## 9.5600000 3.0832450 ## (0.3083245) (0.2180183) Observad que la estimación de la desviación típica que nos da fitdistr es la desviación típica “verdadera” (que es su estimador máximo verosímil) y no la muestral: sd(y) ## [1] 3.098778 sqrt((length(y)-1)/length(y))*sd(y) ## [1] 3.083245 Vamos a estimar ahora el número de grados de libertad de una t de Student que hubiera producido esta muestra. fitdistr(y, densfun=&quot;t&quot;) ## m s df ## 9.5085516 2.7517475 9.9229027 ## (0.2997949) (0.3072053) (8.4890355) ¡Vaya!, aparte del número de grados de libertad, df, han aparecido parámetros que no esperábamos. Los parámetros m y s son los parámetros de posición, \\(\\mu\\), y de escala, \\(\\sigma\\), respectivamente, que definen una familia más general de distribuciones t de Student (si os interesa, consultad esta entrada de la Wikipedia). Las que usamos en este curso tienen \\(\\mu=0\\) y \\(\\sigma=1\\). ¿Cómo podríamos estimar los grados de libertad de una t de Student de las nuestras? Especificando dentro de fitdistr los valores de los parámetros que queremos que tomen un valor concreto: en este caso, añadiendo m=0 y s=1. fitdistr(y, densfun=&quot;t&quot;, m=0, s=1) ## Error in fitdistr(y, densfun = &quot;t&quot;, m = 0, s = 1): &#39;start&#39; must be a named list Ahora R nos pide que demos un valor inicial al número de grados de libertad, df, para poder arrancar el algoritmo numérico que usará. Vamos a inicializarlo a 1, y de paso veremos cómo se usa este parámetro: fitdistr(y, densfun=&quot;t&quot;, m=0, s=1, start=list(df=1)) ## Warning in stats::optim(x = c(8L, 10L, 9L, 12L, 10L, 11L, 8L, 12L, 7L, 11L, : one-dimensional optimization by Nelder-Mead is unreliable: ## use &quot;Brent&quot; or optimize() directly ## Warning in dt((x - m)/s, df, log = TRUE): NaNs produced ## df ## 0.37265625 ## (0.04277075) Obtenemos un número estimado de grados de libertad de la t de Student de aproximadamente 0.37 grados de libertad (sí, los grados de libertad de una t de Student pueden ser un número real positivo cualquiera). Por otro lado, R nos avisa de que el resultado es poco de fiar, pero tampoco nos importa mucho, porque el objetivo era mostrar un ejemplo de cómo fijar valores de parámetros, igualándolos a dichos valores, y cómo especificar el parámetro start, como una list donde asignamos a cada parámetro un valor inicial. El resultado de fitdistr es una list, y por lo tanto el valor de cada estimador y su error típico se pueden obtener con los sufijos adecuados. En concreto, los valores estimados forman la componente estimate y los errores típicos la componente sd. Para obtenerlos directamente, basta usar los sufijos $estimate y $sd, respectivamente: fitdistr(y,&quot;poisson&quot;)$estimate #Estimación de lambda ## lambda ## 9.56 fitdistr(y,&quot;poisson&quot;)$sd #Error típico ## lambda ## 0.3091925 fitdistr(y,&quot;normal&quot;)$estimate #Estimaciones ## mean sd ## 9.560000 3.083245 fitdistr(y,&quot;normal&quot;)$estimate[1] #Estimación de mu ## mean ## 9.56 fitdistr(y,&quot;normal&quot;)$estimate[2] #Estimación de sigma ## sd ## 3.083245 3.2 Guía rápida fitdistr del paquete MASS, sirve para calcular los estimadores máximo verosímiles de los parámetros de una distribución a partir de una muestra. El resultado es una list que incluye los objetos estimate (los valores estimados) y sd (los errores típicos de las estimaciones). Sus parámetros principales son: densfun: el nombre de la familia de distribuciones, entre comillas. start: permite fijar el valor inicial del algoritmo numérico para calcular el estimador, si la función lo requiere. 3.3 Ejercicios Test (1) Las distribuciones de Weibull tienen dos parámetros: forma, shape, y escala, scale. Supongamos que los datos siguientes siguen una distribución de Weibull: 2.46, 2.28, 1.7, 0.62, 0.87, 2.81, 2.35, 2.08, 2.11, 1.72. Calculad el estimador máximo verosímil del parámetro de escala de esta distribución, redondeado a 3 cifras decimales. Tenéis que dar el resultado (sin ceros innecesarios a la derecha), no cómo lo habéis calculado. (2) Generad, con semilla de aleatoriedad igual a 42, una secuencia aleatoria de 100 valores con distribución geométrica Ge(0.6). A continuación estimad por máxima verosimilitud el parámetro \\(p\\) de una distribución geométrica que haya generado dicha muestra y dad como respuesta a esta pregunta el error típico de esta estimación redondeado a 3 cifras decimales. Tenéis que dar el resultado (sin ceros innecesarios a la derecha), no cómo lo habéis calculado. Respuestas al test (1) 2.116 Nosotros lo hemos calculado con x=c(2.46, 2.28, 1.7, 0.62, 0.87, 2.81, 2.35, 2.08, 2.11, 1.72) round(fitdistr(x,&quot;weibull&quot;)$estimate,3) (2) 0.038 Nosotros lo hemos calculado con set.seed(42) x=rgeom(100,0.6) round(fitdistr(x,&quot;geometric&quot;)$sd,3) "],
["chap-IC.html", "Lección 4 Intervalos de confianza 4.1 Intervalo de confianza para la media basado en la t de Student 4.2 Intervalos de confianza para la proporción poblacional 4.3 Intervalo de confianza para la varianza de una población normal 4.4 Bootstrap 4.5 Guía rápida 4.6 Ejercicios", " Lección 4 Intervalos de confianza En esta lección explicamos cómo calcular con R algunos intervalos de confianza básicos. Recordad que un intervalo de confianza del \\(q\\times 100\\%\\) (con \\(q\\) entre 0 y 1) para un parámetro poblacional (la media, la desviación típica, la probabilidad de éxito de una variable Bernoulli, …) es un intervalo obtenido aplicando a una muestra aleatoria simple una fórmula que garantiza (si se cumplen una serie de condiciones sobre la distribución de la variable aleatoria poblacional que en cada caso dependen del parámetro y de la fórmula) que el \\(q\\times 100\\%\\) de las veces que la aplicáramos a una muestra aleatoria simple de la misma población, el intervalo resultante contendría el parámetro poblacional que queremos estimar. Esto es lo que significa lo de “confianza del \\(q\\times 100\\%\\)”: que confiamos en que nuestra muestra pertenece al \\(q\\times 100\\%\\) de las muestras (aleatorias simples) en las que la fórmula acierta y da un intervalo que contiene el parámetro deseado. Algunas de las funciones que aparecen en esta lección volverán a salir en la próxima, ya que aunque calculan intervalos de confianza, su función principal es en realidad efectuar contrastes de hipótesis. 4.1 Intervalo de confianza para la media basado en la t de Student Supongamos que queremos estimar a partir de una m.a.s. la media \\(\\mu\\) de una población que sigue una distribución normal o tomando la muestra grande (por fijar una cota, de tamaño 40 o mayor). En esta situación, si \\(\\overline{X}\\), \\(\\widetilde{S}_{X}\\) y \\(n\\) son, respectivamente, la media muestral, la desviación típica muestral y el tamaño de la muestra, un intervalo de confianza del \\(q\\times 100\\%\\) para \\(\\mu\\) es \\[\\begin{equation} \\overline{X}\\pm t_{n-1,(1+q)/2} \\cdot \\frac{\\widetilde{S}_{X}}{\\sqrt{n}} \\tag{4.1} \\end{equation}\\] donde \\(t_{n-1,(1+q)/2}\\) es el cuantil de orden \\((1+q)/2\\) de una variable aleatoria con distribución t de Student con \\(n-1\\) grados de libertad. Fijaos en que \\(\\widetilde{S}_{X}/\\sqrt{n}\\) es el error típico de la estimación de la media. A la hora de calcular este intervalo de confianza, tenemos dos posibles situaciones. Una, típica de ejercicios, es cuando de la muestra sólo conocemos su media muestral \\(\\overline{X}\\), su desviación típica muestral \\(\\widetilde{S}_X\\) y su tamaño \\(n\\). Si los denotamos por x.b, sdm y n, respectivamente, y denotamos el nivel de confianza en tanto por uno \\(q\\) por q, podemos calcular los extremos de este intervalo de confianza con la expresión siguiente: x.b+(qt((1+q)/2,n-1)*sdm/sqrt(n))*c(-1,1) Ahora bien, “en la vida real” lo usual es disponer de un vector numérico X con los valores de la muestra. En este caso, podemos usar la función t.test de R, que, entre otra información, calcula estos intervalos de confianza para \\(\\mu\\). Si solo nos interesa el intervalo de confianza, podemos usar la sintaxis siguiente: t.test(X,conf.level=...)$conf.int donde tenemos que igualar el parámetro conf.level al nivel de confianza \\(q\\) en tanto por uno. Si \\(q=0.95\\), no hace falta entrarlo, porque es su valor por defecto. Ejemplo 4.1 Tenemos una muestra de pesos en gramos de 28 recién nacidos con luxación severa de cadera: pesos=c(2466,3941,2807,3118,3175,3515,3317,3742,3062,3033,2353,3515,3260,2892, 4423,3572,2750,3459,3374,3062,3205,2608,3118,2637,3438,2722,2863,3513) Vamos a suponer que nuestra muestra es aleatoria simple y que los pesos al nacer de los bebés con esta patología siguen una distribución normal. A partir de esta muestra, queremos calcular un intervalo de confianza del 95% para el peso medio de un recién nacido con luxación severa de cadera, y ver si contiene el peso medio de la población global de recién nacidos, que es de unos 3400 g. Como suponemos que la variable aleatoria poblacional es normal, para calcular un intervalo de confianza del 95% para su valor medio vamos a usar la fórmula basada en la distribución t de Student, y por lo tanto la función t.test: t.test(pesos)$conf.int ## [1] 2997.849 3355.008 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 El intervalo que obtenemos es [2997.8, 3355] y está completamente a la izquierda del peso medio global de 3400 g, por lo que tenemos evidencia (a un 95% de confianza) de que los niños con luxación severa de cadera pesan de media al nacer por debajo de la media global. La apostilla entre paréntesis “a un 95% de confianza” aquí significa que hemos basado esta conclusión en un intervalo obtenido con una fórmula que acierta con una probabilidad del 95%, en el sentido de que el 95% de las ocasiones que aplicamos esta fórmula a una m.a.s. de una variable aleatoria normal, produce un intervalo que contiene la media de esta variable. Observad que el resultado de t.test(pesos)$conf.int tiene un atributo, conf.level, que indica su nivel de confianza. En principio este atributo no molesta para nada en cálculos posteriores con los extremos de este intervalo de confianza, pero si os molesta, lo podéis quitar igualándolo a NULL. IC.lux=t.test(pesos)$conf.int attr(IC.lux,&quot;conf.level&quot;)=NULL IC.lux ## [1] 2997.849 3355.008 Veamos cómo podríamos haber obtenido este intervalo directamente con la fórmula (4.1): x=mean(pesos) sdm=sd(pesos) n=length(pesos) q=0.95 x+(qt((1+q)/2,n-1)*sdm/sqrt(n))*c(-1,1) ## [1] 2997.849 3355.008 Como podéis ver, coincide con el intervalo obtenido con la función t.test. Ejemplo 4.2 Vamos a comprobar con un experimento esto de la “confianza” de los intervalos de confianza, y en concreto de la fórmula (4.1). Vamos a generar al azar una Población de 10,000,000 “individuos” con distribución normal estándard. Vamos a tomar 200 muestras aleatorias simples de tamaño 50 de esta población y calcularemos el intervalo de confianza para la media poblacional usando dicha fórmula. Finalmente, contaremos cuántos de estos intervalos de confianza contienen la media de la Población. Fijaremos la semilla de aleatoriedad para que el experimento sea reproducible y podáis comprobar que no hacemos trampa. En otras simulaciones habríamos obtenido resultados mejores o peores, es lo que tienen las simulaciones aleatorias. set.seed(42) Poblacion=rnorm(10^7) #La población mu=mean(Poblacion) # La media poblacional M=replicate(200, sample(Poblacion,50,replace=TRUE)) # Las muestras dim(M) ## [1] 50 200 Tenemos una matriz M de 200 columnas y 50 filas, donde cada columna es una m.a.s. de nuestra población. Vamos a aplicar a cada una de estas muestras la función t.test para calcular un intervalo de confianza del 95% y luego contaremos los aciertos, es decir, cuántos de ellos contienen la media poblacional IC.t=function(X){t.test(X)$conf.int} ICs=apply(M,FUN=IC.t,MARGIN=2) Aciertos=length(which((mu&gt;=ICs[1,]) &amp; (mu&lt;=ICs[2,]))) Aciertos ## [1] 189 Hemos acertado 189 veces, es decir, un 94.5% de los intervalos obtenidos contienen la media poblacional. No hemos quedado muy lejos del 95% esperado. Para visualizar mejor los aciertos, vamos a dibujar los intervalos apilados en un gráfico, donde aparecerán en azul claro los que aciertan y en rojo los que no aciertan. plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200),xlab=&quot;Valores&quot;,ylab=&quot;Repeticiones&quot;,main=&quot;&quot;) seg.int=function(i){ color=&quot;light blue&quot;; if((mu&lt;ICs[1,i]) | (mu&gt;ICs[2,i])){color = &quot;red&quot;} segments(ICs[1,i],i,ICs[2,i],i,col=color,lwd=2) } sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Figura 4.1: Aciertos y errores en 200 Intervalos de confianza al 95% Fijaos en que los errores no se distribuyen por igual a los dos lados, hay muchos más intervalos que dejan la media poblacional a su izquierda que a su derecha, mientras que, en teoría, tendríamos que esperar que en la mitad de los errores la media poblacional estuviera a la izquierda del intervalo calculado y en la otra mitad a la derecha. Cosas de la aleatoriedad. 4.2 Intervalos de confianza para la proporción poblacional En esta sección consideramos el caso en que la población objeto de estudio sigue una distribución Bernoulli y queremos estimar su probabilidad de éxito (o proporción poblacional) \\(p\\). Para ello, tomamos una muestra aleatoria simple de tamaño \\(n\\) y número de éxitos \\(x\\), y, por lo tanto, de proporción muestral de éxitos \\(\\widehat{p}_X=x/n\\). El método “exacto” de Clopper-Pearson para calcular un intervalo de confianza del \\(q\\times 100\\%\\) para \\(p\\) se basa en el hecho de que, en estas condiciones, el valor de \\(x\\) sigue una distribución binomial \\(B(n,p)\\). Este método se puede usar siempre, sin ninguna restricción sobre la muestra, y consiste básicamente en encontrar los valores \\(p_0\\) y \\(p_1\\) tales que \\[ \\sum_{k=x}^n\\binom{n}{k}p_0^k(1-p_0)^{n-k}=(1-q)/2,\\qquad \\displaystyle\\sum_{k=0}^x\\binom{n}{k}p_1^k(1-p_1)^{n-k}=(1-q)/2 \\] y dar el intervalo \\([p_0,p_1]\\). Para calcular este intervalo se puede usar la función binom.exact del paquete epitools. Su sintaxis es binom.exact(x,n,conf.level) donde x y n representan, respectivamente, el número de éxitos y el tamaño de la muestra, y conf.level es \\(q\\), el nivel de confianza en tanto por uno. El valor por defecto de conf.level es 0.95. Ejemplo 4.3 Supongamos que, de una muestra de 15 enfermos tratados con un cierto medicamento, solo 1 ha desarrollado taquicardia. Queremos conocer un intervalo de confianza del 95% para la proporción de enfermos tratados con este medicamento que presentan este efecto adverso. Tenemos una población Bernoulli, formada por los enfermos tratados con el medicamento en cuestión, donde los éxitos son los enfermos que desarrollan taquicardia. La fracción de éstos es la fracción poblacional \\(p\\) para la que queremos calcular el intervalo de confianza del 95%. Para ello cargamos el paquete epitools y usamos binom.exact: library(epitools) binom.exact(1,15) ## x n proportion lower upper conf.level ## 1 1 15 0.06666667 0.00168643 0.3194846 0.95 El resultado de la función binom.exact es un data frame; el intervalo de confianza deseado está formado por los números en las columnas lower (extremo inferior) y upper (extremo superior): binom.exact(1,15)$lower ## [1] 0.00168643 binom.exact(1,15)$upper ## [1] 0.3194846 Hemos obtenido el intervalo de confianza [0.002,0.319]: podemos afirmar con un nivel de confianza del 95% que el porcentaje de enfermos tratados con este medicamento que presentan este efecto adverso está entre el 0.2% y el 31.9%. Supongamos ahora que el tamaño \\(n\\) de la muestra aleatoria simple es grande; de nuevo, digamos que \\(n{\\geqslant}40\\). En esta situación, podemos usar el Método de Wilson para aproximar, a partir del Teorema Central del Límite, un intervalo de confianza del parámetro \\(p\\) al nivel de confianza \\(q\\times 100\\%\\), mediante la fórmula \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/2}^2}{2n}\\pm z_{(1+q)/2}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/2}^2}{4n^2}}}{1+\\frac{z_{(1+q)/2}^2}{n}} \\] donde \\(z_{(1+q)/2}\\) es el cuantil de orden \\((1+q)/2\\) de una variable aleatoria normal estándar. Para calcular este intervalo se puede usar la función binom.wilson del paquete epitools. Su sintaxis es binom.wilson(x,n,conf.level) con los mismos parámetros que binom.exact. Ejemplo 4.4 Supongamos que tratamos 45 ratones con un agente químico, y 10 de ellos desarrollan un determinado cáncer de piel. Queremos calcular un intervalo de confianza al 90% para la proporción \\(p\\) de ratones que desarrollan este cáncer de piel al ser tratados con este agente químico. Como 45 es relativamente grande, usaremos el método de Wilson. Para comparar los resultados, usaremos también el método exacto. Fijaos que, en este ejemplo, \\(q=0.9\\). binom.wilson(10,45,0.9) ## x n proportion lower upper conf.level ## 1 10 45 0.2222222 0.1377238 0.3382281 0.9 binom.exact(10,45,0.9) ## x n proportion lower upper conf.level ## 1 10 45 0.2222222 0.1258186 0.3477285 0.9 Con el método de Wilson obtenemos el intervalo [0.138,0.338] y con el método de Clopper-Pearson, el intervalo [0.126,0.348], un poco más ancho: hay una diferencia en los extremos de alrededor de un punto porcentual. Supongamos finalmente que la muestra aleatoria simple es considerablemente más grande que la usada en el método de Wilson y que, además, la proporción muestral de éxitos \\(\\widehat{p}_{X}\\) está alejada de 0 y de 1. Una posible manera de formalizar estas condiciones es requerir que \\(n{\\geqslant}100\\) y que \\(n\\widehat{p}_{X}{\\geqslant}10\\) y \\(n(1-\\widehat{p}_{X}){\\geqslant}10\\); observad que estas dos últimas condiciones son equivalentes a que tanto el número de éxitos como el número de fracasos en la muestra sean como mínimo 10. En este caso, se puede usar la fórmula de Laplace, que simplifica la de Wilson (aunque, en realidad, la precede en más de 100 años): un intervalo de confianza del parámetro \\(p\\) al nivel de confianza \\(q\\times 100\\%\\) viene dado aproximadamente por la fórmula \\[ \\widehat{p}_{X}\\pm z_{(1+q)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Esta fórmula está implementada en la función binom.approx del paquete epitools, de uso similar al de las dos funciones anteriores. Ejemplo 4.5 En una muestra aleatoria de 500 familias con niños en edad escolar de una determinada ciudad se ha observado que 340 introducen fruta de forma diaria en la dieta de sus hijos. A partir de este dato, queremos encontrar un intervalo de confianza del 95% para la proporción real de familias de esta ciudad con niños en edad escolar que incorporan fruta fresca de forma diaria en la dieta de sus hijos. Tenemos una población Bernoulli donde los éxitos son las familias que aportan fruta de forma diaria a la dieta de sus hijos, y la fracción de estas familias en el total de la población es la proporción poblacional \\(p\\) para la que queremos calcular el intervalo de confianza. Como \\(n\\) es muy grande y los números de éxitos y fracasos también lo son, podemos emplear el método de Laplace. binom.approx(340,500) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.6391123 0.7208877 0.95 Por lo tanto, según la fórmula de Laplace, un intervalo de confianza al 95% para la proporción poblacional es [0.639,0.721]. ¿Qué hubiéramos obtenido con los otros dos métodos? binom.wilson(340,500) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.637873 0.7193822 0.95 binom.exact(340,500) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.6371369 0.7207188 0.95 Como podéis ver, los resultados son muy parecidos, con diferencias de unas pocas milésimas. 4.3 Intervalo de confianza para la varianza de una población normal Supongamos ahora que queremos estimar la varianza \\(\\sigma^2\\), o la desviación típica \\(\\sigma\\), de una población que sigue una distribución normal. Tomamos una muestra aleatoria simple de tamaño \\(n\\), y sea \\(\\widetilde{S}_{X}\\) su desviación típica muestral. En esta situación, un intervalo de confianza del \\(q\\times 100\\%\\) para la varianza \\(\\sigma^2\\) es \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2},\\ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2}\\right], \\] donde \\(\\chi_{n-1,(1-q)/2}^2\\) y \\(\\chi_{n-1,(1+q)/2}^2\\) son, respectivamente, los cuantiles de orden \\((1-q)/2\\) y \\((1+q)/2\\) de una variable aleatoria que sigue una distribución \\(\\chi^2\\) con \\(n-1\\) grados de libertad. Si conocéis la varianza muestral \\(\\widetilde{S}_{X}^2\\), que denotaremos por varm, podéis calcular este intervalo de confianza para la varianza con la fórmula siguiente (donde qindica el nivel de confianza en tanto por uno \\(q\\)): c((n-1)*varm/qchisq((1+q)/2,n-1),(n-1)*varm/qchisq((1-q)/2,n-1)) Si, en cambio, disponéis de la muestra, podéis calcular este intervalo de confianza con la función varTest del paquete EnvStats. La sintaxis es similar a la usada con t.test: varTest(X,conf.level)$conf.int donde X es el vector que contiene la muestra y conf.level el nivel de confianza, que por defecto es igual a 0.95. Ejemplo 4.6 Un índice de calidad de un reactivo químico es el tiempo que tarda en actuar. Se supone que la distribución de este tiempo de actuación del reactivo es aproximadamente normal. Se realizaron 30 pruebas independientes, que forman una muestra aleatoria simple, en las que se midió el tiempo de actuación del reactivo. Los tiempos obtenidos fueron reactivo = c(12,13,13,14,14,14,15,15,16,17,17,18,18,19,19,25,25,26,27,30,33,34,35, 40,40,51,51,58,59,83) Queremos usar estos datos para calcular un intervalo de confianza del 95% para la desviación típica de este tiempo de actuación. El siguiente código calcula un intervalo de confianza al 95% para la varianza a partir del vector reactivo: library(EnvStats) varTest(reactivo)$conf.int ## LCL UCL ## 191.2627 544.9572 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Este intervalo de confianza es para la varianza. Como la desviación típica es la raíz cuadrada de la varianza, para obtener un intervalo de confianza al 95% para la desviación típica, tenemos que tomar la raíz cuadrada de este intervalo para la varianza: sqrt(varTest(reactivo)$conf.int) ## LCL UCL ## 13.82977 23.34432 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Por lo tanto un intervalo de confianza del 95% para la desviación típica poblacional es [13.83, 23.34]. De nuevo, si os molesta, podéis eliminar el atributo conf.level igualándolo a NULL. 4.4 Bootstrap Cuando no tiene sentido usar un método paramétrico como los explicados en las secciones anteriores para calcular un intervalo de confianza porque no se satisfacen las condiciones teóricas que garantizan que el intervalo obtenido contiene el 95% de las veces el parámetro poblacional deseado, podemos recurrir a un método no paramétrico. El más utilizado es el bootstrap, que básicamente consiste en: Remuestrear la muestra: tomar muchas muestras aleatorias simples de la muestra de la que disponemos, cada una de ellas del mismo tamaño que la muestra original (pero simples, es decir, con reposición). Calcular el estimador sobre cada una de estas submuestras. Organizar los resultados en un vector. Usar este vector para calcular un intervalo de confianza. La manera más sencilla de llevar a cabo el cálculo final del intervalo de confianza es el llamado método de los percentiles, en el que se toman como extremos del intervalo de confianza del \\(q\\times 100\\%\\) los cuantiles de orden \\((1-q)/2\\) y \\((1+q)/2\\) del vector de estimadores, pero hay mucho otros métodos; encontraréis algunos en esta entrada de la Wikipedia. Ejemplo 4.7 Volvamos a la muestra de pesos del Ejemplo 4.1, pero supongamos ahora que la variable aleatoria poblacional de la que la hemos extraído no es normal (o que no queremos suponer que lo sea). Vamos a usar el método bootstrap de los percentiles para calcular un intervalo de confianza del 95% para el peso medio poblacional. Para ello, vamos a general 1000 muestras aleatorias simples de la muestra, todas ellas del mismo tamaño que la muestra, calcularemos la media de cada una de estas muestras simples, construiremos un vector con estas medias muestrales, y daremos como extremos del intervalo de confianza los cuantiles de orden 0.025 y 0.975 del vector así obtenido. set.seed(42) n=length(pesos) X=replicate(1000,mean(sample(pesos,n,replace=TRUE))) IC.boot=c(quantile(X,0.025),quantile(X,0.975)) round(IC.boot,1) ## 2.5% 97.5% ## 3000.0 3348.2 El intervalo obtenido en este caso es [3000, 3348.2]; como se trata de un método basado en una simulación aleatoria, seguramente con otra semilla de aleatoriedad daría un intervalo diferente. Para comparar, recordad que el intervalo de confianza obtenido con la fórmula basada en la t de Student ha sido [2997.8, 3355]. El paquete boot dispone de la función boot para llevar a cabo simulaciones bootstrap. Aplicando luego la función boot.ci al resultado de la función boot obtenemos diversos intervalos de confianza basados en el enfoque bootstrap. La sintaxis básica de la función boot es boot(X,estadístico,R) donde: X es el vector que forma la muestra de la que disponemos R es el número de muestras que queremos extraer de la muestra original El estadístico es la función que calcula el estadístico deseado de la submuestra, y tiene que tener dos parámetros: el primero representa la muestra original X y el segundo representa el vector de índices de una m.a.s. de X. Por ejemplo, si vamos a usar la función boot para efectuar una simulación bootstrap de medias muestrales, podemos tomar como estadístico la función: media.boot=function(X,índices){mean(X[índices])} Por otro lado, el nivel de confianza se especifica en la función boot.ci mediante el parámetro conf (no conf.level, como hasta ahora), cuyo valor por defecto es, eso sí, el de siempre: 0.95. A modo de ejemplo, vamos a usar las funciones del paquete boot para calcular un intervalo de confianza del 95% para la media de la variable aleatoria que ha producido el vector pesos. library(boot) set.seed(42) simulacion=boot(pesos,media.boot,1000) El resultado simulacion de esta última instrucción es una list que incluye, en su componente t, el vector de 1000 medias muestrales obtenido mediante la simulación; sus 10 primeros valores son: simulacion$t[1:10] ## [1] 3344.57 3107.43 3162.89 3038.86 3094.64 3202.71 3151.25 3020.39 ## [9] 3072.75 3284.75 Calculemos ahora el intervalo de confianza deseado: boot.ci(simulacion) ## Warning in boot.ci(simulacion): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 1000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = simulacion) ## ## Intervals : ## Level Normal Basic ## 95% (3022, 3345 ) (3021, 3336 ) ## ## Level Percentile BCa ## 95% (3017, 3332 ) (3028, 3359 ) ## Calculations and Intervals on Original Scale Obtenemos cuatro intervalos de confianza para \\(\\mu\\), calculados con cuatro métodos a partir de la simulación realizada (y un aviso de que no ha podido calcular un quinto intervalo). Cada uno de estos intervalos es un objeto de una list y por lo tanto se puede obtener con el sufijo adecuado, que podréis deducir del resultado de aplicar str al resultado de una función boot.ci. El intervalo Percentile es el calculado con el método de los percentiles que hemos explicado antes, y se obtiene con el sufijo $percent[4:5] (no ha dado lo mismo que antes, pese a usar la misma semilla de aleatoriedad, porque el procedimiento interno usado por la función boot para remuestrear el vector pesos ha sido diferente). No vamos a entrar en detalle sobre los métodos que usa para calcular el resto de intervalos, en realidad todos tienen ventajas e inconvenientes. Ejemplo 4.8 ¿Realmente funciona el enfoque bootstrap? Vamos a retomar el experimento realizado en el Ejemplo 4.2, donde construimos una matriz M cuyas columnas son 200 muestras aleatorias simples de tamaño 50 de una población que sigue una distribución normal estándard. En dicho ejemplo calculamos para cada una de estas muestras el intervalo de confianza del 95% para la media poblacional usando la fórmula (4.1), que es la recomendada por la teoría en este caso. De los 200 intervalos calculados, 189 contuvieron la media poblacional, lo que representa un 94.5% de aciertos. Ahora vamos a calcular para cada una de estas muestras un intervalo de confianza del 95% por el método bootstrap de los percentiles y compararemos las tasas de aciertos. Aunque se puede comprobar fácilmente que no es el caso, para mayor seguridad vamos a volver a generar en las mismas condiciones las 200 muestras de la población, no sea que a lo largo de la lección hayamos modificado inadvertidamente el contenido de la matriz M (y así de paso fijamos la semilla de aleatoriedad). set.seed(42) Poblacion=rnorm(10^7) #La población mu=mean(Poblacion) # La media poblacional M=replicate(200, sample(Poblacion,50,replace=TRUE)) # Las muestras IC.b=function(X){boot.ci(boot(X,media.boot,1000))$percent[4:5]} ICs.bootstrap=apply(M,FUN=IC.b,MARGIN=2) Aciertos.bootstrap=length(which((mu&gt;=ICs.bootstrap[1,]) &amp; (mu&lt;=ICs.bootstrap[2,]))) Aciertos.bootstrap ## [1] 186 Con el bootstrap, hemos acertado en 186 ocasiones, lo que supone un 93% de aciertos. 4.5 Guía rápida t.test(X, conf.level=...)$conf.int calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la media poblacional usando la fórmula basada en la t de Student aplicada a la muestra X. binom.exact(x,n,conf.level=...) del paquete epitools, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la proporción poblacional aplicando el método de Clopper-Pearson a una muestra de tamaño n con x éxitos. binom.wilson(x,n,conf.level=...) del paquete epitools, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la proporción poblacional aplicando el método de Wilson a una muestra de tamaño n con x éxitos. binom.approx(x,n,conf.level=...) del paquete epitools, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la proporción poblacional aplicando la fórmula de Laplace a una muestra de tamaño n con x éxitos. varTest(X,conf.level=...)$conf.int del paquete EnvStats, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la varianza poblacional usando la fórmula basada en la ji cuadrado aplicada a la muestra X. boot(X,E,R) del paquete boot, lleva a cabo una simulación bootstrap, tomando R submuestras del vector X y calculando sobre ellas el estadístico representado por la función E. boot.ci del paquete boot, aplicado al resultado de una función boot, calcula diversos intervalos de confianza a partir del resultado de la simulación efectuada con boot. El nivel de confianza se especifica con el parámetro conf. 4.6 Ejercicios Modelo de test (1) Tomad la muestra de todas las longitudes de pétalos de flores Iris setosa contenida en la tabla de datos iris y usadla para calcular un intervalo de confianza del 95% para el valor medio de las longitudes de pétalos de esta especie de flores usando la fórmula basada en la t de Student. Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 2 cifras decimales (sin ceros innecesarios a la derecha). (2) Tenemos una población de media \\(\\mu\\) desconocida. Tomamos una muestra aleatoria simple de tamaño 80 y obtenemos una media muestral de 6.2 y una desviación típica muestral de 1.2. Usad estos datos y la fórmula del intervalo de confianza para la media basado en la t de Student para calcular un intervalo de confianza al 95% para \\(\\mu\\). Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 2 cifras decimales (sin ceros innecesarios a la derecha). (3) Tenemos una población Bernoulli de proporción poblacional \\(p\\) desconocida. Tomamos una muestra aleatoria simple de 80 individuos y obtenemos una proporción muestral de 35% de éxitos. Calculad un intervalo de confianza para \\(p\\) a un nivel de confianza del 95% usando el método de Wilson. Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 3 cifras decimales (sin ceros innecesarios a la derecha). (4) Tomad la muestra de todas las longitudes de pétalos de flores Iris setosa contenida en la tabla de datos iris y usadla para calcular un intervalo de confianza del 95% para la varianza de las longitudes de pétalos de esta especie de flores. Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 3 cifras decimales (sin ceros innecesarios a la derecha). Respuestas al test (1) 1.41,1.51 Nosotros lo hemos calculado con round(t.test(iris[iris$Species==&quot;setosa&quot;,&quot;Petal.Length&quot;])$conf.int,2) ## [1] 1.41 1.51 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 (2) 5.933,6.467 Nosotros lo hemos calculado con x=6.2 n=80 sdm=1.2 conf.level=0.95 round(x+(qt((1+conf.level)/2,n-1)*sdm/sqrt(n))*c(-1,1),3) ## [1] 5.933 6.467 (3) 0.255,0.459 Nosotros lo hemos calculado con round(binom.wilson(0.35*80,80),3) ## x n proportion lower upper conf.level ## 1 28 80 0.35 0.255 0.459 0.95 (4) 0.021,0.047 Nosotros lo hemos calculado con round(varTest(iris[iris$Species==&quot;setosa&quot;,&quot;Petal.Length&quot;])$conf.int,3) ## LCL UCL ## 0.021 0.047 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 "],
["chap-contrastes.html", "Lección 5 Contrastes de hipótesis 5.1 Contrastes para medias 5.2 Contrastes para varianzas 5.3 Contrastes para proporciones 5.4 Cálculo de la potencia de un contraste 5.5 Guía rápida 5.6 Ejercicios", " Lección 5 Contrastes de hipótesis En esta lección explicamos algunas instrucciones de R que permiten llevar a cabo contrastes de hipótesis sobre parámetros poblacionales. Antes de empezar, repasemos el vocabulario básico relacionado con los contrastes de hipótesis: Hipótesis alternativa, \\(H_1\\): Aquella de la que buscamos evidencia en nuestro estudio. Hipótesis nula, \\(H_0\\): La hipótesis que estamos dispuestos a aceptar si no encontramos evidencia suficiente de la hipótesis alternativa. Suele plantearse en términos de “no hay diferencia”. Contraste bilateral: Contraste en el que la hipótesis alternativa viene definida por un \\(\\neq\\): que un parámetro sea diferente de un valor dado, que un parámetro sobre una población sea diferente del mismo parámetro sobre otra población, … Contraste unilateral: Contraste en el que la hipótesis alternativa viene definida por un \\(&gt;\\) o un \\(&lt;\\): que un parámetro sea mayor que un valor dado, que un parámetro sobre una población sea menor que el mismo parámetro sobre otra población, … Error de tipo I, o Falso positivo: Concluir que la hipótesis alternativa es verdadera cuando en realidad es falsa. Nivel de significación, \\(\\alpha\\): La probabilidad de cometer un error de tipo I. Nivel de confianza, \\(1-\\alpha\\): La probabilidad de no cometer un error de tipo I. Error de tipo II, o Falso negativo: Concluir que la hipótesis alternativa es falsa cuando en realidad es verdadera. Potencia, \\(1-\\beta\\): La probabilidad de no cometer un error de tipo II. Estadístico de contraste: El valor que se calcula a partir de la muestra obtenida en el estudio y que se usará para tomar la decisión en el contraste planteado. p-valor: La probabilidad de que, si la hipótesis nula es verdadera, el estadístico de contraste tome un valor tan o más extremo en el sentido de la hipótesis alternativa que el obtenido en el estudio Intervalo de confianza al nivel de confianza \\(1-\\alpha\\): Un intervalo en el que el parámetro poblacional que contrastamos tiene probabilidad \\(1-\\alpha\\) de pertenecer en el sentido de los intervalos de confianza de la Lección 4: es decir, porque se ha obtenido con un procedimiento que produce intervalos que, en el \\((1-\\alpha)\\times 100\\%\\) de las ocasiones que lo aplicamos a muestras aleatorias simples, contiene el parámetro poblacional. Está formado por los valores del parámetro poblacional que, si fueran los que contrastáramos en nuestro contraste, producirían un p-valor como mínimo \\(\\alpha\\). Los intervalos de confianza de los contrastes bilaterales coinciden con los definidos en la Lección 4. Regla de rechazo: Rechazamos la hipótesis nula en favor de la alternativa con un nivel de significación \\(\\alpha\\) dado cuando se da alguna de las dos condiciones siguientes (que son equivalentes, es decir, se dan las dos o ninguna): El p-valor és menor que el nivel de significación. El valor contrastado del parámetro poblacional no pertenece al intervalo de confianza del nivel \\(1-\\alpha\\). Ejemplo 5.1 Tenemos una moneda y creemos que está trucada a favor de Cara, es decir, que al lanzarla al aire produce más caras que cruces. Para intentar decidir si esto es cierto o no, lanzamos la moneda al aire 20 veces y obtenemos 15 caras. Llamemos \\(p\\) a la probabilidad de obtener cara al lanzar al aire esta moneda. Entonces: La hipótesis alternativa, de la que buscamos evidencia, es que la moneda está trucada a favor de cara: \\(H_1: p&gt;0.5\\). La hipótesis nula, que aceptaremos por defecto si no encontramos evidencia de que la alternativa sea verdadera, es que la moneda no está trucada: \\(H_0: p=0.5\\). Cometeríamos un error de tipo I si la moneda fuera honrada y nosotros concluyéramos que está trucada. Cometeríamos un error de tipo II si la moneda estuviera trucada y nosotros concluyéramos que no lo está. El estadístico de contraste en este experimento es simplemente el número de caras en un serie de lanzamientos de la moneda. El p-valor es la probabilidad de obtener 15 o más caras al lanzar al aire 20 veces la moneda si fuera verdad que \\(p=0.5\\). Como en este caso el número de caras seguiría una distribución binomial \\(B(20,0.5)\\), podemos calcular fácilmente esta probabilidad: 1-pbinom(14,20,0.5) ## [1] 0.0206947 Por lo tanto, el p-valor es 0.021. El intervalo de confianza del 95% de este contraste está formado por los valores de \\(p\\) para los que la probabilidad de obtener 15 o más caras al lanzar al aire 20 veces la moneda es mayor o igual que el 5%, y es [0.5444, 1]. Y bueno, tras todo este vocabulario, ¿cuál sería la conclusión? El p-valor obtenido significa que si la moneda no estuviera trucada, la probabilidad de obtener el número de caras que hemos obtenido o más es muy pequeña, lo que hace difícil de creer que la moneda no esté trucada. En particular, si trabajamos con un nivel de significación del 5%, como el p-valor es más pequeño que 0.05, rechazamos la hipótesis nula. Equivalentemente, como el intervalo de confianza del 95% para la \\(p\\) está completamente a la derecha del valor que contrastamos, 0.5, con este nivel de confianza hemos de concluir que \\(p&gt;0.5\\). En resumen, aceptando una probabilidad de error de tipo I (de concluir que una moneda honrada está trucada) del 5%, rechazamos la hipótesis nula e inferimos que la moneda está trucada a favor de cara. Figura 5.1: “Hipótesis Nula” (http://imgs.xkcd.com/comics/null_hypothesis.png (CC-BY-NC 2.5)) 5.1 Contrastes para medias El test t El test t para contrastar una o dos medias basado en la t de Student está implementado en la función t.test. Este test usa diferentes estadísticos según que el contraste sea de una media o de dos; en este último caso, según se usen muestras emparejadas o independientes; y en este último caso, según las poblaciones tengan varianzas iguales o diferentes. Aunque este test solo es exacto (en el sentido de que da la conclusión con el nivel de significación requerido) cuando las poblaciones involucradas siguen distribuciones normales, el Teorema Central del Límite garantiza que también da resultados aproximadamente correctos cuando las muestras son grandes, aunque las poblaciones no sean normales, por lo que en esta situación también se recomienda su uso. Así pues, aunque en la práctica el test t se use como test “de talla única” para contrastar una o dos medias en cualquier situación, hay que tener claro que su resultado es fiable tan solo: cuando las variables poblacionales involucradas son (aproximadamente) normales, o cuando todas las muestras usadas son grandes. Al final de esta sección explicamos las funciones asociadas a algunos contrastes no paramétricos que pueden usarse cuando estas condiciones no se cumplen. La sintaxis básica de la función t.test es t.test(x, y, mu=..., alternative=..., conf.level=..., paired=..., var.equal=...) donde: x es el vector de datos que forma la muestra que analizamos. y es un vector opcional; si lo entramos, R entiende que estamos realizando un contraste de dos medias, con hipótesis nula la igualdad de estas medias. Podemos sustituir los vectores x e y por una fórmula variable1~variable2 que indique que separamos la variable numérica variable1 en dos vectores definidos por los niveles de un factor variable2 de dos niveles (o de otra variable asimilable a un factor de dos niveles, como por ejemplo una variable numérica que solo tome dos valores diferentes). Con esta construcción, R tomará estos vectores en el orden natural de los niveles de variable2: x será el vector correspondiente al primer nivel e y el correspondiente al segundo. Hay que tener esto en cuenta a la hora de especificar la hipótesis alternativa si es unilateral. Si las dos variables de la fórmula son columnas de un dataframe, se puede usar el parámetro data=... para indicarlo. Solamente tenemos que especificar el parámetro mu si hemos entrado una sola muestra, y en este caso lo hemos de igualar al valor \\(\\mu_0\\) que queremos contrastar, de manera que la hipótesis nula será \\(H_0: \\mu=\\mu_0\\). El parámetro alternative puede tomar tres valores: &quot;two.sided&quot;, para contrastes bilaterales, y &quot;less&quot; y &quot;greater&quot;, para contrastes unilaterales. En esta función, y en todas las que explicamos en esta lección, su valor por defecto, que no hace falta especificar, es &quot;two.sided&quot;. El significado de estos valores depende del tipo de test que efectuemos: Si el test es de una sola muestra, &quot;two.sided&quot; representa la hipótesis alternativa \\(H_1: \\mu\\neq \\mu_0\\), &quot;less&quot; corresponde a \\(H_1: \\mu&lt; \\mu_0\\), y &quot;greater&quot; corresponde a \\(H_1: \\mu&gt; \\mu_0\\). Si hemos entrado dos muestras y llamamos \\(\\mu_x\\) y \\(\\mu_y\\) a las medias de las poblaciones de las que hemos extraído las muestras \\(x\\) e \\(y\\), respectivamente, entonces &quot;two.sided&quot; representa la hipótesis alternativa \\(H_1: \\mu_x \\neq \\mu_y\\); &quot;less&quot; indica que la hipótesis alternativa es \\(H_1: \\mu_x&lt; \\mu_y\\); y &quot;greater&quot;, que la hipótesis alternativa es \\(H_1: \\mu_x&gt; \\mu_y\\). El valor del parámetro conf.level es el nivel de confianza \\(1-\\alpha\\). En esta función, y en todas las que explicamos en esta lección, su valor por defecto, que no es necesario especificar, es 0.95, que corresponde a un nivel de confianza del 95%, es decir, a un nivel de significación \\(\\alpha=0.05\\). El parámetro paired solo lo tenemos que especificar si llevamos a cabo un contraste de dos medias. En este caso, con paired=TRUE indicamos que las muestras son emparejadas, y con paired=FALSE (que es su valor por defecto) que son independientes. Si se trata de muestras emparejadas, los vectores x e y tienen que tener la misma longitud, naturalmente. El parámetro var.equal solo lo tenemos que especificar si llevamos a cabo un contraste de dos medias usando muestras independientes, y en este caso sirve para indicar si queremos considerar las dos varianzas poblacionales iguales (igualándolo a TRUE) o diferentes (igualándolo a FALSE, que es su valor por defecto). La función t.test tiene otro parámetro que queremos destacar, que es común a la mayoría de las funciones de estadística inferencial y análisis de datos. Se trata del parámetro na.action, que sirve para especificar qué queremos hacer con los valores NA. Su valor por defecto es na.omit, que elimina las entradas NA de los vectores (o los pares que contengan algún NA, en el caso de muestras emparejadas). Por ahora, esta opción por defecto es la adecuada, por lo que no hace falta usar este parámetro, pero conviene saber que hay alternativas. Las más útiles son: na.fail, que hace que la ejecución pare si hay algún NA en los vectores, y na.pass, que no hace nada con los NA y permite que las operaciones internas de la función sigan su curso y los manejen como les corresponda. Veamos varios ejemplos de uso de esta función. Ejemplo 5.2 Consideremos el siguiente vector de longitud 25: x=c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,3.44,1.53) Supongamos que esta muestra ha sido extraída de una población normal. Postulamos que el valor medio \\(\\mu\\) de la población no es 2. Para confirmarlo, vamos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2\\\\ H_{1}:\\mu\\neq 2 \\end{array}\\right. \\] con nivel de significación \\(\\alpha=0.05\\): t.test(x, mu=2, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## One Sample t-test ## ## data: x ## t = 5.912, df = 24, p-value = 4.23e-06 ## alternative hypothesis: true mean is not equal to 2 ## 95 percent confidence interval: ## 2.52384 3.08576 ## sample estimates: ## mean of x ## 2.8048 (Como los parámetros alternative=&quot;two.sided&quot; y conf.level=0.95 eran los que toma R por defecto, en realidad no hacía falta especificarlos.) Observad la información que obtenemos con esta instrucción: Información sobre la muestra \\(x\\): su media muestral (mean of x) \\(\\overline{x}\\), que vale 2.8048. La hipótesis alternativa (alternative hypothesis), en este caso true mean is not equal to 2: la media verdadera, o poblacional, \\(\\mu\\) es diferente de 2. El valor t que toma el estadístico de contraste, \\(T=\\frac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\), sobre la muestra, en este caso 5.912, y los grados de libertad df (degrees of freedom) de su distribución t de Student cuando la hipótesis nula es verdadera, df =24. El p-valor (p-value) de nuestro test, en este caso p-value = 4.232e-06, es decir, \\(4.232\\times 10^{-6}\\). Un intervalo de confianza del \\((1-\\alpha)\\times 100\\%\\) (en nuestro caso, 95 percent confidence interval) para la \\(\\mu\\): en este ejemplo, [2.523844, 3.085756]. Lo único que no nos dice directamente es si tenemos que rechazar o no la hipótesis nula, pero esto lo deducimos del p-valor: como es más pequeño que el nivel de significación (de hecho, es muy pequeño), podemos rechazar la hipótesis nula, \\(\\mu=2\\), en favor de la alternativa, \\(\\mu \\neq 2\\). Es decir, hay evidencia estadísticamente significativa de que \\(\\mu \\neq 2\\). Otra manera de decidir si rechazamos o no la hipótesis nula es mirar si el valor que contrastamos pertenece al intervalo de confianza del contraste. Puesto que \\(2 \\notin [2.523844, 3.085756]\\), podemos rechazar la hipótesis nula en favor de la alternativa y concluir que \\(\\mu\\neq 2\\). Hagamos ahora el test cambiando la hipótesis alternativa por \\(H_{1}:\\mu&lt; 3\\), es decir, \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=3\\\\ H_{1}:\\mu&lt; 3 \\end{array}\\right. \\] y tomando como nivel de significación \\(\\alpha=0.1\\): t.test(x, mu=3, alternative=&quot;less&quot;, conf.level=0.9) ## ## One Sample t-test ## ## data: x ## t = -1.434, df = 24, p-value = 0.0822 ## alternative hypothesis: true mean is less than 3 ## 90 percent confidence interval: ## -Inf 2.9842 ## sample estimates: ## mean of x ## 2.8048 En este caso, el p-valor es 0.082, por lo que podemos rechazar la hipótesis nula con un nivel de significación del 10% y concluir, con este nivel de significación (es decir, asumiendo esta probabilidad de equivocarnos), que \\(\\mu&lt;3\\); pero fijaos en que con un nivel de significación del 5% no podríamos rechazar la hipótesis nula. El intervalo de confianza del 90% es ahora \\((-\\infty,2.984]\\) (Inf representa \\(\\infty\\)). Que no contenga el 3 (aunque por muy poco) también indica que podemos rechazar la hipótesis nula \\(\\mu=3\\) en favor de la alternativa \\(\\mu&lt; 3\\) con este nivel de confianza. El p-valor y el intervalo de confianza se pueden obtener directamente, añadiendo a la instrucción t.test los sufijos $p.value o $conf.int, respectivamente. Esperamos que recordéis que en la lección anterior ya usábamos la construcción t.test(...)$conf.int para calcular un intervalo de confianza para la media usando la fórmula basada en la t de Student. Es lo correcto, puesto que el intervalo de confianza de un test t bilateral es el que explicamos entonces y no depende para nada de la hipótesis nula (por eso no especificábamos la \\(\\mu\\), y dejábamos que la función tomase su valor por defecto, 0). Pero ahora podemos calcular dos intervalos de confianza más, correspondientes a los dos tipos de contrastes unilaterales. En ellos toda la “probabilidad de equivocarnos” se concentra a un lado del intervalo de confianza, en lugar de repartirse por igual a ambos lados. t.test(x, mu=2)$p.value ## [1] 4.23159e-06 t.test(x, mu=2)$conf.int ## [1] 2.52384 3.08576 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 t.test(x, mu=2)$conf.int[1] ## [1] 2.52384 t.test(x, mu=2)$conf.int[2] ## [1] 3.08576 t.test(x, mu=3, alternative=&quot;less&quot;, conf.level=0.9)$conf.int ## [1] -Inf 2.9842 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 Podéis consultar los sufijos necesarios para obtener las otras componentes del resultado en la Ayuda de la función. Ejemplo 5.3 Queremos contrastar si el valor medio del nivel de colesterol en una población es de 220 mg/dl o no, a un nivel de significación del 5%. Es decir, si llamamos \\(\\mu\\) a la media de la variable aleatoria “Nivel de colesterol de un individuo de esta población, en mg/dl”, queremos realizar el contraste bilateral \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=220\\\\ H_{1}:\\mu \\neq 220 \\end{array}\\right. \\] Para ello, hemos tomado una muestra del nivel de colesterol en plasma de 9 individuos de la población. Los datos obtenidos, en mg/dl, son los siguientes: colesterol=c(203,229,215,220,223,233,208,228,209) Suponemos que el nivel de colesterol en plasma sigue una ley normal y que por lo tanto nos podemos fiar del resultado de un test t: t.test(colesterol, mu=220) ## ## One Sample t-test ## ## data: colesterol ## t = -0.3801, df = 8, p-value = 0.714 ## alternative hypothesis: true mean is not equal to 220 ## 95 percent confidence interval: ## 210.577 226.756 ## sample estimates: ## mean of x ## 218.667 El p-valor es 0.714, muy grande y en particular superior a 0.05, por lo tanto no podemos rechazar la hipótesis nula de que el valor medio sea 220 mg/dl. Además, el intervalo de confianza del 95% del contraste es [210.58, 226.76], y contiene holgadamente el valor 220. Más adelante en esta misma sección discutiremos qué podemos hacer si el nivel de colesterol en plasma no sigue una ley aproximadamente normal, en cuyo caso el resultado de este test t no sirve para nada. Ejemplo 5.4 Recordad el dataframe iris, que recoge datos de las flores de 50 ejemplares de cada una de tres especies de iris. str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Queremos estudiar si la longitud media \\(\\mu_v\\) de los sépalos de las Iris virginica es mayor que la longitud media \\(\\mu_s\\) de los sépalos de las Iris setosa usando las muestras contenidas en esta tabla de datos. Para ello realizamos el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_s=\\mu_v\\\\ H_{1}:\\mu_s&lt; \\mu_v \\end{array}\\right. \\] En este caso, se trata de un contraste de dos muestras independientes, y como las muestras son grandes, podemos usar con garantías un test t. Ahora bien, recordad que el test t concreto que hay que usar depende de si las varianzas de las dos variables cuyas medias comparamos son iguales o diferentes. Como no sabemos nada de las varianzas de las longitudes de los sépalos de estas dos especies, y no nos supone apenas esfuerzo realizar los tests, llevaremos a cabo el contraste en los dos casos: varianzas iguales y varianzas diferentes.1 Más adelante, en el Ejemplo 5.11, explicamos cómo contrastar si estas dos varianzas son iguales o diferentes. S=iris[iris$Species==&quot;setosa&quot;,]$Sepal.Length V=iris[iris$Species==&quot;virginica&quot;,]$Sepal.Length El test suponiendo que las dos varianzas son iguales: t.test(S, V, alternative=&quot;less&quot;, var.equal=TRUE) ## ## Two Sample t-test ## ## data: S and V ## t = -15.39, df = 98, p-value &lt;2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -1.41126 ## sample estimates: ## mean of x mean of y ## 5.006 6.588 El test suponiendo que las dos varianzas son diferentes: t.test(S, V, alternative=&quot;less&quot;, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: S and V ## t = -15.39, df = 76.52, p-value &lt;2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -1.4108 ## sample estimates: ## mean of x mean of y ## 5.006 6.588 En los dos casos el p-valor es prácticamente 0 y por lo tanto podemos rechazar la hipótesis nula en favor de la alternativa: tenemos evidencia estadísticamente muy significativa de que, en promedio, las flores de la especie setosa tienen sépalos más cortos que las de la especie virginica. El intervalo de confianza del 95% para la diferencia de medias \\(\\mu_s-\\mu_v\\) en este contraste es en ambos casos \\((-\\infty, -1.41]\\) y no contiene el 0, que sería el valor de esta diferencia si la hipótesis nula \\(\\mu_s=\\mu_v\\) fuera verdad. Ejemplo 5.5 En un experimento clásico de la primera década del siglo XX, Student quiso comparar el efecto somnífero de dos compuestos químicos, la hiosciamina y la hioscina. La hipótesis a contrastar era que la hioscina es más efectiva que la hiosciamina. Para ello, tomó 10 sujetos y midió su promedio de horas de sueño durante períodos de entre 3 y 9 días bajo tres tratamientos: en condiciones normales, tomando antes de acostarse 0.6 mg de hiosciamina y tomando antes de acostarse 0.6 mg de hioscina. A continuación, calculó para cada sujeto y cada compuesto la diferencia “promedio de horas de sueño tomando el compuesto menos promedio de horas de sueño en condiciones normales”. Las diferencias que obtuvo fueron las siguientes (las podéis encontrar en el dataframe sleep de la instalación básica de R, aunque no lo vamos a usar): Sujeto Hiosciamina Hioscina 1 0.7 1.9 2 -1.6 0.8 3 -0.2 1.1 4 -1.2 0.1 5 -0.1 -0.1 6 3.4 4.4 7 3.7 5.5 8 0.8 1.6 9 0.0 4.6 10 2.0 3.4 Una manera de comparar el efecto en las horas de sueño de estos compuestos es comparando las medias de estas diferencias de promedios de horas de sueño: una diferencia media mayor significa que, de media, el compuesto “ha añadido” más horas de sueño al promedio normal. Digamos \\(\\mu_1\\) a la media de las diferencias individuales del promedio de horas de sueño tomando hiosciamina menos el promedio en condiciones normales y \\(\\mu_2\\) a la media de las diferencias individuales del promedio de horas de sueño tomando hioscina menos el promedio en condiciones normales. Tomaremos como hipótesis nula \\(H_0: \\mu_1= \\mu_2\\) (ambos compuestos tienen el mismo efecto medio sobre las horas de sueño de los individuos) e hipótesis alternativa \\(H_1: \\mu_1&lt;\\mu_2\\) (la hioscina aumenta más las horas de sueño que la hiosciamina). Si podemos rechazar la hipótesis nula en favor de la alternativa, concluiremos que la hioscina tiene un mayor efecto somnífero que la hiosciamina. Observad que se trata de un contraste de dos muestras emparejadas, porque los datos refieren a los mismos 10 pacientes. Vamos a suponer que las diferencias medias en horas de sueño en ambos casos siguen leyes normales (Student así lo hizo) y que, por lo tanto, el resultado de un test t es fiable. Hiosciamina=c(0.7,-1.6,-0.2,-1.2,-0.1,3.4,3.7,0.8,0,2.0) Hioscina=c(1.9,0.8,1.1,0.1,-0.1,4.4,5.5,1.6,4.6,3.4) t.test(Hiosciamina, Hioscina, alternative=&quot;less&quot;, paired=TRUE) ## ## Paired t-test ## ## data: Hiosciamina and Hioscina ## t = -4.062, df = 9, p-value = 0.00142 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.866995 ## sample estimates: ## mean of the differences ## -1.58 El p-valor es 0.001, mucho menor que 0.05, y por lo tanto podemos rechazar la hipótesis nula con un nivel de significación del 5%. Observad también que el intervalo de confianza del 95% para la diferencia de medias \\(\\mu_1-\\mu_2\\) es \\((-\\infty,-0.867]\\) y está totalmente a la izquierda del 0. La conclusión es, pues, que efectivamente la hioscina tiene un mayor efecto somnífero que la hiosciamina y que con un 95% de confianza podemos afirmar que añade, de media, como mínimo 52 minutos (-0.867 horas) diarios más de sueño. Ejemplo 5.6 Veamos un ejemplo de aplicación de t.test a una fórmula. Queremos contrastar si es cierto que fumar durante el embarazo está asociado a un peso menor del recién nacido. Si llamamos \\(\\mu_n\\) y \\(\\mu_f\\) al peso medio de un recién nacido de madre no fumadora y fumadora, respectivamente, el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_n=\\mu_f\\\\ H_{1}:\\mu_n&gt; \\mu_f \\end{array}\\right. \\] Vamos a usar los datos incluidos en la tabla birthwt incluida en el paquete MASS, que recoge información sobre una muestra de madres y sus hijos. library(MASS) str(birthwt) ## &#39;data.frame&#39;: 189 obs. of 10 variables: ## $ low : int 0 0 0 0 0 0 0 0 0 0 ... ## $ age : int 19 33 20 21 18 21 22 17 29 26 ... ## $ lwt : int 182 155 105 108 107 124 118 103 123 113 ... ## $ race : int 2 3 1 1 1 3 1 3 1 1 ... ## $ smoke: int 0 0 1 1 1 0 0 0 1 1 ... ## $ ptl : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ht : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ui : int 1 0 0 1 1 0 0 0 0 0 ... ## $ ftv : int 0 3 1 2 0 0 1 1 1 0 ... ## $ bwt : int 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ... En la Ayuda de birthwt nos enteramos de que la variable smoke indica si la madre ha fumado durante el embarazo (1) o no (0), y que la variable bwt da el peso del recién nacido en gramos. Lo primero que haremos será mirar si las muestras de madres fumadoras y no fumadoras contenidas en esta tabla son lo suficientemente grandes como para que el resultado del test t sea fiable. table(birthwt$smoke) ## ## 0 1 ## 115 74 Vemos que sí, que ambas son suficientemente grandes. Para entrar en la instrucción t.test los vectores de pesos de hijos de fumadoras y no fumadoras, usaremos la fórmula bwt~smoke especificando que data=birthwt. Fijaos en que los valores de smoke son 0 y 1, y que R los considera ordenados en este orden (basta ver el resultado de la función table anterior). Por consiguiente, bwt~smoke representa, en este orden, el vector de pesos de recién nacidos de madres no fumadoras (smoke=0) y el vector de pesos de recién nacidos de madres fumadoras (smoke=1). Como la hipótesis alternativa es \\(\\mu_n&gt;\\mu_f\\), deberemos especificar en la función t.test que alternative=&quot;greater&quot;. Es un contraste de muestras independientes, y por lo tanto el procedimiento para llevarlo a cabo depende de la igualdad o no de las varianzas de los pesos de los recién nacidos en los dos grupos de madres. Como en el Ejemplo 5.4, vamos a llevar a cabo el test t suponiendo que estas varianzas son iguales y que son diferentes, y cruzaremos los dedos para que la conclusión sea la misma. Otra posibilidad es contrastar antes la igualdad de las varianzas. t.test(bwt~smoke, data=birthwt, alternative=&quot;greater&quot;, paired=FALSE, var.equal=TRUE) ## ## Two Sample t-test ## ## data: bwt by smoke ## t = 2.653, df = 187, p-value = 0.00433 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 106.953 Inf ## sample estimates: ## mean in group 0 mean in group 1 ## 3055.70 2771.92 t.test(bwt~smoke, data=birthwt, alternative=&quot;greater&quot;, paired=FALSE, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: bwt by smoke ## t = 2.73, df = 170.1, p-value = 0.0035 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 111.855 Inf ## sample estimates: ## mean in group 0 mean in group 1 ## 3055.70 2771.92 En ambos casos hemos obtenido un p-valor un orden de magnitud inferior a 0.05, lo que nos permite concluir que, en efecto, los hijos de las madres no fumadoras pesan más al nacer que los de las fumadoras. En vez de especificar los vectores de pesos con bwt~smoke,data=birthwt, hubiéramos podido usar birthwt$bwt~birthwt$smoke. Por ejemplo: t.test(birthwt$bwt~birthwt$smoke, alternative=&quot;greater&quot;, paired=FALSE, var.equal=TRUE) ## ## Two Sample t-test ## ## data: birthwt$bwt by birthwt$smoke ## t = 2.653, df = 187, p-value = 0.00433 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 106.953 Inf ## sample estimates: ## mean in group 0 mean in group 1 ## 3055.70 2771.92 Tests no paramétricos Cuando comparamos dos medias, o una media con un valor, usando un test t sobre muestras pequeñas, suponemos que las variables poblacionales que han producido las muestras son normales. En la Lección ?? estudiaremos los contrastes que nos permiten aceptar o rechazar que una muestra provenga de una variable aleatoria con una distribución concreta, pero en estos momentos ya tendría que ser claro que nos podemos encontrar con conjuntos de datos para los cuales el supuesto de normalidad de la variable poblacional no esté justificado: por ejemplo, porque sean datos cuantitativos discretos o porque la variable sea claramente muy asimétrica (por citar una, la duración del embarazo, con una clara cola a la izquierda: hay un número no despreciable de partos prematuros, pero ningún embarazo dura 11 meses). En las situaciones en las que no estamos seguros de que las variables poblacionales satisfagan aproximadamente las hipótesis de los teoremas que nos garantizan la fiabilidad de las conclusiones de un contraste, por ejemplo de un test t, una salida razonable es usar un test no paramétrico alternativo. En el caso de los contrastes de medias, los tests no paramétricos para comparar medias en realidad lo que comparan son las medianas. Los más populares son los siguientes: El test de signos, que permite contrastar si la mediana de una variable aleatoria cualquiera (incluso ordinal) es un valor dado \\(M_0\\) estudiando la distribución de los signos de las diferencias entre este valor y los de una muestra (si la mediana fuera \\(M_0\\), los números de diferencias positivas y negativas en muestras aleatorias seguirían distribuciones binomiales con \\(p=0.5\\)). En R está implementado en la función SIGN.test del paquete BSDA. Su sintaxis es similar a la de t.test para una muestra, cambiando el parámetro mu, que en t.test sirve para especificar el valor de la media que contrastamos, por md, que en SIGN.test sirve para especificar el valor de la mediana que contrastamos. Esta función también se puede aplicar a dos muestras emparejadas: en este caso, la hipótesis nula del contraste que realiza es que “la mediana de las diferencias de las dos variables es 0”. El test de Wilcoxon para comparar la media de una variable continua simétrica con un valor dado o las medias de dos variables continuas cuya diferencia sea simétrica por medio de muestras emparejadas. Más en general, se puede usar para comparar la mediana de una variable continua con un valor dado o para comparar la mediana de la diferencia de dos variables continuas (medidas sobre muestras emparejadas) con 0. Observad que cuando las variables en juego son simétricas, las medianas coinciden con las medias y el contraste de medianas es también un contraste de medias. En R está implementado en la función wilcox.test y su sintaxis es la misma que la de t.test para una muestra o para dos muestras emparejadas (en este último caso, hay que especificar paired=TRUE). El test de Mann-Whitney para comparar las medianas de dos variables aleatorias por medio de muestras independientes. En R también está implementado en la función wilcox.test y su sintaxis es la misma que la de t.test para dos muestras independientes (especificando paired=FALSE), salvo que aquí no hay que especificar si las varianzas son iguales o diferentes, puesto que esto no se usa en este test. Ejemplo 5.7 Si los niveles de colesterol no siguen una distribución normal, el test t realizado en el Ejemplo 5.3 no sirve para nada. Una posibilidad es entonces no contrastar si el nivel medio de colesterol es 220, sino si el nivel mediano es 220. Para ello vamos realizar un test de signos. Los parámetros alternative=&quot;two.sided&quot; y conf.level=0.95 son los que usa la función SIGN.test por defecto, así que no haría falta especificarlos; los incluimos para que los veáis. library(BSDA) SIGN.test(colesterol, md=220, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## One-sample Sign-Test ## ## data: colesterol ## s = 4, p-value = 1 ## alternative hypothesis: true median is not equal to 220 ## 95 percent confidence interval: ## 208.078 228.922 ## sample estimates: ## median of x ## 220 ## ## Achieved and Interpolated Confidence Intervals: ## ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.8203 209.000 228.000 ## Interpolated CI 0.9500 208.078 228.922 ## Upper Achieved CI 0.9609 208.000 229.000 Observad que la salida de la función es muy similar a la de t.test (salvo por los últimos intervalos de confianza, que no vamos a explicar). El p-valor ha dado directamente 1 y el intervalo de confianza al 95% para la mediana ha dado [208.1, 228.9]: por lo tanto, no podemos rechazar que la mediana del nivel de colesterol en la población de la que hemos extraído la muestra sea 220. También podríamos usar el test de Wilcoxon para realizar este contraste de una mediana: wilcox.test(colesterol, mu=220, alternative=&quot;two.sided&quot;,conf.level=0.95) ## Warning in wilcox.test.default(colesterol, mu = 220, alternative = ## &quot;two.sided&quot;, : cannot compute exact p-value with zeroes ## ## Wilcoxon signed rank test with continuity correction ## ## data: colesterol ## V = 15, p-value = 0.726 ## alternative hypothesis: true location is not equal to 220 El p-valor es 0.726, la conclusión es la misma. El mensaje de advertencia nos avisa de que la muestra ha contenido valores iguales al valor de la mediana contrastado, por lo que el p-valor obtenido no es exacto. Solo os tenéis que preocupar de un mensaje como este si el p-valor fuera muy cercano al nivel de significación deseado, que no es el caso. Ejemplo 5.8 Si las diferencias en promedios de horas de sueño no siguen distribuciones normales, el test t realizado en el Ejemplo 5.5 no sirve para nada. En este caso, vamos a usar un test de Wilcoxon para muestras emparejadas. Este test en realidad contrastará la hipótesis nula de que si para cada individuo calculamos la diferencia entre el aumento promedio de horas de sueño cuando toma hiosciamina y el aumento promedio tomando hioscina, la mediana de la variable aleatoria que define estas diferencias es 0, y como hipótesis alternativa que esta mediana es menor que 0 (y que por lo tanto más de la mitad de las veces es negativa, es decir, que a más de la mitad de la población la hioscina le añade más tiempo promedio de sueño que la hiosciamina). Si las variables “aumento de horas de sueño” en juego son simétricas, estas medianas coinciden con las correspondientes medias y llevamos a cabo el contraste del Ejemplo 5.5. Si no son simétricas, igualmente estamos contrastando si la hioscina es más efectiva que la hiosciamina, solo que planteándolo de otra manera. wilcox.test(Hiosciamina, Hioscina, alternative=&quot;less&quot;, paired=TRUE) ## Warning in wilcox.test.default(Hiosciamina, Hioscina, alternative = ## &quot;less&quot;, : cannot compute exact p-value with ties ## Warning in wilcox.test.default(Hiosciamina, Hioscina, alternative = ## &quot;less&quot;, : cannot compute exact p-value with zeroes ## ## Wilcoxon signed rank test with continuity correction ## ## data: Hiosciamina and Hioscina ## V = 0, p-value = 0.00455 ## alternative hypothesis: true location shift is less than 0 En este caso R nos avisa de nuevo de que el p-valor no es exacto, pero esto no afecta a la conclusión dado que el p-valor es muy pequeño: rechazamos la hipótesis nula en favor de la alternativa y también concluimos con este test no paramétrico que la hioscina tiene un mayor efecto somnífero que la hiosciamina. Ejemplo 5.9 Nos preguntamos si los hijos de madres de 20 años pesan lo mismo al nacer que los de madres de 30 años, o no. Querríamos responder esta pregunta planteándola como un contraste bilateral de los pesos medios de los hijos de madres de 20 y 30 años y usando la muestra recogida en la tabla de datos birthwt del paquete MASS, que contiene la variable age con la edad de las madres. hijos.20=birthwt[birthwt$age==20,&quot;bwt&quot;] hijos.30=birthwt[birthwt$age==30,&quot;bwt&quot;] c(length(hijos.20),length(hijos.30)) ## [1] 18 7 Las muestras no son lo suficientemente grandes como para usar un test t si no estamos seguros de que las variables poblacionales sean normales. Como las muestras son independientes, vamos a usar un test de Mann-Whitney para comparar los pesos medianos. Es decir, en vez de traducir “los hijos de madres de 20 años pesan lo mismo al nacer que los de madres de 30 años” en términos de igualdad de pesos medios, lo traducimos en términos de igualdad de pesos medianos. (En realidad, la hipótesis nula de este test es que “Es igual de probable que un hijo de madre de 20 años pese más que un hijo de madre de 30 años que al revés”, pero no vamos a entrar en este nivel de precisión. Es otra manera de decir que no hay tendencia a que unos pesen más que los otros.) wilcox.test(hijos.20, hijos.30, alternative=&quot;two.sided&quot;,paired=FALSE) ## Warning in wilcox.test.default(hijos.20, hijos.30, alternative = ## &quot;two.sided&quot;, : cannot compute exact p-value with ties ## ## Wilcoxon rank sum test with continuity correction ## ## data: hijos.20 and hijos.30 ## W = 43.5, p-value = 0.25 ## alternative hypothesis: true location shift is not equal to 0 El p-valor es 0.25, por lo que no podemos rechazar que las medianas de los pesos al nacer de los hijos de madres de 20 años y de 30 sean iguales. 5.2 Contrastes para varianzas El test \\(\\chi^2\\) para comparar la varianza \\(\\sigma^2\\) (o la desviación típica \\(\\sigma\\)) de una población normal con un valor dado \\(\\sigma_0^2\\) (o \\(\\sigma_0\\)) usa el estadístico \\[ \\frac{(n-1)\\widetilde{S}_X^2}{\\sigma_0^2} \\] que, si la hipótesis nula \\(\\sigma^2=\\sigma_0^2\\) es verdadera, sigue una distribución \\(\\chi^2_{n-1}\\), de ahí su nombre. Dicho test está convenientemente implementado en la función sigma.test del paquete TeachingDemos. Su sintaxis es la misma que la de la función t.test para una muestra, substituyendo el parámetro mu de t.test por el parámetro sigma (para especificar el valor de la desviación típica que contrastamos, \\(\\sigma_0\\)) o sigmasq (por “sigma al cuadrado”, para especificar el valor de la varianza que contrastamos, \\(\\sigma_0^2\\)). Como siempre, los valores por defecto de alternative y conf.level son &quot;two.sided&quot; y 0.95, respectivamente. La salida de la función es también similar a la de t.test. Veamos un ejemplo. Ejemplo 5.10 Se ha realizado un experimento para estudiar el tiempo \\(X\\) (en minutos) que tarda un lagarto del desierto en llegar a los 45o partiendo de su temperatura normal mientras está a la sombra. Los tiempos obtenidos (en minutos) en una muestra aleatoria de lagartos fueron los siguientes: TL45=c(10.1,12.5,12.2,10.2,12.8,12.1,11.2,11.4,10.7,14.9,13.9,13.3) Supongamos que estos tiempos siguen una ley normal. ¿Aporta este experimento evidencia de que la desviación típica \\(\\sigma\\) de \\(X\\) es inferior a 1.5 minutos? Para responder esta pregunta, hemos de realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma= 1.5 \\\\ H_{1}:\\sigma&lt; 1.5 \\end{array}\\right. \\] Para ello, usaremos la función sigma.test aplicada a esta muestra y a sigma=1.5: library(TeachingDemos) sigma.test(TL45, sigma=1.5, alternative=&quot;less&quot;) ## ## One sample Chi-squared test for variance ## ## data: TL45 ## X-squared = 10.69, df = 11, p-value = 0.53 ## alternative hypothesis: true variance is less than 2.25 ## 95 percent confidence interval: ## 0.00000 5.25686 ## sample estimates: ## var of TL45 ## 2.18629 El p-valor que obtenemos es 0.53, muy grande, por lo que no tenemos evidencia que nos permita concluir que \\(\\sigma&lt;1.5\\). ¡Atención! El intervalo de confianza que da la función sigma.test es siempre para la varianza, aunque le entréis el valor de la desviación típica. Así que si queréis un intervalo de confianza para la desviación típica, tenéis que tomar la raíz cuadrada del que os da sigma.test: sqrt(sigma.test(TL45, sigma=1.5, alternative=&quot;less&quot;)$conf.int) ## [1] 0.00000 2.29279 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 El test \\(\\chi^2\\) no se usa mucho en la práctica. En parte, porque realmente es poco interesante ya que suele ser difícil conjeturar la desviación típica a contrastar, y en parte porque su validez depende fuertemente de la hipótesis de que la variable aleatoria poblacional sea normal. En cambio, el contraste de las desviaciones típicas de dos poblaciones sí que es muy utilizado. Por ejemplo, en un contraste de dos medias usando un test t sobre dos muestras independientes, nos puede interesar conocer a priori si las varianzas poblacionales son iguales o diferentes, en lugar de realizar el test bajo ambas suposiciones. Si no las conocemos, ¿cómo podemos saber cuál es el caso? Si las dos variables poblacionales son normales, podemos contrastar la igualdad de las varianzas con el test F, basado en el estadístico \\[ \\frac{\\widetilde{S}_{X_1}^2} {\\widetilde{S}_{X_2}^2} \\] que, si las dos poblaciones son normales y tienen la misma varianza, sigue una distribución F de Fisher-Snedecor. Por desgracia, este test es también muy sensible a la no normalidad de las poblaciones objeto de estudio: a la que una de ellas se aleja un poco de la normalidad, el test deja de dar resultados fiables.2 La función para efectuar este test es var.test y su sintaxis básica es la misma que la de t.test para dos muestras: var.test(x, y, alternative=..., conf.level=...) donde x e y son los dos vectores de datos, que se pueden especificar mediante una fórmula como en el caso de t.test, y el parámetro alternative puede tomar los tres mismos valores que en los tests anteriores: su valor por defecto es, como siempre, &quot;two.sided&quot;, que es el que nos permite contrastar si las varianzas son iguales o diferentes. Ejemplo 5.11 Suponiendo que las longitudes de los sépalos de las flores de las diferentes especies de iris siguen leyes normales, ¿hubiéramos podido considerar a priori iguales las varianzas de las dos muestras en el Ejemplo 5.4? Veamos: S=iris[iris$Species==&quot;setosa&quot;,]$Sepal.Length V=iris[iris$Species==&quot;virginica&quot;,]$Sepal.Length var.test(S,V) ## ## F test to compare two variances ## ## data: S and V ## F = 0.3073, num df = 49, denom df = 49, p-value = 6.37e-05 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.174378 0.541496 ## sample estimates: ## ratio of variances ## 0.307286 El p-valor es \\(6.4\\times 10^{-5}\\), muy pequeño. Por lo tanto, podemos rechazar la hipótesis nula de que las dos varianzas son iguales, en favor de la hipótesis alternativa de que las dos varianzas son diferentes. Así, pues, bastaba realizar solo el t.test con var.equal=FALSE. Puede ser conveniente remarcar aquí que el intervalo de confianza obtenido con var.test es para el cociente de varianzas poblacionales \\(\\sigma^2_x/\\sigma^2_y\\), no para su diferencia. Por lo tanto, para contrastar si las varianzas son iguales o diferentes, hay que mirar si el 1 pertenece o no al intervalo obtenido. En este ejemplo, el intervalo de confianza al 95% ha sido [0.174, 0.541] y no contiene el 1, lo que confirma la evidencia de que las varianzas son diferentes. Ejemplo 5.12 Queremos contrastar si los gatos adultos macho pesan más que los gatos adultos hembra. Para ello usaremos los datos recogidos en el dataframe cats del paquete MASS, que contiene información sobre el peso de una muestra de gatos adultos, separados por su sexo. str(cats) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ Sex: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Bwt: num 2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ... ## $ Hwt: num 7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ... table(cats$Sex) ## ## F M ## 47 97 Consultando la Ayuda de cats nos enteramos de que la variable Bwt contiene el peso de cada gato en kg, y la variable Sex contiene el sexo de cada gato: F para hembra (female) y M para macho (male). Como vemos en la tabla de frecuencias, los números de ejemplares de cada sexo son grandes. Así pues, si llamamos \\(\\mu_m\\) al peso medio de un gato macho adulto y \\(\\mu_h\\) al peso medio de un gato hembra adulto, el contraste que vamos a realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&gt;\\mu_h \\end{array}\\right. \\] y para ello antes vamos a contrastar si las varianzas de ambas poblaciones son iguales o diferentes, para luego poder aplicar la función t.test con el valor de var.equal adecuado. Vamos a suponer que los pesos en ambos sexos siguen leyes normales. Para que el contraste de las varianzas sea fiable es necesario que esta suposición sea cierta; para el de los pesos medios, no, ya que ambas muestras son grandes. El contraste de la igualdad de varianzas es el siguiente: var.test(Bwt~Sex, data=cats) ## ## F test to compare two variances ## ## data: Bwt by Sex ## F = 0.3435, num df = 46, denom df = 96, p-value = 0.000116 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.212628 0.580348 ## sample estimates: ## ratio of variances ## 0.343501 El p-valor es \\(1.2\\times 10^{-4}\\), y por lo tanto podemos rechazar la hipótesis nula de que las varianzas son iguales y concluir que son diferentes. Así que en el test t las consideraremos diferentes. Recordemos ahora que la hipótesis alternativa que queremos contrastar es \\(H_{1}:\\mu_m&gt;\\mu_h\\). En el factor cats$Sex, la F (hembra) va antes que la M (macho), y, por tanto, si entramos los vectores de pesos mediante Bwt~Sex,data=cats, el primer vector corresponderá a las gatas y el segundo a los gatos. Así pues, la hipótesis alternativa que tenemos que especificar es que la media del primer vector es inferior a la del segundo vector: alternative=&quot;less&quot;. t.test(Bwt~Sex, data=cats, alternative=&quot;less&quot;,var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: Bwt by Sex ## t = -8.709, df = 136.8, p-value = 4.42e-15 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.437666 ## sample estimates: ## mean in group F mean in group M ## 2.35957 2.90000 Como el p-valor es prácticamente 0, podemos concluir que, efectivamente, de media, los gatos adultos pesan más que las gatas adultas. Hemos insistido en que el test F solo es válido si las dos poblaciones cuyas varianzas comparamos son normales. ¿Qué podemos hacer si dudamos de su normalidad? Usar un test no paramétrico que no presuponga esta hipótesis. Hay diversos tests no paramétricos para realizar contrastes bilaterales de dos varianzas. Aquí os recomendamos el test de Fligner-Killeen, implementado en la función fligner.test. Se aplica o bien a una list formada por las dos muestras, o bien a una fórmula que separe un vector numérico en dos muestras por medio de un factor de dos niveles. Ejemplo 5.13 Si queremos contrastar si las varianzas de las longitudes de los sépalos de las flores iris setosa y virginica son iguales o no sin presuponer que siguen leyes normales, podemos usar el test de Fligner-Killeen de la manera siguiente: fligner.test(list(S,V)) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: list(S, V) ## Fligner-Killeen:med chi-squared = 9.984, df = 1, p-value = 0.00158 El p-valor es 0.0016, por lo que podemos concluir que las varianzas son diferentes. Ejemplo 5.14 Si queremos contrastar si las varianzas de los pesos de los gatos y las gatas adultos son iguales o no sin presuponer que dichos pesos tienen distribuciones normales, podemos usar el test de Fligner-Killeen de la manera siguiente: fligner.test(Bwt~Sex, data=cats) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: Bwt by Sex ## Fligner-Killeen:med chi-squared = 16.91, df = 1, p-value = ## 3.92e-05 El p-valor es \\(4\\times 10^{-5}\\), por lo que podemos concluir que las varianzas son diferentes. 5.3 Contrastes para proporciones Cuando tenemos que efectuar un contraste sobre una probabilidad de éxito \\(p\\) de una variable Bernoulli, podemos emplear el test binomial exacto. Este test se basa en que, si la hipótesis nula \\(H_0: p=p_0\\) es verdadera, los números de éxitos en muestras aleatorias simples de tamaño \\(n\\) de la variable poblacional, que será de tipo \\(Be(p_0)\\), siguen una ley binomial \\(B(n,p_0)\\). Este test está implementado en la función binom.test, cuya sintaxis es binom.test(x, n, p=..., alternative=..., conf.level=...) donde x y n son números naturales: el número de éxitos y el tamaño de la muestra. p es la probabilidad de éxito que queremos contrastar. El significado de alternative y conf.level, y sus posibles valores, son los usuales. Fijaos en particular que binom.test no se aplica directamente al vector de una muestra, sino a su número de éxitos y a su longitud. Si la muestra es un vector binario X, el número de éxitos será sum(X) y la longitud length(X). Nota. El intervalo de confianza para la \\(p\\) que da binom.test en un contraste bilateral es el de Clopper-Pearson. Ejemplo 5.15 Recordemos el Ejemplo 5.1, donde, en una serie de 20 lanzamientos de una moneda, había obtenido 15 caras. ¿Podemos sospechar que la moneda está trucada a favor de cara? Como comentamos en ese ejemplo, si llamamos \\(p\\) a la probabilidad de obtener cara con esta moneda, el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:p=0.5\\\\ H_{1}:p&gt; 0.5 \\end{array}\\right. \\] Usaremos la función binom.test: binom.test(15,20, p=0.5, alternative=&quot;greater&quot;) ## ## Exact binomial test ## ## data: 15 and 20 ## number of successes = 15, number of trials = 20, p-value = 0.0207 ## alternative hypothesis: true probability of success is greater than 0.5 ## 95 percent confidence interval: ## 0.544418 1.000000 ## sample estimates: ## probability of success ## 0.75 El p-valor del test es 0.0207 y el intervalo de confianza que nos da este test para la \\(p\\) es [0.5444, 1]. Ambos valores coinciden con los dados en el ejemplo original Cuando la muestra es grande, pongamos de 40 o más sujetos, podemos usar también el test aproximado, basado en la aproximación de la distribución de la proporción muestral por medio de una normal dada por el Teorema Central del Límite. En R está implementado en la función prop.test, que además también sirve para contrastar dos proporciones por medio de muestras independientes grandes. Su sintaxis es prop.test(x, n, p =..., alternative=..., conf.level=...) donde: x puede ser dos cosas: Un número natural: en este caso, R entiende que es el número de éxitos en una muestra. Un vector de dos números naturales: en este caso, R entiende que es un contraste de dos proporciones y que estos son los números de éxitos en las muestras. Cuando trabajamos con una sola muestra, n es su tamaño. Cuando estamos trabajando con dos muestras, n es el vector de dos entradas de sus tamaños. Cuando trabajamos con una sola muestra, p es la proporción poblacional que contrastamos. En el caso de un contraste de dos muestras, no hay que especificarlo. El significado de alternative y conf.level, y sus posibles valores, son los usuales. Veamos algunos ejemplos más. Ejemplo 5.16 Queremos contrastar si la proporción de estudiantes zurdos en la UIB es diferente del 10%, el porcentaje estimado de zurdos en España. Es decir, si llamamos \\(p\\) a la proporción de estudiantes zurdos en la UIB, queremos realizar el contraste \\[ \\left\\{ \\begin{array}{l} H_0:p=0.1\\\\ H_1:p\\neq 0.1 \\end{array} \\right. \\] Para ello, tomamos una muestra de 50 estudiantes de la UIB encuestados al azar y resulta que 3 son zurdos. Vamos a suponer que forman una muestra aleatoria simple. Como la muestra es grande (\\(n=50\\)) usaremos la función prop.test. prop.test(3, 50, p=0.1) ## ## 1-sample proportions test with continuity correction ## ## data: 3 out of 50, null probability 0.1 ## X-squared = 0.5, df = 1, p-value = 0.48 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.0156246 0.1754187 ## sample estimates: ## p ## 0.06 El p-valor obtenido en el test es 0.48, muy superior a 0.05. Por lo tanto, no podemos rechazar que un 10% de los estudiantes de la UIB sean zurdos. El intervalo de confianza del 95% para \\(p\\) que hemos obtenido es [0.016, 0.175]. La conclusión usando el test binomial hubiera sido la misma: binom.test(3, 50, p=0.1) ## ## Exact binomial test ## ## data: 3 and 50 ## number of successes = 3, number of trials = 50, p-value = 0.48 ## alternative hypothesis: true probability of success is not equal to 0.1 ## 95 percent confidence interval: ## 0.0125486 0.1654819 ## sample estimates: ## probability of success ## 0.06 Ya que estamos, comprobemos que el intervalo de confianza del 95% obtenido con binom.test es efectivamente el de Clopper-Pearson: library(epitools) binom.exact(3,50) ## x n proportion lower upper conf.level ## 1 3 50 0.06 0.0125486 0.165482 0.95 Nota. El intervalo de confianza que se obtiene con prop.test en un contraste bilateral es el de Wilson modificado mediante una corrección de continuidad, un ajuste que se recomienda realizar cuando una distribución discreta (en este caso, una binomial) se aproxima mediante una distribución continua. En concreto, la fórmula que utiliza prop.test es la que se explica en esta entrada de la Wikipedia. Podéis indicar que R no efectue esta corrección de continuidad con el parámetro correct=FALSE: prop.test(3, 50, p=0.1, correct=FALSE) ## ## 1-sample proportions test without continuity correction ## ## data: 3 out of 50, null probability 0.1 ## X-squared = 0.8889, df = 1, p-value = 0.346 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.020615 0.162171 ## sample estimates: ## p ## 0.06 (Observad que sin el correct=FALSE, el encabezamiento del resultado del prop.test es 1-sample proportions test with continuity correction, mientras que con correct=FALSE es 1-sample proportions test without continuity correction). Comprobemos que el intervalo de confianza del 95% que hemos obtenido ahora sí que es el de Wilson: binom.wilson(3, 50) ## x n proportion lower upper conf.level ## 1 3 50 0.06 0.020615 0.162171 0.95 Ejemplo 5.17 Una empresa que fabrica trampas para cucarachas ha producido una nueva versión de su trampa más popular y afirma que la nueva trampa mata más cucarachas que la vieja. Hemos llevado a cabo un experimento para comprobarlo. Hemos situado dos trampas en dos habitaciones. En cada habitación hemos soltado 60 cucarachas. La versión vieja de la trampa ha matado 40 y la nueva, 48. ¿Es suficiente evidencia de que la nueva trampa es más efectiva que la vieja? Digamos \\(p_v\\) y \\(p_n\\) a las proporciones de cucarachas que matan la trampa vieja y la trampa nueva, respectivamente. La hipótesis nula será que las trampas de los dos tipos son igual de efectivas, \\(H_0:p_v=p_n\\), y la hipótesis alternativa que las trampas nuevas son más efectivas que las viejas, \\(H_1:p_v&lt;p_n\\). Los tamaños de las muestras nos permiten usar la función prop.test. prop.test(c(40,48),c(60,60),alternative=&quot;less&quot;) ## ## 2-sample test for equality of proportions with continuity ## correction ## ## data: c(40, 48) out of c(60, 60) ## X-squared = 2.088, df = 1, p-value = 0.0742 ## alternative hypothesis: less ## 95 percent confidence interval: ## -1.0000000 0.0146167 ## sample estimates: ## prop 1 prop 2 ## 0.666667 0.800000 El p-valor es 0.074, y el intervalo de confianza que nos da el test, [-1, 0.015], es para la diferencia de proporciones \\(p_v-p_n\\) y contiene el 0, aunque por poco. En resumen, a un nivel de significación de 0.05 no encontramos evidencia de que la trampa nueva sea mejor que la vieja, pero el resultado no es del todo concluyente y convendría llevar a cabo otro experimento con más cucarachas para aumentar la potencia (cf. Ejemplo 5.23 en la próxima sección). La función prop.test solo sirve para contrastar dos proporciones cuando las dos muestras son independientes y grandes. Un test que se puede usar siempre para contrastar dos proporciones usando muestras independientes es el test exacto de Fisher, que usa una distribución hipergeométrica. Supongamos que evaluamos una característica dicotómica (es decir, que solo puede tomar dos valores y por tanto define distribuciones de Bernoulli) sobre dos poblaciones y tomamos dos muestras independientes, una de cada población. Resumimos los resultados en una tabla como la que sigue: \\[ \\begin{array}{r|c} &amp; \\quad\\mbox{Población}\\quad \\\\ \\mbox{Característica} &amp;\\quad 1 \\qquad 2\\quad \\\\\\hline \\mbox{Sí} &amp;\\quad a \\qquad b\\quad \\\\ \\mbox{No} &amp;\\quad c \\qquad d\\quad \\end{array} \\] Llamemos \\(p_{1}\\) a la proporción de individuos con la característica bajo estudio en la población 1 y \\(p_{2}\\) a su proporción en la población 2. Queremos contrastar la hipótesis nula \\(H_{0}:p_1=p_2\\) contra alguna hipótesis alternativa. Por ejemplo, en el experimento de las trampas para cucarachas, las poblaciones vendrían definidas por el tipo de trampa, y la característica que tendríamos en cuenta sería si la cucaracha ha muerto o no, lo que nos daría la tabla siguiente: \\[ \\begin{array}{r|c} &amp; \\qquad\\mbox{Trampas}\\quad \\\\ &amp;\\quad \\mbox{Viejas}\\qquad \\mbox{Nuevas}\\\\\\hline \\mbox{Muertas} &amp;\\qquad 40 \\qquad\\qquad 48\\quad \\\\ \\mbox{Vivas} &amp;\\qquad 20 \\qquad\\qquad 12\\quad \\end{array} \\] El test exacto de Fisher está implementado en la función fisher.test. Su sintaxis es fisher.test(x, alternative=..., conf.level=...) donde x es la matriz \\(\\left(\\begin{array}{cc} a &amp; b\\\\ c &amp; d\\end{array}\\right)\\), en la que los números de éxitos van en la primera fila y los de fracasos en la segunda, y las poblaciones se ordenan por columnas. El significado de alternative y conf.level, y sus posibles valores, son los usuales. Así, en el ejemplo de las trampas para cucarachas, entraríamos: Datos=rbind(c(40,48),c(20,12)) Datos ## [,1] [,2] ## [1,] 40 48 ## [2,] 20 12 fisher.test(Datos, alternative=&quot;less&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: Datos ## p-value = 0.0739 ## alternative hypothesis: true odds ratio is less than 1 ## 95 percent confidence interval: ## 0.00000 1.08414 ## sample estimates: ## odds ratio ## 0.502909 y obtenemos de nuevo un p-valor cercano a 0.074. Hay que ir con cuidado con la interpretación del intervalo de confianza que da esta función: no es ni para la diferencia de las proporciones ni para su cociente, sino para su odds ratio: el cociente \\[ \\Big({\\frac{p_v}{1-p_v}}\\Big)\\Big/\\Big({\\frac{p_n}{1-p_n}}\\Big). \\] Recordad que si la probabilidad de un suceso \\(A\\) es \\(P(A)\\), sus odds son el cociente \\[ \\mbox{Odds}(A)=\\frac{P(A)}{1-P(A)} \\] que mide cuántas veces es más probable \\(A\\) que su contrario. Las odds son una función creciente de la probabilidad, y por lo tanto \\[ \\mbox{Odds}(A)&lt;\\mbox{Odds}(B)\\Longleftrightarrow P(A)&lt;P(B). \\] Esto permite comparar odds en vez de probabilidades, con la misma conclusión. Por ejemplo, en nuestro caso, como el intervalo de confianza para la odds ratio va de 0 a 1.084, en particular contiene el 1, por lo que no podemos rechazar que \\[ \\Big({\\frac{p_v}{1-p_v}}\\Big)\\Big/\\Big({\\frac{p_n}{1-p_n}}\\Big)=1, \\] es decir, no podemos rechazar que \\[ \\frac{p_v}{1-p_v}=\\frac{p_n}{1-p_n} \\] y esto es equivalente a \\(p_v=p_n\\). Si, por ejemplo, el intervalo de confianza hubiera ido de 0 a 0.8, entonces la conclusión a este nivel de confianza hubiera sido que \\[ \\Big({\\frac{p_v}{1-p_v}}\\Big)\\Big/\\Big({\\frac{p_n}{1-p_n}}\\Big)&lt;1 \\] es decir, que \\[ \\frac{p_v}{1-p_v}&lt;\\frac{p_n}{1-p_n} \\] y esto es equivalente a \\(p_v&lt;p_n\\). Ejemplo 5.18 Para determinar si el Síndrome de Muerte Súbita del Recién Nacido (SIDS, por sus siglas en inglés) tiene algún componente genético, se estudiaron parejas de gemelos y mellizos en las que se dio algún caso de SIDS. Sean \\(p_1\\) la proporción de casos con exactamente una muerte por SIDS entre las parejas de gemelos con algún caso de SIDS, y \\(p_2\\) la proporción de casos con exactamente una muerte por SIDS entre las parejas de mellizos con algún caso de SIDS. La hipótesis de trabajo es que si el SIDS tiene componente genético, será más probable que un gemelo de un muerto por SIDS también lo sufra que si solo es mellizo, y por lo tanto que en las parejas de gemelos ha de ser más raro que haya exactamente un caso de SIDS que en las parejas de mellizos. Es decir, que \\(p_1&lt;p_2\\). Así pues, queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&lt; p_2 \\end{array}\\right. \\] En un estudio se obtuvieron los datos siguientes: \\[ \\begin{array}{r|c} &amp; \\ \\mbox{Tipo de gemelos}\\ \\\\ \\mbox{Casos de SIDS} &amp;\\ \\mbox{Gemelos}\\qquad \\mbox{Mellizos}\\\\\\hline \\mbox{Uno} &amp; \\quad\\ 23 \\qquad\\quad\\quad\\quad \\ 35\\quad \\\\ \\mbox{Dos} &amp; \\quad\\ 1 \\quad\\quad\\qquad\\quad \\ \\hphantom{3} 2 \\quad \\end{array} \\] Vamos a realizar el contraste. Observad que damos la tabla de manera que \\(p_1\\) es la proporción de parejas con un solo caso de SIDS entre las de la población 1 (gemelos), y \\(p_{2}\\) es la proporción de parejas con un solo caso de SIDS entre las de la población 2 (mellizos). Por tanto hemos de aplicar fisher.test a esta matriz y \\(p_1&lt;p_2\\) corresponderá a alternative=&quot;less&quot;. Datos=rbind(c(23,35),c(1,2)) Datos ## [,1] [,2] ## [1,] 23 35 ## [2,] 1 2 fisher.test(Datos, alternative=&quot;less&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: Datos ## p-value = 0.784 ## alternative hypothesis: true odds ratio is less than 1 ## 95 percent confidence interval: ## 0.0000 39.7395 ## sample estimates: ## odds ratio ## 1.30859 El p-valor es 0.784, muy grande, por lo que no obtenemos evidencia de componente genético en el SIDS. Supongamos ahora que queremos comparar dos proporciones usando muestras emparejadas. Por ejemplo, supongamos que evaluamos dos características dicotómicas sobre una misma muestra de \\(n\\) sujetos. Resumimos los resultados obtenidos en la tabla siguiente: \\[ \\begin{array}{r|c} &amp; \\ \\mbox{Característica 1}\\ \\\\ \\mbox{Característica 2} &amp;\\ \\ \\, \\mbox{Sí}\\qquad \\mbox{No}\\\\\\hline \\mbox{Sí} &amp; \\quad\\ \\ a \\qquad \\ \\ \\, b\\quad \\\\ \\mbox{No} &amp; \\quad\\ \\ c \\qquad \\ \\ \\, d\\quad \\end{array} \\] donde \\(a+b+c+d=n\\). Esta tabla quiere decir, naturalmente, que \\(a\\) sujetos de la muestra tuvieron la característica 1 y la característica 2, que \\(b\\) sujetos de la muestra tuvieron la característica 2 pero no tuvieron la característica 1, etc. Vamos a llamar \\(p_{1}\\) a la proporción poblacional de individuos con la característica 1, y \\(p_{2}\\) a la proporción poblacional de individuos con la característica 2. Queremos contrastar la hipótesis nula \\(H_{0}:p_1=p_2\\) contra alguna hipótesis alternativa. En este caso, no pueden usarse las funciones prop.test o fisher.test. Tenemos dos soluciones posibles. La primera nos permite realizar el contraste bilateral \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2 \\end{array}\\right. \\] cuando \\(n\\) es grande (digamos que \\(n{\\geqslant}100\\)) y el número \\(b+c\\) de casos discordantes (en los que una característica da Sí y la otra da No) es razonablemente grande, pongamos \\({\\geqslant}20\\). En esta situación podemos usar el test de McNemar, que se lleva a cabo en R con la instrucción mcnemar.test. Su sintaxis básica es mcnemar.test(X) donde X es la matriz \\(\\left(\\begin{array}{cc} a &amp; b\\\\ c&amp; d \\end{array}\\right)\\) que corresponde a la tabla anterior. Ejemplo 5.19 Para comparar la efectividad de dos tratamientos del asma, se escogieron 200 pacientes con asma severo, y a cada uno se le trató durante un mes con el tratamiento A o el tratamiento B, decidiéndose cada tratamiento al azar; tras esta fase de tratamiento, se les dejó sin tratamiento durante un mes, y a continuación a cada uno se le trató durante un mes con el otro tratamiento (B si antes había recibido A, A si antes había recibido B). Se anotó si durante cada periodo de tratamiento cada enfermo visitó o no el servicio de urgencias por dificultades respiratorias. Los resultados del experimento se resumen en la tabla siguiente (“Sí” significa que sí que acudió a urgencias por dificultades respiratorias): \\[ \\begin{array}{r|c} &amp; \\ \\mbox{Tratamiento A}\\ \\\\ \\mbox{Trat. B} &amp;\\quad \\ \\mbox{ Sí}\\qquad\\quad \\mbox{No}\\quad \\\\\\hline \\mbox{Sí} &amp; \\quad \\ 71 \\qquad\\quad 48\\quad \\\\ \\mbox{No} &amp; \\quad \\ 30 \\qquad\\quad 51\\quad \\end{array} \\] Queremos determinar si hay diferencia en la efectividad de los dos tratamientos. Para ello, entramos la tabla anterior en una matriz y le aplicamos la función mcnemar.test: Datos=matrix(c(71,48,30,51),nrow=2,byrow=TRUE) Datos ## [,1] [,2] ## [1,] 71 48 ## [2,] 30 51 mcnemar.test(Datos) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: Datos ## McNemar&#39;s chi-squared = 3.705, df = 1, p-value = 0.0542 El p-valor del test es 0.054, ligeramente superior a 0.05, por lo tanto no permite concluir a un nivel de significación del 5% que haya evidencia de que la efectividad de los dos tratamientos sea diferente, pero sería conveniente llevar a cabo un estudio más amplio. Otra posibilidad para realizar un contraste de dos proporciones usando muestras emparejadas, que no requiere de ninguna hipótesis sobre los tamaños de las muestras, es usar de manera adecuada la función binom.test. Para explicar este método, consideremos la tabla siguiente, donde ahora damos las probabilidades poblacionales de las cuatro combinaciones de resultados: \\[ \\begin{array}{r|c} &amp; \\ \\mbox{Característica 1}\\ \\\\ \\mbox{Característica 2} &amp;\\quad \\ \\!\\mbox{Sí}\\qquad\\quad\\, \\mbox{No}\\quad \\\\\\hline \\mbox{Sí} &amp; \\quad \\ p_{11} \\qquad\\quad p_{01}\\quad \\\\ \\mbox{No} &amp; \\quad \\ p_{10} \\qquad\\quad p_{00}\\quad \\end{array} \\] De esta manera \\(p_1=p_{11}+p_{10}\\) y \\(p_2=p_{11}+p_{01}\\). Entonces, \\(p_1=p_2\\) es equivalente a \\(p_{10}=p_{01}\\) y cualquier hipótesis alternativa se traduce en la misma desigualdad, pero para \\(p_{10}\\) y \\(p_{01}\\): \\(p_1\\neq p_2\\) es equivalente a \\(p_{10}\\neq p_{01}\\); \\(p_1&lt; p_2\\) es equivalente a \\(p_{10}&lt; p_{01}\\); y \\(p_1&gt; p_2\\) es equivalente a \\(p_{10}&gt; p_{01}\\). Por lo tanto podemos traducir el contraste sobre \\(p_1\\) y \\(p_2\\) al mismo contraste sobre \\(p_{10}\\) y \\(p_{01}\\). La gracia ahora está en que si la hipótesis nula \\(p_{10}=p_{01}\\) es cierta, entonces, en el total de casos discordantes, el número de sujetos en los que la característica 1 da Sí y la característica 2 da No sigue una ley binomial con \\(p=0.5\\). Por lo tanto, podemos efectuar el contraste usando un test binomial exacto tomando como muestra los casos discordantes de nuestra muestra, de tamaño \\(b+c\\), como éxitos los sujetos que han dado Sí en la característica 1 y No en la característica 2, de tamaño \\(c\\), con proporción a contrastar \\(p=0.5\\) y con hipótesis alternativa la que corresponda. La ventaja de este test es que su validez no requiere de ninguna hipótesis sobre los tamaños de las muestras. El inconveniente es que el intervalo de confianza que nos dará será para \\(p_{10}/(p_{10}+p_{01})\\), y no permite obtener un intervalo de confianza para la diferencia o el cociente de las probabilidades \\(p_1\\) y \\(p_2\\) de interés. Ejemplo 5.20 Usemos el test binomial para llevar a cabo el contraste bilateral del Ejemplo 5.19. Habíamos obtenido 30+48=78 casos discordantes, de los que 48 eran casos en los que el tratamiento A había dado Sí y el tratamiento B había dado No. binom.test(48, 78, p=0.5) ## ## Exact binomial test ## ## data: 48 and 78 ## number of successes = 48, number of trials = 78, p-value = 0.0535 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.498331 0.723398 ## sample estimates: ## probability of success ## 0.615385 Obtenemos de nuevo un p-valor en la zona de penumbra, ligeramente superior a 0.05. Ejemplo 5.21 Para determinar si un test casero de VIH basado en un frotis bucal da más positivos (que seguramente serán falsos positivos) que el test de VIH de referencia, basado en una analítica de sangre que detecta la presencia del virus, se tomó una muestra aleatoria de 241 individuos en situación de riesgo, y a todos se les realizaron ambos tests. Los resultados se resumen en la tabla siguiente: \\[ \\begin{array}{r|c} &amp; \\ \\mbox{Test estándar}\\ \\\\ \\mbox{Test casero} &amp;\\quad \\ \\mbox{ Positivo}\\qquad\\quad \\quad \\mbox{Negativo}\\quad \\\\\\hline \\mbox{Positivo} &amp; \\quad\\ \\ 72 \\qquad\\qquad\\qquad\\ 10 \\quad \\\\ \\mbox{Negativo} &amp; \\quad\\quad 2 \\qquad\\qquad\\quad\\quad \\ 157 \\quad \\end{array} \\] Si llamamos \\(p_{c}\\) a la probabilidad de que el test casero dé positivo y \\(p_{e}\\) a la probabilidad de que el test estándar dé positivo, queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:p_{e}=p_{c}\\\\ H_{1}:p_{e}&lt; p_{c} \\end{array}\\right. \\] El número de casos discordantes es pequeño (10+2=12) y además el test es unilateral, así que usaremos el test binomial. Como queremos realizar un contraste unilateral, hay que pensar en cómo traducir la hipótesis alternativa en términos de una hipótesis sobre la probabilidad \\(p=p_{10}/(p_{10}+p_{01})\\) de que un caso discordante tenga la característica 1 (la de las columnas). Veamos, \\(p_{e}&lt; p_{c}\\) significa que la característica de las columnas es menos probable que la de las filas, por tanto se ha de traducir en que la probabilidad de tener la característica de las columnas y no la de las filas es más pequeña que la probabilidad de tener la característica de las filas y no la de las columnas, es decir, en que \\(p&lt;0.5\\): hemos de usar alternative=less. binom.test(2, 12, alternative=&quot;less&quot;, p=0.5) ## ## Exact binomial test ## ## data: 2 and 12 ## number of successes = 2, number of trials = 12, p-value = 0.0193 ## alternative hypothesis: true probability of success is less than 0.5 ## 95 percent confidence interval: ## 0.000000 0.438105 ## sample estimates: ## probability of success ## 0.166667 Obtenemos evidencia significativa de que, efectivamente, el test casero da positivo con mayor frecuencia que el de referencia. 5.4 Cálculo de la potencia de un contraste Recordemos que la potencia de un contraste de hipótesis es la probabilidad de no cometer un error de tipo II, es decir, la probabilidad de aceptar la hipótesis alternativa si es verdadera. Usualmente, la probabilidad de cometer un error de tipo II se denota por \\(\\beta\\), y por lo tanto la potencia es \\(1-\\beta\\). La potencia de un contraste está relacionada con lo que se llama la magnitud del efecto (effect size). En un contraste, el efecto es la diferencia entre el valor estimado del parámetro a partir de la muestra usada y el valor que se da a dicho parámetro como hipótesis nula: por ejemplo, en el contraste de una media, la diferencia entre la media muestral \\(\\overline{x}\\) y el valor contrastado \\(\\mu_0\\); o, en el contraste de dos medias, la diferencia entre las dos medias muestrales. Se rechaza entonces la hipótesis nula si el efecto observado es tan grande que es muy improbable cuando la hipótesis nula es verdadera. Pero recordad que, en realidad, no se tiene en cuenta si el efecto observado ha sido grande o no por si mismo, solo si es estadísticamente significativo, es decir, si es improbable cuando la hipótesis nula es verdadera. Entonces, sin entrar en detalle, digamos que la magnitud del efecto es una medida estadística específica del tamaño del efecto observado respecto de su valor esperado si la hipótesis nula es verdadera. La fórmula para calcular la magnitud del efecto depende del contraste y del estadístico usado. Para cada tipo de test se han consensuado unos valores de la magnitud del efecto considerados como “pequeño”, “medio” y “grande”. Estos valores se obtienen con R con la función cohen.ES del paquete pwr. Su sintaxis básica es cohen.ES(test=..., size=...) donde: el parámetro test sirve para indicar el tipo de test: por ejemplo, test=&quot;t&quot; para un test t usando t.test, o test=&quot;p&quot; para un test aproximado de proporciones usando prop.test; el parámetro size sirve para indicar la magnitud esperada: &quot;small&quot;, &quot;medium&quot; o &quot;large&quot;. A modo de ejemplo, la siguiente instrucción nos da la magnitud de efecto que se considera pequeña en un test t: library(pwr) cohen.ES(test=&quot;t&quot;,size=&quot;small&quot;) ## ## Conventional effect size from Cohen (1982) ## ## test = t ## size = small ## effect.size = 0.2 De manera similar, para saber la magnitud de efecto que se considera media en un test aproximado de proporciones podemos usar instrucción siguiente: cohen.ES(test=&quot;p&quot;,size=&quot;medium&quot;) ## ## Conventional effect size from Cohen (1982) ## ## test = p ## size = medium ## effect.size = 0.5 Si se desea solo el valor de la magnitud del efecto, para poderlo entrar en otras funciones, se obtiene con el sufijo $effect.size: cohen.ES(test=&quot;p&quot;,size=&quot;medium&quot;)$effect.size ## [1] 0.5 Así pues, en un contraste de hipótesis intervienen cuatro cantidades fundamentales: el tamaño de la muestra, \\(n\\); el nivel de significación, \\(\\alpha\\); la potencia, \\(1-\\beta\\); y la magnitud del efecto. El tamaño de la muestra y el nivel de significación están bajo el control del investigador; sin embargo, la potencia del contraste y la magnitud del efecto afectan al contraste de forma más indirecta y su control escapa al investigador. Por ejemplo, si incrementamos el tamaño de la muestra, la potencia aumenta, pero el aumento preciso depende de la magnitud del efecto esperada. De hecho, las cuatro cantidades anteriores no son independientes, sino que, a partir de tres cualesquiera de ellas, se puede calcular la cuarta. Las funciones del paquete pwr permiten realizar estos cálculos para los contrastes de medias y proporciones. Las funciones de dicho paquete que por ahora nos interesan en este sentido son las siguientes: pwr.t.test, para utilizar en tests t de una media, de dos medias usando muestras emparejadas o de dos medias usando muestras independientes del mismo tamaño. pwr.t2n.test, para utilizar en tests t de dos medias usando muestras independientes de distinto tamaño. pwr.p.test, para utilizar en contrastes aproximados de una proporción. pwr.2p.test, para utilizar en contrastes aproximados de dos proporciones usando muestras independientes del mismo tamaño. pwr.2p2n.test, para utilizar en contrastes aproximados de dos proporciones usando muestras de distinto tamaño. Estas funciones tienen los parámetros básicos siguientes: n: el tamaño de la muestra (o de las muestras cuando son del mismo tamaño). n1 y n2: los tamaños de las dos muestras en pwr.2p2n.test y pwr.t2n.test. d (en las dos primeras) o h (en las tres últimas): la magnitud del efecto. sig.level: el nivel de significación. power: la potencia. type (en la primera): el tipo de muestras usado, siendo sus posibles valores &quot;one.sample&quot; (para contrastes de una muestra), &quot;two.sample&quot; (para contrastes de dos muestras independientes), o &quot;paired&quot; (para contrastes de dos muestras emparejadas). alternative: el tipo de hipótesis alternativa, con sus valores usuales. Si, en una cualquiera de estas funciones se especifican todos los parámetros n (o n1 y n2), d (o h), sig.level y power menos uno, la función da el valor del parámetro que falta. Veamos algunos ejemplos de uso. Ejemplo 5.22 Queremos calcular la potencia del contraste llevado a cabo en el Ejemplo 5.2. Se trataba de un contraste bilateral de una media usando un test t, por lo que utilizaremos la función pwr.t.test. Los parámetros que le entraremos son: n, el tamaño de la muestra; en este ejemplo, \\(n=25\\). d, la magnitud del efecto. Para tests t de una media e hipótesis nula \\(H_0: \\mu = \\mu_0\\), la magnitud del efecto se calcula con la fórmula \\[ d=\\frac{|\\overline{x}-\\mu_0|}{\\widetilde{s}_x}. \\] En nuestro ejemplo, \\(d=\\frac{|2.8048-2|}{0.68064}= 1.1824\\). sig.level, el nivel de significación; en este ejemplo, \\(\\alpha=0.05\\). Además como es un contraste bliateral de una media, especificaremos type=&quot;one.sample&quot; y alternative=&quot;two.sided&quot; (esto último en realidad no hace falta: como siempre, este es su valor por defecto). x=c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,2.16,2.46,2.71,2.04,3.74,3.24, 3.92,2.38,2.82,2.2,2.42,2.82,2.84,4.22,3.64,1.77,3.44,1.53) mag.ef=abs(mean(x)-2)/sd(x) #Magnitud del efecto pwr.t.test(n=25, d=mag.ef, sig.level=0.05, type=&quot;one.sample&quot;, alternative=&quot;two.sided&quot;) ## ## One-sample t test power calculation ## ## n = 25 ## d = 1.18241 ## sig.level = 0.05 ## power = 0.999893 ## alternative = two.sided Obtenemos que la potencia del test es prácticamente 1. Si estuviéramos diseñando el experimento y quisiéramos calcular el tamaño mínimo de una muestra para tener un nivel de significación del 5% y potencia del 99%, suponiendo a priori que la magnitud del efecto esperado va a ser grande (y que por lo tanto detectar que la hipótesis alternativa es verdadera va a ser fácil), primero calcularíamos cuánto vale una magnitud del efecto grande: cohen.ES(test=&quot;t&quot;,size=&quot;large&quot;)$effect.size ## [1] 0.8 y a continuación la usaríamos en la función pwr.t.test: pwr.t.test(d=0.8, sig.level=0.05, power=0.99, type=&quot;one.sample&quot;) ## ## One-sample t test power calculation ## ## n = 30.7143 ## d = 0.8 ## sig.level = 0.05 ## power = 0.99 ## alternative = two.sided Bastarían 31 observaciones para tener la potencia deseada. Si en cambio esperáramos una magnitud del efecto pequeña: pwr.t.test(d=cohen.ES(test=&quot;t&quot;,size=&quot;small&quot;)$effect.size, sig.level=0.05, power=0.99, type=&quot;one.sample&quot;) ## ## One-sample t test power calculation ## ## n = 461.238 ## d = 0.2 ## sig.level = 0.05 ## power = 0.99 ## alternative = two.sided En este caso necesitaríamos 462 observaciones. Podemos obtener solo una de las componentes del resultado de una de estas funciones añadiéndole el sufijo adecuado. Por ejemplo, la potencia se obtiene con el sufijo $power y el valor de \\(n\\) con el sufijo $n: pwr.t.test(n=25, d=mag.ef, sig.level=0.05, type=&quot;one.sample&quot;, alternative=&quot;two.sided&quot;)$power ## [1] 0.999893 pwr.t.test(d=0.8, sig.level=0.05, power=0.99, type=&quot;one.sample&quot;)$n ## [1] 30.7143 Ejemplo 5.23 Vamos a calcular la potencia del contraste \\[ \\left\\{ \\begin{array}{l} H_0:p_v=p_n\\\\ H_1:p_v&lt;p_n \\end{array} \\right. \\] del Ejemplo 5.17. En este caso, usamos la función pwr.2p.test, ya que usamos dos muestras del mismo tamaño, y le entramos los parámetros siguientes: n, el tamaño de las muestras; en este ejemplo, \\(n=60\\). h, la magnitud del efecto. Para calcularla,3 usamos la función ES.h del mismo paquete pwr y que se aplica a las proporciones muestrales de éxitos: en este ejemplo, \\(\\widehat{p}_v=0.67\\) y \\(\\widehat{p}_n =0.8\\) y la magnitud del efecto vale: ES.h(0.67,0.8) ## [1] -0.296584 sig.level, el nivel de significación, 0.05. Como solo nos interesa la potencia, añadiremos al pwr.2p.test el sufijo $power: pwr.2p.test(h=ES.h(0.67,0.8), n=60, sig.level=0.05,alternative=&quot;less&quot;)$power ## [1] 0.491864 Hemos obtenido una potencia de, aproximadamente, un 49%. Si estuviéramos diseñando el experimento y quisiéramos calcular el tamaño de las muestras necesario para tener una potencia del 90% al nivel de significación del 5% y esperando una magnitud del efecto pequeña (porque esperamos una mejora con las nuevas trampas, pero solo pequeña), entraríamos: cohen.ES(test=&quot;p&quot;,size=&quot;small&quot;)$effect.size ## [1] 0.2 pwr.2p.test(h=-0.2, sig.level=0.05, power=0.9,alternative=&quot;less&quot;)$n ## [1] 428.192 Tendríamos que usar dos muestras de 429 cucarachas cada una. Observad que en pwr.2p.test hemos entrado en h la magnitud del efecto en negativo: esto es debido a que usamos alternative=&quot;less&quot; y por lo tanto esperamos que la primera proporción sea menor que la segunda. Ejemplo 5.24 En el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_n=\\mu_f\\\\ H_{1}:\\mu_n&gt; \\mu_f \\end{array}\\right. \\] del Ejemplo 5.6, ¿qué tamaño de la muestra de mujeres fumadoras tendríamos que tomar si usáramos una muestra de 100 no fumadoras, quisiéramos una potencia del 90% y un nivel de significación del 5% y esperáramos una magnitud del efecto media? Como es un contraste de dos medias independientes y los tamaños de las muestras pueden ser diferentes, usaremos la función pwr.t2n.test. Entraremos como n1 el tamaño de la muestra de fumadoras y le pediremos que nos dé solo el valor de n2, el tamaño de la “otra” muestra: pwr.t2n.test(n1=100, d=cohen.ES(test=&quot;t&quot;,size=&quot;medium&quot;)$effect.size, sig.level=0.05, power=0.9, alternative=&quot;greater&quot;)$n2 ## [1] 52.8251 Bastaría estudiar 53 madres fumadoras. 5.5 Guía rápida Excepto en las que decimos lo contrario, todas las funciones para realizar contrastes que damos a continuación admiten los parámetros alternative, que sirve para especificar el tipo de contraste (unilateral en un sentido u otro o bilateral), y conf.level, que sirve para indicar el nivel de confianza \\(1-\\alpha\\). Sus valores por defecto son contraste bilateral y nivel de confianza 0.95. t.test realiza tests t para contrastar una o dos medias (tanto usando muestras independientes como emparejadas). Aparte de alternative y conf.level, sus parámetros principales son: mu para especificar el valor de la media que queremos contrastar en un test de una media. paired para indicar si en un contraste de dos medias usamos muestras independientes o emparejadas. var.equal para indicar en un contraste de dos medias usando muestras independientes si las varianzas poblacionales son iguales o diferentes. SIGN.test del paquete BSDA, realiza un test de signos para contrastar una mediana. Dispone del parámetro md para entrar la mediana a contrastar. wilcox.test, para realizar tests de Wilcoxon y de Mann-Whitney para contrastar una o dos medianas (tanto usando muestras independientes como emparejadas). Sus parámetros son los mismos que los de t.test (salvo var.equal, que en estos tests no tiene sentido). sigma.test, para realizar tests \\(\\chi^2\\) para contrastar una varianza (o una desviación típica). Dispone de los parámetros sigma y sigmasq para indicar, respectivamente, la desviación típica o la varianza a contrastar. var.test, para realizar tests F para contrastar dos varianzas (o dos desviaciones típicas). fligner.test, para realizar tests no paramétricos de Fligner-Killeen para contrastar dos varianzas (o dos desviaciones típicas). No dispone de los parámetros alternative (solo sirve para contrastes bilaterales) ni conf.level (no calcula intervalos de confianza). binom.test, para realizar tests binomiales exactos para contrastar una proporción. Dispone del parámetro p para indicar la proporción a contrastar. prop.test, para realizar tests aproximados para contrastar una proporción o dos proporciones de poblaciones usando muestras independientes. También dispone del parámetro p para indicar la proporción a contrastar en un contraste de una proporción. fisher.test, para realizar tests exactos de Fisher para contrastar dos proporciones usando muestras independientes. mcnemar.test, para realizar tests bilaterales de McNemar para contrastar dos proporciones usando muestras emparejadas. No dispone de los parámetros alternative ni conf.level. cohen.ES del paquete pwr, da los valores aceptados por convenio como “pequeño”, “mediano” y “grande” para diferentes tests. pwr.t.test del paquete pwr, relaciona el tamaño de la(s) muestra(s), el nivel de significación, la potencia y la magnitud del efecto (en el sentido de que si se entran tres de estos valores se obtiene el cuarto) en tests t de una media, de dos medias usando muestras emparejadas o de dos medias usando muestras independientes del mismo tamaño. Sus parámetros, son n: el tamaño de la muestra o de las muestras. sig.level: el nivel de significación. power: la potencia. d: la magnitud del efecto type: el tipo de muestras (una muestra, dos muestras emparejadas, dos muestras independientes). alternative: el tipo de hipótesis alternativa. pwr.t2n.testdel paquete pwr, relaciona los tamaños de muestras, el nivel de significación, la potencia y la magnitud del efecto en tests t de dos medias usando muestras independientes de distinto tamaño. Sus parámetros son n1 y n2: los tamaños de las dos muestras. sig.level, power, d y alternative como en pwr.t.test. pwr.p.test del paquete pwr, relaciona los tamaños de muestras, el nivel de significación, la potencia y la magnitud del efecto en contrastes aproximados de una proporción. Sus parámetros son n, sig.level, power y alternative como en pwr.t.test. h: la magnitud del efecto pwr.2p.test del paquete pwr, relaciona los tamaños de muestras, el nivel de significación, la potencia y la magnitud del efecto en contrastes aproximados de dos proporciones usando muestras independientes del mismo tamaño. Sus parámetros son los mismos que los de pwr.p.test. pwr.2p2n.test, del paquete pwr, relaciona los tamaños de muestras, el nivel de significación, la potencia y la magnitud del efecto en contrastes aproximados de dos proporciones usando muestras de distinto tamaño. Sus parámetros son n1 y n2: los tamaños de las dos muestras. sig.level, power, h y alternative como en pwr.p.test. 5.6 Ejercicios Modelo de test (1) Tenemos una m.a.s. de una población normal \\(X\\sim N(\\mu,\\sigma)\\) formada por los números 2,5,3,5,6,6,7,2. Usando la función t.test, calculad el p-valor (redondeado a 3 cifras decimales, sin ceros innecesarios a la derecha) del contraste \\(H_0: \\mu=4\\) contra \\(H_1:\\mu \\neq 4\\) y decid (contestando SI, sin acento, o NO) si podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.05. Tenéis que dar las dos respuestas en este orden, separadas por un único espacio en blanco. (2) Tenemos dos muestras de poblaciones normales, \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\). Sean \\(x_1=(2,5,3,5,6,6,7,2)\\) y \\(x_2=(3,2,5,4,2,2,4,5,1,6,2)\\) muestras aleatorias simples de \\(X_1\\) y \\(X_2\\), respectivamente. Usando la función t.test, calculad el p-valor (redondeado a 3 cifras decimales, sin ceros innecesarios a la derecha) del contraste \\(H_0: \\mu_1=\\mu_2\\) contra \\(H_1:\\mu_1&gt;\\mu_2\\) suponiendo que las varianzas son diferentes y decid (contestando SI, sin acento, o NO) si podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.1. Tenéis que dar las dos respuestas en este orden, separadas por un único espacio en blanco. (3) Tenemos dos muestras de poblaciones normales, \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\). Sean \\(x_1=(2,5,3,5,6,6,7,2)\\) y \\(x_2=(3,2,10,9,2,2,4,5,1,10,2)\\) muestras aleatorias simples de \\(X_1\\) y \\(X_2\\), respectivamente. Usando la función var.test, calculad los extremos inferior y superior de un intervalo de confianza del 95% para \\(\\sigma_1^2/\\sigma_2^2\\) (redondeados a 3 cifras decimales, sin ceros innecesarios a la derecha) y decid (contestando SI, sin acento, o NO) si en el contraste \\(H_0: \\sigma_1=\\sigma_2\\) contra \\(H_1:\\sigma_1 \\neq \\sigma_2\\) podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.05. Tenéis que dar las tres respuestas en este orden, separadas por un único espacio en blanco. (4) Tenemos dos variables aleatorias de Bernoulli de proporciones poblacionales \\(p_1\\) y \\(p_2\\), respectivamente. En una muestra de 100 observaciones de la primera hemos obtenido 20 éxitos, y en una muestra de 150 observaciones de la segunda, hemos obtenido 40 éxitos. Usando la función prop.test, calculad el p-valor (redondeado a 3 cifras decimales, sin ceros innecesarios a la derecha) del contraste \\(H_0: p_1=p_2\\) contra \\(H_1:p_1&lt;p_2\\) y decid (contestando SI, sin acento, o NO) si podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.05. Tenéis que dar las dos respuestas en este orden, separadas por un único espacio en blanco. Respuestas al test (1) 0.487 NO Nosotros lo hemos resuelto con x=c(2,5,3,5,6,6,7,2) round(t.test(x,mu=4)$p.value,3) ## [1] 0.487 (2) 0.083 SI Nosotros lo hemos resuelto con x1=c(2,5,3,5,6,6,7,2) x2=c(3,2,5,4,2,2,4,5,1,6,2) round(t.test(x1,x2,alternative=&quot;greater&quot;)$p.value,3) ## [1] 0.083 (3) 0.078 1.465 NO Nosotros lo hemos resuelto con x1=c(2,5,3,5,6,6,7,2) x2=c(3,2,10,9,2,2,4,5,1,10,2) round(var.test(x1,x2)$conf.int,3) ## [1] 0.078 1.465 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 (4) 0.145 NO Nosotros lo hemos resuelto con round(prop.test(c(20,40),c(100,150),alternative=&quot;less&quot;)$p.value,3) ## [1] 0.145 Se sabe que si las dos muestras provienen de poblaciones normales y son del mismo tamaño, el test t tiende a dar la misma conclusión tanto si se supone que las dos varianzas son iguales como si se supone que son diferentes: véase C. A. Markowski y E. P. Markowski, “Conditions for the Effectiveness of a Preliminary Test of Variance,” The American Statistician 44 (1990), pp. 322-326. Pero no sabemos si estas longitudes siguen distribuciones normales o no, y que “tienda a dar” la misma conclusión no significa que en un ejemplo concreto con p-valores cercanos al nivel de significación no pueda dar conclusiones diferentes.↩ Véanse: E. S. Pearson, “The analysis of variance in cases of non-normal variation,” Biometrika 23 (1931), pp. 114-133; G. E. P. Box, “Non-normality and tests on variances,” Biometrika 40 (1953), pp. 318-335.↩ Por si a alguien le interesa, la fórmula para esta magnitud del efecto es \\[ h=2\\left(\\arcsin\\big(\\sqrt{\\widehat{p}_1}\\,\\big)-\\arcsin\\big(\\sqrt{\\widehat{p}_2}\\,\\big)\\right), \\] siendo \\(\\widehat{p}_1\\) y \\(\\widehat{p}_2\\) las proporciones muestrales de éxitos de las dos muestras.↩ "]
]
