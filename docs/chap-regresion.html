<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lección 10 Regresión lineal | AprendeR: Parte II</title>
  <meta name="description" content="Apuntes AprendeR bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Lección 10 Regresión lineal | AprendeR: Parte II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apuntes AprendeR bookdown::gitbook." />
  <meta name="github-repo" content="AprendeR-UIB/AprendeR2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lección 10 Regresión lineal | AprendeR: Parte II" />
  
  <meta name="twitter:description" content="Apuntes AprendeR bookdown::gitbook." />
  

<meta name="author" content="The UIB-AprendeR team" />


<meta name="date" content="2021-03-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-ANOVA.html"/>
<link rel="next" href="chap-clustering.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">AprendeR: Parte II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a></li>
<li class="part"><span><b>Parte II: Estadística inferencial</b></span></li>
<li class="chapter" data-level="1" data-path="chap-distr.html"><a href="chap-distr.html"><i class="fa fa-check"></i><b>1</b> Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>1.1</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#problemas"><i class="fa fa-check"></i>Problemas</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chap-muestreo.html"><a href="chap-muestreo.html"><i class="fa fa-check"></i><b>2</b> Conceptos básicos de muestreo</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chap-muestreo.html"><a href="chap-muestreo.html#sec:muestreo"><i class="fa fa-check"></i><b>2.1</b> Tipos de muestreo</a></li>
<li class="chapter" data-level="2.2" data-path="chap-muestreo.html"><a href="chap-muestreo.html#muestreo-aleatorio-con-r"><i class="fa fa-check"></i><b>2.2</b> Muestreo aleatorio con R</a></li>
<li class="chapter" data-level="2.3" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>2.3</b> Guía rápida</a></li>
<li class="chapter" data-level="2.4" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>2.4</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#problemas"><i class="fa fa-check"></i>Problemas</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap-estimacion.html"><a href="chap-estimacion.html"><i class="fa fa-check"></i><b>3</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chap-estimacion.html"><a href="chap-estimacion.html#estimación-máximo-verosímil"><i class="fa fa-check"></i><b>3.1</b> Estimación máximo verosímil</a></li>
<li class="chapter" data-level="3.2" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>3.2</b> Guía rápida</a></li>
<li class="chapter" data-level="3.3" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>3.3</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#problemas"><i class="fa fa-check"></i>Problemas</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap-IC.html"><a href="chap-IC.html"><i class="fa fa-check"></i><b>4</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chap-IC.html"><a href="chap-IC.html#sec:ICT"><i class="fa fa-check"></i><b>4.1</b> Intervalo de confianza para la media basado en la t de Student</a></li>
<li class="chapter" data-level="4.2" data-path="chap-IC.html"><a href="chap-IC.html#intervalos-de-confianza-para-la-proporción-poblacional"><i class="fa fa-check"></i><b>4.2</b> Intervalos de confianza para la proporción poblacional</a></li>
<li class="chapter" data-level="4.3" data-path="chap-IC.html"><a href="chap-IC.html#sec:ICvar"><i class="fa fa-check"></i><b>4.3</b> Intervalo de confianza para la varianza de una población normal</a></li>
<li class="chapter" data-level="4.4" data-path="chap-IC.html"><a href="chap-IC.html#bootstrap"><i class="fa fa-check"></i><b>4.4</b> Bootstrap</a></li>
<li class="chapter" data-level="4.5" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>4.5</b> Guía rápida</a></li>
<li class="chapter" data-level="4.6" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>4.6</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#problemas"><i class="fa fa-check"></i>Problemas</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap-contrastes.html"><a href="chap-contrastes.html"><i class="fa fa-check"></i><b>5</b> Contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chap-contrastes.html"><a href="chap-contrastes.html#contrastes-para-medias"><i class="fa fa-check"></i><b>5.1</b> Contrastes para medias</a>
<ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#el-test-t"><i class="fa fa-check"></i>El test t</a></li>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#tests-no-paramétricos"><i class="fa fa-check"></i>Tests no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="chap-contrastes.html"><a href="chap-contrastes.html#contrastes-para-varianzas"><i class="fa fa-check"></i><b>5.2</b> Contrastes para varianzas</a></li>
<li class="chapter" data-level="5.3" data-path="chap-contrastes.html"><a href="chap-contrastes.html#contrastes-para-proporciones"><i class="fa fa-check"></i><b>5.3</b> Contrastes para proporciones</a></li>
<li class="chapter" data-level="5.4" data-path="chap-contrastes.html"><a href="chap-contrastes.html#cálculo-de-la-potencia-de-un-contraste"><i class="fa fa-check"></i><b>5.4</b> Cálculo de la potencia de un contraste</a></li>
<li class="chapter" data-level="5.5" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>5.5</b> Guía rápida</a></li>
<li class="chapter" data-level="5.6" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>5.6</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#modelo-de-test"><i class="fa fa-check"></i>Modelo de test</a></li>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#ejercicios-1"><i class="fa fa-check"></i>Ejercicios</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#respuestas-sucintas-a-los-ejercicios"><i class="fa fa-check"></i>Respuestas sucintas a los ejercicios</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap-bondad.html"><a href="chap-bondad.html"><i class="fa fa-check"></i><b>6</b> Contrastes de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chap-bondad.html"><a href="chap-bondad.html#pruebas-gráficas-q-q-plots"><i class="fa fa-check"></i><b>6.1</b> Pruebas gráficas: Q-Q-plots</a></li>
<li class="chapter" data-level="6.2" data-path="chap-bondad.html"><a href="chap-bondad.html#el-test-chi2-de-pearson"><i class="fa fa-check"></i><b>6.2</b> El test <span class="math inline">\(\chi^2\)</span> de Pearson</a></li>
<li class="chapter" data-level="6.3" data-path="chap-bondad.html"><a href="chap-bondad.html#el-test-chi2-para-distribuciones-continuas"><i class="fa fa-check"></i><b>6.3</b> El test <span class="math inline">\(\chi^2\)</span> para distribuciones continuas</a></li>
<li class="chapter" data-level="6.4" data-path="chap-bondad.html"><a href="chap-bondad.html#el-test-de-kolgomorov-smirnov"><i class="fa fa-check"></i><b>6.4</b> El test de Kolgomorov-Smirnov</a></li>
<li class="chapter" data-level="6.5" data-path="chap-bondad.html"><a href="chap-bondad.html#tests-de-normalidad"><i class="fa fa-check"></i><b>6.5</b> Tests de normalidad</a></li>
<li class="chapter" data-level="6.6" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>6.6</b> Guía rápida</a></li>
<li class="chapter" data-level="6.7" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>6.7</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#modelo-de-test"><i class="fa fa-check"></i>Modelo de test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#problemas"><i class="fa fa-check"></i>Problemas</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-indep.html"><a href="chap-indep.html"><i class="fa fa-check"></i><b>7</b> Contrastes de independencia y homogeneidad</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chap-indep.html"><a href="chap-indep.html#tablas-de-contingencia"><i class="fa fa-check"></i><b>7.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="7.2" data-path="chap-indep.html"><a href="chap-indep.html#contraste-de-independencia"><i class="fa fa-check"></i><b>7.2</b> Contraste de independencia</a></li>
<li class="chapter" data-level="7.3" data-path="chap-indep.html"><a href="chap-indep.html#sec:hom"><i class="fa fa-check"></i><b>7.3</b> Contraste de homogeneidad</a></li>
<li class="chapter" data-level="7.4" data-path="chap-indep.html"><a href="chap-indep.html#potencia-de-un-contraste-chi2"><i class="fa fa-check"></i><b>7.4</b> Potencia de un contraste <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="7.5" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>7.5</b> Guía rápida</a></li>
<li class="chapter" data-level="7.6" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>7.6</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#modelo-de-test"><i class="fa fa-check"></i>Modelo de test</a></li>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#ejercicios-1"><i class="fa fa-check"></i>Ejercicios</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chap-estmult.html"><a href="chap-estmult.html"><i class="fa fa-check"></i><b>8</b> Introducción a la estadística descriptiva multidimensional</a>
<ul>
<li class="chapter" data-level="8.1" data-path="chap-estmult.html"><a href="chap-estmult.html#matrices-de-datos-cuantitativos"><i class="fa fa-check"></i><b>8.1</b> Matrices de datos cuantitativos</a></li>
<li class="chapter" data-level="8.2" data-path="chap-estmult.html"><a href="chap-estmult.html#transformaciones-lineales"><i class="fa fa-check"></i><b>8.2</b> Transformaciones lineales</a></li>
<li class="chapter" data-level="8.3" data-path="chap-estmult.html"><a href="chap-estmult.html#covarianzas-y-correlaciones"><i class="fa fa-check"></i><b>8.3</b> Covarianzas y correlaciones</a></li>
<li class="chapter" data-level="8.4" data-path="chap-estmult.html"><a href="chap-estmult.html#correlación-de-spearman"><i class="fa fa-check"></i><b>8.4</b> Correlación de Spearman</a></li>
<li class="chapter" data-level="8.5" data-path="chap-estmult.html"><a href="chap-estmult.html#contrastes-de-correlación"><i class="fa fa-check"></i><b>8.5</b> Contrastes de correlación</a></li>
<li class="chapter" data-level="8.6" data-path="chap-estmult.html"><a href="chap-estmult.html#un-ejemplo"><i class="fa fa-check"></i><b>8.6</b> Un ejemplo</a></li>
<li class="chapter" data-level="8.7" data-path="chap-estmult.html"><a href="chap-estmult.html#representación-gráfica-de-datos-multidimensionales"><i class="fa fa-check"></i><b>8.7</b> Representación gráfica de datos multidimensionales</a></li>
<li class="chapter" data-level="8.8" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>8.8</b> Guía rápida</a></li>
<li class="chapter" data-level="8.9" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>8.9</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#modelo-de-test"><i class="fa fa-check"></i>Modelo de test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#problemas"><i class="fa fa-check"></i>Problemas</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#soluciones-sucintas-de-los-problemas"><i class="fa fa-check"></i>Soluciones sucintas de los problemas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html"><i class="fa fa-check"></i><b>9</b> ANOVA básico</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#sec:modelos"><i class="fa fa-check"></i><b>9.1</b> Los modelos del ANOVA en R</a></li>
<li class="chapter" data-level="9.2" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#sec:ANOVA-1"><i class="fa fa-check"></i><b>9.2</b> ANOVA de un factor</a></li>
<li class="chapter" data-level="9.3" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#anova-de-bloques-completos-aleatorios"><i class="fa fa-check"></i><b>9.3</b> ANOVA de bloques completos aleatorios</a></li>
<li class="chapter" data-level="9.4" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#sec:ANOVA2"><i class="fa fa-check"></i><b>9.4</b> ANOVA de dos vías</a></li>
<li class="chapter" data-level="9.5" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#condiciones-del-anova"><i class="fa fa-check"></i><b>9.5</b> Condiciones del ANOVA</a></li>
<li class="chapter" data-level="9.6" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#sec:pares"><i class="fa fa-check"></i><b>9.6</b> Comparaciones de pares de medias</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#tests-t-por-parejas"><i class="fa fa-check"></i><b>9.6.1</b> Tests t por parejas</a></li>
<li class="chapter" data-level="9.6.2" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#test-de-duncan"><i class="fa fa-check"></i><b>9.6.2</b> Test de Duncan</a></li>
<li class="chapter" data-level="9.6.3" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#método-de-tukey"><i class="fa fa-check"></i><b>9.6.3</b> Método de Tukey</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#métodos-no-paramétricos"><i class="fa fa-check"></i><b>9.7</b> Métodos no paramétricos</a></li>
<li class="chapter" data-level="9.8" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>9.8</b> Guía rápida</a></li>
<li class="chapter" data-level="9.9" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>9.9</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="9.9.1" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#ejercicio"><i class="fa fa-check"></i><b>9.9.1</b> Ejercicio</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
<li class="chapter" data-level="9.9.2" data-path="chap-ANOVA.html"><a href="chap-ANOVA.html#soluciones-sucintas-del-ejercicio"><i class="fa fa-check"></i><b>9.9.2</b> Soluciones sucintas del ejercicio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap-regresion.html"><a href="chap-regresion.html"><i class="fa fa-check"></i><b>10</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chap-regresion.html"><a href="chap-regresion.html#sec:1"><i class="fa fa-check"></i><b>10.1</b> El modelo de regresión lineal en R</a></li>
<li class="chapter" data-level="10.2" data-path="chap-regresion.html"><a href="chap-regresion.html#intervalos-de-confianza-en-el-modelo-de-regresión-lineal"><i class="fa fa-check"></i><b>10.2</b> Intervalos de confianza en el modelo de regresión lineal</a></li>
<li class="chapter" data-level="10.3" data-path="chap-regresion.html"><a href="chap-regresion.html#sec:seleccion"><i class="fa fa-check"></i><b>10.3</b> Selección del modelo en base al ajuste de los datos</a></li>
<li class="chapter" data-level="10.4" data-path="chap-regresion.html"><a href="chap-regresion.html#sec:diagn"><i class="fa fa-check"></i><b>10.4</b> Diagnósticos de regresión</a></li>
<li class="chapter" data-level="10.5" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>10.5</b> Guía rápida</a></li>
<li class="chapter" data-level="10.6" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>10.6</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-clustering.html"><a href="chap-clustering.html"><i class="fa fa-check"></i><b>11</b> <em>Clustering</em> básico</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chap-clustering.html"><a href="chap-clustering.html#método-de-k-medias-o-k-means"><i class="fa fa-check"></i><b>11.1</b> Método de k-medias o <em>k-means</em></a></li>
<li class="chapter" data-level="11.2" data-path="chap-clustering.html"><a href="chap-clustering.html#elección-del-número-de-clusters"><i class="fa fa-check"></i><b>11.2</b> Elección del número de <em>clusters</em></a></li>
<li class="chapter" data-level="11.3" data-path="chap-clustering.html"><a href="chap-clustering.html#métodos-jerárquicos-aglomerativos"><i class="fa fa-check"></i><b>11.3</b> Métodos jerárquicos aglomerativos</a></li>
<li class="chapter" data-level="11.4" data-path="chap-muestreo.html"><a href="chap-muestreo.html#guía-rápida"><i class="fa fa-check"></i><b>11.4</b> Guía rápida</a></li>
<li class="chapter" data-level="11.5" data-path="chap-distr.html"><a href="chap-distr.html#ejercicios"><i class="fa fa-check"></i><b>11.5</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#test"><i class="fa fa-check"></i>Test</a></li>
<li class="chapter" data-level="" data-path="chap-distr.html"><a href="chap-distr.html#respuestas-al-test"><i class="fa fa-check"></i>Respuestas al test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="extras-de-r-markdown.html"><a href="extras-de-r-markdown.html"><i class="fa fa-check"></i><b>12</b> Extras de <em>R Markdown</em></a>
<ul>
<li class="chapter" data-level="12.1" data-path="extras-de-r-markdown.html"><a href="extras-de-r-markdown.html#parámetros-de-los-chunks-de-r"><i class="fa fa-check"></i><b>12.1</b> Parámetros de los <em>chunks</em> de R</a></li>
<li class="chapter" data-level="12.2" data-path="extras-de-r-markdown.html"><a href="extras-de-r-markdown.html#los-chunks-en-modo-línea"><i class="fa fa-check"></i><b>12.2</b> Los <em>chunks</em> en modo línea</a></li>
<li class="chapter" data-level="12.3" data-path="extras-de-r-markdown.html"><a href="extras-de-r-markdown.html#figuras"><i class="fa fa-check"></i><b>12.3</b> Figuras</a></li>
<li class="chapter" data-level="12.4" data-path="extras-de-r-markdown.html"><a href="extras-de-r-markdown.html#tablas"><i class="fa fa-check"></i><b>12.4</b> Tablas</a></li>
<li class="chapter" data-level="12.5" data-path="extras-de-r-markdown.html"><a href="extras-de-r-markdown.html#fórmulas-matemáticas"><i class="fa fa-check"></i><b>12.5</b> Fórmulas matemáticas</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AprendeR: Parte II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap:regresion" class="section level1" number="10">
<h1><span class="header-section-number">Lección 10</span> Regresión lineal</h1>
<p>En esta lección, explicamos el uso de R para realizar regresiones lineales, tanto simples como múltiples. Presentaremos algunos ejemplos para ilustrar el uso de las funciones de R específicas para esta técnica de modelado estadístico, así como la posterior validación y adecuación del modelo mediante el análisis de los residuos. Aunque en la Lección 3 de la primera parte del curso ya introdujimos la regresión lineal sin entrar en mucha profundidad, es en esta lección donde desarrollaremos más ámpliamente este tema.</p>
<div id="sec:1" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> El modelo de regresión lineal en R</h2>
<p>Uno de los problemas recurrentes en estadística es determinar a partir de un conjunto de observaciones de variables si existe alguna relación funcional entre una de las variables, llamada <strong>variable dependiente</strong> o <strong>de respuesta</strong>, y el resto de variables, conocidas como <strong>variables independientes</strong> o <strong>de control</strong>. Los objetivos de encontrar esta relación funcional son, por un lado, entender cómo los valores de la variable dependiente “dependen” de los de las variables independientes y, por otro lado, poder estimar el valor de la variable dependiente sobre un sujeto para el que conozcamos sus valores de las variables independientes. En esta lección nos centramos en el caso en que esta relación funcional es lineal.</p>
<p>Formalmente, la situación es la siguiente. Sean <span class="math inline">\(X_1\)</span>, …, <span class="math inline">\(X_k\)</span> <em>k</em> variables (no necesariamente aleatorias), que serán las independientes, y sea <span class="math inline">\(Y\)</span> la variable dependiente. Llamemos <span class="math inline">\(Y|{x_1,\ldots, x_k}\)</span> a la variable aleatoria que nos da los valores de <span class="math inline">\(Y\)</span> sobre los individuos en los que cada variable independiente <span class="math inline">\(X_i\)</span> toma el correspondiente valor <span class="math inline">\(x_i\)</span>, y sea <span class="math inline">\(\mu_{Y|{x_1,\ldots, x_k}}\)</span> el valor esperado de <span class="math inline">\(Y|{x_1,\ldots, x_k}\)</span>. Vamos a suponer que <span class="math inline">\(\mu_{Y|{x_1,\ldots, x_k}}\)</span> es una función lineal de <span class="math inline">\(X_1\)</span>, …, <span class="math inline">\(X_k\)</span>, y que por lo tanto “en la realidad” existen unos coeficientes reales <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_k\)</span>, que desconocemos, tales que, para cada posible vector de valores <span class="math inline">\((x_1,\ldots,x_k)\)</span> de las variables independientes <span class="math inline">\(X_1\)</span>, …,<span class="math inline">\(X_k\)</span>, se tiene que<br />
<span class="math display">\[
\mu_{Y|{x_1,\ldots, x_k}}=\beta_0+\beta_1x_1+\cdots+\beta_kx_k.
\]</span></p>
<p>De esta manera, si denotamos por <span class="math inline">\(E_{x_1,\ldots,x_k}\)</span> la variable <strong>error</strong>
<span class="math display">\[
Y|{x_1,\ldots, x_k}-\mu_{Y|{x_1,\ldots, x_k}}
\]</span>
que, para cada individuo cuyas variables <span class="math inline">\(X_i\)</span> valen <span class="math inline">\(x_i\)</span>, nos da la diferencia entre su valor de <span class="math inline">\(Y\)</span> y el valor esperado de esta variable para los individuos con sus mismos valores de <span class="math inline">\(X_1\)</span>, …, <span class="math inline">\(X_k\)</span>, tenemos que
<span class="math display">\[
Y|{x_1,\ldots, x_k}=\beta_0+\beta_1x_1+\cdots+\beta_kx_k+E_{x_1,\ldots,x_k}.
\]</span>
Esta ecuación nos dice que el valor de <span class="math inline">\(Y\)</span> sobre un sujeto para el que <span class="math inline">\(X_1=x_1\)</span>, …, <span class="math inline">\(X_k=x_k\)</span>, viene dado por dos componentes: por un lado, una componente “fija” definida por el <strong>modelo lineal</strong> <span class="math inline">\(\mu_{Y|{x_1,\ldots, x_k}}=\beta_0+\beta_1x_1+\cdots+\beta_kx_k\)</span>, y por otro lado, el error aleatorio <span class="math inline">\(E_{x_1,\ldots,x_k}\)</span>. Por la linealidad de las esperanzas, como el valor esperado de <span class="math inline">\(Y|{x_1,\ldots, x_k}\)</span> es <span class="math inline">\(\beta_0+\beta_1x_1+\cdots+\beta_kx_k\)</span>, el valor esperado del error <span class="math inline">\(E_{x_1,\ldots,x_k}\)</span> es 0.</p>
<p>Si disponemos entonces de un conjunto de <em>n</em> datos
<span class="math display">\[
(x_{i1},x_{i2},\ldots,x_{ik},y)_{i=1,\ldots,n}
\]</span>
donde cada vector <span class="math inline">\((x_{i1},x_{i2},\ldots,x_{ik},y)\)</span> está formado por los valores de las variables <span class="math inline">\(X_1\)</span>, …, <span class="math inline">\(X_{k}\)</span> e <span class="math inline">\(Y\)</span> sobre un individuo,
podemos usar estos datos para estimar los valores poblacionales de <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_k\)</span>. Vamos a suponer que <span class="math inline">\(n&gt;k\)</span>, por lo que no podemos esperar encontrar los valores de <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_k\)</span> simplemente resolviendo un sistema de ecuaciones.</p>
<p>Sean <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, …, <span class="math inline">\(b_k\)</span> nuestras estimaciones de <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_k\)</span>, respectivamente, a partir de nuestro conjunto de datos. Podemos escribir entonces la <strong>función lineal de regresión</strong>
<span class="math display">\[
\widehat{y}=b_0+b_1x_{1}+\cdots+b_kx_{k}
\]</span>
que nos permite estimar por medio de <span class="math inline">\(\widehat{y}\)</span> el valor de <span class="math inline">\(Y\)</span> que esperamos que tenga un sujeto para el que las variables <span class="math inline">\(X_1\)</span>, …, <span class="math inline">\(X_{k}\)</span> valgan, respectivamente, <span class="math inline">\(x_1\)</span>, …, <span class="math inline">\(x_{k}\)</span>. En particular, para cada <span class="math inline">\(i=1,\ldots,n\)</span>, llamaremos <span class="math inline">\(\widehat{y}_i\)</span> al valor de <span class="math inline">\(Y\)</span> que estimamos sobre el sujeto <span class="math inline">\(i\)</span>-ésimo de nuestro conjunto de datos, en el que las variables <span class="math inline">\(X_1\)</span>, …, <span class="math inline">\(X_{k}\)</span> valen, respectivamente, <span class="math inline">\(x_{i1}\)</span>, …, <span class="math inline">\(x_{ik}\)</span>:
<span class="math display">\[
\widehat{y}_i=b_0+b_1x_{i1}+\cdots+b_kx_{ik}.
\]</span>
Para cada <span class="math inline">\(i=1,\ldots,n\)</span>, denotaremos por <span class="math inline">\(e_i\)</span> el <strong>error</strong> cometido con la estimación sobre el individuo <em>i</em>-ésimo de nuestro conjunto de datos, definido como la diferencia
<span class="math display">\[
y_i-\widehat{y}_i=y_i-(b_0+b_1x_{i1}+\cdots+b_kx_{ik})
\]</span>
entre el valor <span class="math inline">\(y_i\)</span> de la variable <span class="math inline">\(Y\)</span> observado sobre dicho sujeto <em>i</em>-ésimo y nuestra estimación <span class="math inline">\(\widehat{y}_i\)</span> de este valor por medio de la función lineal que hemos encontrado.</p>
<p>La mayoría de las estrategias usadas para calcular las estimaciones <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, …, <span class="math inline">\(b_k\)</span> se basan en preestablecer un cierto criterio de “bondad” de la estimación de cada <span class="math inline">\(y_i\)</span> por medio del correspondiente <span class="math inline">\(\widehat{y}_i\)</span> y encontrar entonces los coeficientes que dan las “mejores” estimaciones según este criterio. El criterio más utilizado en este sentido es el de <strong>mínimos cuadrados</strong>, en el que se minimiza la suma de los cuadrados de los errores cometidos sobre los sujetos de nuestro conjunto de datos. Es decir, en el <strong>método de mínimos cuadrados</strong> se toman como estimaciones de <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_k\)</span> los valores <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, …, <span class="math inline">\(b_k\)</span> para los que la suma
<span class="math display">\[
SS_e=\sum_{i=1}^n e_i^2=\sum_{i=1}^n(y_i-b_0-b_1x_{i1}-\cdots-b_kx_{ik})^2 
\]</span>
toma su valor mínimo: de ahí la coletilla de <strong>mínimos cuadrados</strong>. Como es el único método que vamos a explicar, a partir de ahora siempre que hablemos de <strong>regresión lineal</strong> nos referiremos a esta regresión lineal por el método de mínimos cuadrados. Además, hablaremos de <strong>regresión lineal simple</strong> si <span class="math inline">\(k=1\)</span> (es decir, cuando usamos una única variable independiente) y de <strong>regresión lineal múltiple</strong> si <span class="math inline">\(k&gt;1\)</span> (es decir, cuando usamos más de una variable independiente).</p>
<p>La función básica de R para realizar una regresión lineal es <code>lm</code>. Su sintaxis básica es</p>
<div class="sourceCode" id="cb1142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1142-1"><a href="chap-regresion.html#cb1142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(formula,<span class="at">data=</span>..., <span class="at">subset=</span>...)</span></code></pre></div>
<p>donde:</p>
<ul>
<li><p><code>formula</code> refiere a una <strong>fórmula</strong> que relaciona la variable respuesta y las variables independientes del modelo, en el sentido de las fórmulas introducidas en la Sección <a href="chap-ANOVA.html#sec:modelos">9.1</a>. Su estructura en este caso ha de ser la siguiente. En primer lugar, se escribe la variable dependiente, que necesariamente tiene que ser una variable numérica. A continuación, el símbolo ~ que indica la dependencia de esta variable respecto de las variables que se indiquen a su derecha. Finalmente, se incluyen las variables independientes separadas por símbolos +.</p></li>
<li><p><code>data</code> es un parámetro opcional que sirve para especificar, si es necesario, el <em>data frame</em> al que pertenecen las variables utilizadas en la fórmula.</p></li>
<li><p><code>subset</code> es otro parámetro opcional que sirve para especificar que la regresión sólo tenga en cuenta un subconjunto de las observaciones, definido mediante alguna condición lógica.</p></li>
</ul>
<p>Así, por ejemplo, si tenemos un <em>data frame</em> llamado <code>DF</code>, con una variable numérica <code>Y</code> y tres variables independientes <code>X1</code>, <code>X2</code> y <code>X3</code>, para realizar la regresión lineal de la variable <code>Y</code> respecto de <code>X1</code>, <code>X2</code> y <code>X3</code> se puede ejecutar</p>
<div class="sourceCode" id="cb1143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1143-1"><a href="chap-regresion.html#cb1143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Y<span class="sc">~</span>X1<span class="sc">+</span>X2<span class="sc">+</span>X3,<span class="at">data=</span>DF)</span></code></pre></div>
<p>o</p>
<div class="sourceCode" id="cb1144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1144-1"><a href="chap-regresion.html#cb1144-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(DF<span class="sc">$</span>Y<span class="sc">~</span>DF<span class="sc">$</span>X1<span class="sc">+</span>DF<span class="sc">$</span>X2<span class="sc">+</span>DF<span class="sc">$</span>X3)</span></code></pre></div>
<p>Un atajo muy útil en la ejecución de <code>lm</code> cuando nuestro <em>data frame</em> <code>DF</code> tiene muchas variables y queremos obtener la funció de regresión lineal de una variable, <code>Y</code>, respecto de todas las otras es entrar</p>
<div class="sourceCode" id="cb1145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1145-1"><a href="chap-regresion.html#cb1145-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Y<span class="sc">~</span>.,<span class="at">data=</span>DF)</span></code></pre></div>
<p>El punto a la derecha de la ~ es una abreviatura de “la suma de todas las variables de <code>DF</code> diferentes de <code>Y</code>”.</p>
<p>El siguiente ejemplo ilustra el uso de la función <code>lm</code> y de la salida que proporciona.</p>

<div class="example">
<p><span id="exm:exempDavis" class="example"><strong>Ejemplo 10.1  </strong></span>La tabla de datos <code>Davis</code> del paquete <strong>car</strong> contiene datos del peso y la altura de 200 hombres y mujeres que realizan ejercicio habitualmente obtenidos de dos formas distintas: los valores medidos con los instrumentos adecuados (báscula y escaliómetro, respectivamente) y los valores que notificaron estas personas antes de realizarse las mediciones.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> Veamos su estructura.</p>
</div>
<div class="sourceCode" id="cb1146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1146-1"><a href="chap-regresion.html#cb1146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb1146-2"><a href="chap-regresion.html#cb1146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Davis)</span>
<span id="cb1146-3"><a href="chap-regresion.html#cb1146-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Davis)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:	200 obs. of  5 variables:
##  $ sex   : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 1 1 2 1 2 2 2 2 2 ...
##  $ weight: int  77 58 53 68 59 76 76 69 71 65 ...
##  $ height: int  182 161 161 177 157 170 167 186 178 171 ...
##  $ repwt : int  77 51 54 70 59 76 77 73 71 64 ...
##  $ repht : int  180 159 158 175 155 165 165 180 175 170 ...</code></pre>
<p>En la Ayuda del objeto nos enteramos de que el factor <code>sex</code> indica el sexo del individuo, con niveles “F” y “M”; las variables cuantitativas <code>weight</code> y <code>height</code> indican, respectivamente, el peso (en kg.) y la altura (en cm.) <em>medidas</em>; y las variables cuantitativas <code>repwt</code> y <code>repht</code> indican, respectivamente, el peso (en kg.) y la altura (en cm.) <em>notificadas</em> por el individuo. Además, en la Descripción se nos avisa de que hay valores que faltan.</p>
<p>En este primer ejemplo, nos centramos en las variables <code>weight</code> y <code>repwt</code> y vamos a suponer que el peso esperado de una persona que realiza ejercicio habitualmente (nuestra <strong>población</strong> de interés) es función lineal del peso que dice que tiene, y vamos a estimar los coeficientes de esta función lineal. De esta manera, cuando una persona de la población de interés nos diga su peso, podremos estimar su peso real.</p>
<p>Lo primero que haremos será extraer un <em>data frame</em> formado por estas dos columnas, a las que renombraremos <code>pesos</code>y <code>pesosnotif</code>, respectivamente. Además, por si estas variables tienen valores NA, aplicaremos al <em>data frame</em> la función <code>na.omit</code> para eliminar filas que no correspondan a observaciones completas.</p>
<div class="sourceCode" id="cb1148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1148-1"><a href="chap-regresion.html#cb1148-1" aria-hidden="true" tabindex="-1"></a>datospeso<span class="ot">=</span><span class="fu">data.frame</span>(Davis<span class="sc">$</span>weight,Davis<span class="sc">$</span>repwt)</span>
<span id="cb1148-2"><a href="chap-regresion.html#cb1148-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(datospeso)<span class="ot">=</span><span class="fu">c</span>(<span class="st">&quot;peso&quot;</span>,<span class="st">&quot;pesonotif&quot;</span>)</span>
<span id="cb1148-3"><a href="chap-regresion.html#cb1148-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(datospeso)</span></code></pre></div>
<pre><code>##   peso pesonotif
## 1   77        77
## 2   58        51
## 3   53        54
## 4   68        70
## 5   59        59
## 6   76        76</code></pre>
<div class="sourceCode" id="cb1150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1150-1"><a href="chap-regresion.html#cb1150-1" aria-hidden="true" tabindex="-1"></a>datospeso<span class="ot">=</span><span class="fu">na.omit</span>(datospeso)</span>
<span id="cb1150-2"><a href="chap-regresion.html#cb1150-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(datospeso)</span></code></pre></div>
<pre><code>## [1] 183   2</code></pre>
<p>Han sobrevivido 183 de las 200 filas originales.</p>
<p>Para calcular la recta de regresión por mínimos cuadrados de la variable <code>peso</code> respecto de la variable <code>pesonotif</code>, usaremos la función <code>lm</code>.</p>
<div class="sourceCode" id="cb1152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1152-1"><a href="chap-regresion.html#cb1152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = peso ~ pesonotif, data = datospeso)
## 
## Coefficients:
## (Intercept)    pesonotif  
##      5.3363       0.9278</code></pre>
<p>El resultado obtenido significa que la recta de regresión buscada tiene término independiente (<code>Intercept</code>, el valor en el que la recta resultante corta el eje de ordenadas) <span class="math inline">\(b_0=5.3363\)</span> y coeficiente de la variable <code>peso</code> <span class="math inline">\(b_1=0.9278\)</span>. Es decir, tenemos
<span class="math display">\[
\widehat{\hbox{peso}}=5.3363+0.9278\cdot \hbox{pesonotif}.
\]</span></p>
<p>Vamos a representar gráficamente los puntos de la muestra conjuntamente con la recta de regresión encontrada:</p>
<div class="sourceCode" id="cb1154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1154-1"><a href="chap-regresion.html#cb1154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(datospeso<span class="sc">$</span>pesonotif, datospeso<span class="sc">$</span>peso, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">xlab=</span><span class="st">&quot;peso notificado&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;peso medido&quot;</span>)</span>
<span id="cb1154-2"><a href="chap-regresion.html#cb1154-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-570"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-570-1.png" alt="Gráfico de los pares de observaciones (pesonotif,peso) junto con la correspondiente recta de regresión." width="480" />
<p class="caption">
Figura 10.1: Gráfico de los pares de observaciones (pesonotif,peso) junto con la correspondiente recta de regresión.
</p>
</div>
<p>Como se puede observar, la recta de regresión se ajusta notablemente a los puntos de la muestra indicando un buen comportamiento del modelo a nivel visual. Sin embargo, destaca una de las observaciones que se encuentra muy alejada tanto del patrón seguido por el resto de puntos como de la recta de regresión. Para obtener a qué observación corresponde ese punto, podríamos utilizar la función <code>identify</code> de R. Si inmediatamente después de generar el gráfico anterior ejecutáis</p>
<div class="sourceCode" id="cb1155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1155-1"><a href="chap-regresion.html#cb1155-1" aria-hidden="true" tabindex="-1"></a><span class="fu">identify</span>(datospeso<span class="sc">$</span>pesonotif,datospeso<span class="sc">$</span>peso)</span></code></pre></div>
<p>al pulsar con el cursor sobre un punto del gráfico podéis saber sus coordenadas. Como en este documento esto es imposible, lo que haremos será determinar ese punto anómalo como el que tiene ordenada mayor que 160:</p>
<div class="sourceCode" id="cb1156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1156-1"><a href="chap-regresion.html#cb1156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(datospeso<span class="sc">$</span>peso<span class="sc">&gt;</span><span class="dv">160</span>)</span></code></pre></div>
<pre><code>## [1] 12</code></pre>
<div class="sourceCode" id="cb1158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1158-1"><a href="chap-regresion.html#cb1158-1" aria-hidden="true" tabindex="-1"></a>datospeso[<span class="fu">which</span>(datospeso<span class="sc">$</span>peso<span class="sc">&gt;</span><span class="dv">160</span>),]</span></code></pre></div>
<pre><code>##    peso pesonotif
## 12  166        56</code></pre>
<p>El punto anómalo, correspondiente al individuo 12 de la muestra, ¡dijo que pesaba 56 kg y en realidad pesaba 166! Más adelante, en la Sección <a href="chap-regresion.html#sec:diagn">10.4</a>, trataremos el procedimiento a seguir en estas situaciones.</p>
<p>Veamos un segundo ejemplo.</p>

<div class="example">
<p><span id="exm:exempUSA" class="example"><strong>Ejemplo 10.2  </strong></span>El fichero de datos “USA2012.txt” que podéis descargar desde el enlace <a href="https://raw.githubusercontent.com/AprendeR-UIB/Material/master/USA2012.txt" class="uri">https://raw.githubusercontent.com/AprendeR-UIB/Material/master/USA2012.txt</a> contiene datos demográficos, sociales y económicos de los 50 estados de los Estados Unidos más el distrito de Columbia correspondientes al año 2012, el año que Barack Obama ganó sus segundas elecciones presidenciales. Estos datos han sido recopilados de diversas fuentes como el <em>United States Census Bureau</em>, el <em>Pew Research Center</em> o el <em>Bureau of Labor Statistics</em>. Vamos a cargarlo en un <em>data frame</em> y consultar su estructura.</p>
</div>
<div class="sourceCode" id="cb1160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1160-1"><a href="chap-regresion.html#cb1160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb1160-2"><a href="chap-regresion.html#cb1160-2" aria-hidden="true" tabindex="-1"></a>datos<span class="ot">=</span><span class="fu">getURL</span>(<span class="st">&quot;https://raw.githubusercontent.com/AprendeR-UIB/Material/master/USA2012.txt&quot;</span>)</span>
<span id="cb1160-3"><a href="chap-regresion.html#cb1160-3" aria-hidden="true" tabindex="-1"></a>USA<span class="ot">=</span><span class="fu">read.table</span>(<span class="at">text=</span>datos,<span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb1160-4"><a href="chap-regresion.html#cb1160-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(USA)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:	51 obs. of  21 variables:
##  $ estado        : Factor w/ 51 levels &quot;Alabama&quot;,&quot;Alaska&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ region        : int  3 4 4 3 4 4 1 3 3 3 ...
##  $ densidad      : num  94.4 1.2 56.3 56 239.1 ...
##  $ veteranos     : num  8.1 10.1 8.2 7.9 5 8.1 6 8.5 5.2 8.3 ...
##  $ mujeres       : num  51.5 48 50.3 50.9 50.3 49.9 51.3 51.6 52.8 51.1 ...
##  $ grad_instituto: num  82.6 91.6 85.4 83.3 81 89.9 89 87.7 87.5 85.8 ...
##  $ grad_univ     : num  22.3 27.5 26.6 19.8 30.5 36.7 36.2 28.5 51.2 26.2 ...
##  $ afro          : num  26.2 3.3 4.1 15.4 6.2 4 10.1 21.4 50.7 16 ...
##  $ asia          : num  1.1 5.4 2.8 1.2 13 2.8 3.8 3.2 3.5 2.4 ...
##  $ hispanos      : num  3.9 5.5 29.6 6.4 37.6 20.7 13.4 8.2 9.1 22.5 ...
##  $ blancos       : num  67 64.1 57.8 74.5 40.1 70 71.2 65.3 34.8 57.9 ...
##  $ evangelicos   : int  49 26 23 53 18 23 9 15 15 25 ...
##  $ protestantes  : int  1 19 15 16 14 19 13 18 20 15 ...
##  $ relig_afro    : int  18 2 2 10 4 2 4 14 18 8 ...
##  $ catolicos     : int  6 14 25 5 31 19 43 27 18 26 ...
##  $ mormones      : int  1 4 4 0 2 2 1 0 0 0 ...
##  $ jubilados     : num  13.8 7.7 13.8 14.4 11.4 10.9 14.2 14.4 11.4 17.3 ...
##  $ paro          : num  8 7.6 8.4 7.6 10.4 7.8 8.3 7.2 9 8.5 ...
##  $ salario       : int  43464 63648 47044 39018 57020 57255 64247 48972 65246 46071 ...
##  $ obama         : num  38.4 40.8 44.6 36.9 60.2 ...
##  $ diputados     : int  9 3 11 6 55 9 7 3 3 29 ...</code></pre>
<p>Calculemos, por ejemplo, la recta de regresión del porcentaje de voto a Obama (variable <code>obama</code>) con respecto al porcentaje de graduados universitarios del estado (variable <code>grad_univ</code>):</p>
<div class="sourceCode" id="cb1162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1162-1"><a href="chap-regresion.html#cb1162-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ,<span class="at">data=</span>USA)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obama ~ grad_univ, data = USA)
## 
## Coefficients:
## (Intercept)    grad_univ  
##       7.812        1.460</code></pre>
<p>Se obtiene la recta
<span class="math display">\[
\widehat{\hbox{obama}}=7.812+1.46\cdot \hbox{grad_univ}.
\]</span>
Como podemos observar, a mayor porcentaje de graduados universitarios, el modelo nos predice un mayor porcentaje de voto a Obama. Añadamos ahora al modelo la variable <code>veteranos</code> que indica el porcentaje de veteranos de guerra en la población del estado.</p>
<div class="sourceCode" id="cb1164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1164-1"><a href="chap-regresion.html#cb1164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ<span class="sc">+</span>veteranos,<span class="at">data=</span>USA)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obama ~ grad_univ + veteranos, data = USA)
## 
## Coefficients:
## (Intercept)    grad_univ    veteranos  
##     13.7318       1.4104      -0.5981</code></pre>
<p>En este caso, la ecuación de regresión es
<span class="math display">\[
\widehat{\hbox{obama}}=13.732+1.41\cdot \hbox{grad_univ}-0.598\cdot \hbox{veteranos}.
\]</span>
Así, mientras que un mayor porcentaje de graduados universitarios sigue correspondiéndose a un mayor porcentaje de voto a Obama, un mayor porcentaje de veteranos en la población lleva asociada una disminución de este porcentaje de voto.</p>
<p>Ya hemos visto que los coeficientes de la recta de regresión se pueden obtener simplemente ejecutando la función <code>lm</code>. Sin embargo, esta función nos puede proporcionar mucha información adicional, aplicando <code>summary</code> al resultado de <code>lm</code>. Volvamos al Ejemplo <a href="chap-regresion.html#exm:exempDavis">10.1</a>.</p>
<div class="sourceCode" id="cb1166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1166-1"><a href="chap-regresion.html#cb1166-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = peso ~ pesonotif, data = datospeso)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
##  -7.048  -1.868  -0.728   0.601 108.705 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   5.3363     3.0369   1.757   0.0806 .  
## pesonotif     0.9278     0.0453  20.484   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.419 on 181 degrees of freedom
## Multiple R-squared:  0.6986,	Adjusted R-squared:  0.697 
## F-statistic: 419.6 on 1 and 181 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>En esta salida encontramos la siguiente información:</p>
<ul>
<li><p>En <code>Residuals</code>, se proporciona un resumen descriptivo de los residuos o errores <span class="math inline">\(e_i\)</span> del modelo, concretamente, sus valores mínimo y máximo y sus cuartiles.</p></li>
<li><p>En la tabla de <code>Coefficients</code>, en la columna <code>Estimate</code> se dan las estimaciones de los coeficientes de cada variable de la función de regresión, junto a sus respectivos errores típicos en la columna <code>Std. Error</code>. A continuación, las columnas <code>t value</code> y <code>Pr(&gt;|t|)</code> proporcionan para cada coeficiente <span class="math inline">\(\beta_i\)</span> el valor del estadístico y el p-valor del contraste
<span class="math display">\[
\left\{\begin{array}{ll} 
H_0:&amp; \beta_i=0\\ H_1:&amp; \beta_i\neq 0
\end{array}\right.
\]</span>
R indica el significado estadístico de cada p-valor a su derecha mediante el código usual de estrellas.</p></li>
<li><p>Después de la tabla, encontramos el <code>Residual standard error</code> que corresponde a la raíz del valor estimado de la varianza común de los residuos <span class="math inline">\(S=\sqrt{\frac{SS_E}{n-k-1}}\)</span>, junto con los grados de libertad <span class="math inline">\(n-k-1\)</span>.</p></li>
<li><p>En la siguiente fila, tenemos los valores <code>Multiple R-squared</code> y <code>Adjusted R-squared</code>, es decir, los coeficientes de determinación <span class="math inline">\(R^2\)</span> y de determinación ajustado <span class="math inline">\(R^2_{adj}\)</span>, respectivamente. Recordemos que
<span class="math display">\[
R^2=\dfrac{s_{\widehat{y}}^2}{s_{y}^2}, \quad R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span>
donde <span class="math inline">\(s_{y}^2\)</span> y <span class="math inline">\(s_{\widehat{y}}^2\)</span> denotan la varianza de los valores de <span class="math inline">\(y\)</span> en nuestra muestra y de los valores de <span class="math inline">\(y\)</span> que predice nuestro modelo sobre los puntos de la muestra, respectivamente. Cuánto mejor aproxime la función de regresión el conjunto de puntos, más cercanos a 1 serán los valores de estos índices ya que representan la fracción de variabilidad de <span class="math inline">\(y\)</span> explicada por el modelo de regresión lineal.</p></li>
<li><p>En la última fila, aparecen el valor del estadístico <span class="math inline">\(F\)</span>, los grados de libertad, 1 y <em>n-k-1</em>, y el p-valor, en este orden, del siguiente contraste ANOVA:
<span class="math display">\[
\left\{\begin{array}{ll} 
H_0:&amp;\beta_1=\cdots=\beta_k=0\\ H_1:&amp; \hbox{existe al menos un } \beta_i\neq 0
\end{array}\right.
\]</span>
En la regresión lineal simple, este contraste es equivalente al contraste para <span class="math inline">\(\beta_1\)</span> dado en la tabla <code>Coefficients</code>.</p></li>
</ul>
<p>En este ejemplo concreto, hay que destacar que el valor de <span class="math inline">\(R^2\)</span> es 0.6986, un valor relativamente bajo. También podemos inferir que <span class="math inline">\(\beta_1\neq 0\)</span> ya que el p-valor correspondiente al contraste para la variable <code>pesonotif</code> es pequeño.
Observad que si <span class="math inline">\(\beta_1\)</span> fuera 0, los valores de la variable <code>peso</code> no dependerían de los de la variable <code>pesonotif</code> y el modelo carecería de sentido. Por lo tanto, hemos obtenido evidencia de que el modelo lineal puede ser válido.</p>
<p>La información proporcionada por <code>summary(lm( ))</code> se puede extraer individualmente ya que se trata de una <code>list</code>. Veamos algunos ejemplos.</p>
<ul>
<li>El coeficiente de determinación se obtiene con el sufijo <code>$r.squared</code>:</li>
</ul>
<div class="sourceCode" id="cb1168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1168-1"><a href="chap-regresion.html#cb1168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))<span class="sc">$</span>r.squared </span></code></pre></div>
<pre><code>## [1] 0.6986308</code></pre>
<ul>
<li>El coeficiente de determinación ajustado se obtiene con el sufijo <code>$adj.r.squared</code>:</li>
</ul>
<div class="sourceCode" id="cb1170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1170-1"><a href="chap-regresion.html#cb1170-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))<span class="sc">$</span>adj.r.squared </span></code></pre></div>
<pre><code>## [1] 0.6969658</code></pre>
<ul>
<li>La tabla de coeficientes se obtiene con el sufijo <code>$coefficients</code>:</li>
</ul>
<div class="sourceCode" id="cb1172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1172-1"><a href="chap-regresion.html#cb1172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))<span class="sc">$</span>coefficients </span></code></pre></div>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) 5.3362605 3.03690979  1.757135 8.058558e-02
## pesonotif   0.9278428 0.04529609 20.483950 5.102807e-49</code></pre>
<ul>
<li>Las estimaciones de los coeficientes forman la primera columna de la tabla anterior, y por lo tanto se obtienen con el sufijo <code>$coefficients[,1]</code>:</li>
</ul>
<div class="sourceCode" id="cb1174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1174-1"><a href="chap-regresion.html#cb1174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))<span class="sc">$</span>coefficients[,<span class="dv">1</span>] </span></code></pre></div>
<pre><code>## (Intercept)   pesonotif 
##   5.3362605   0.9278428</code></pre>
<ul>
<li>Los residuos se obtienen con el sufijo <code>$residuals</code>:</li>
</ul>
<div class="sourceCode" id="cb1176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1176-1"><a href="chap-regresion.html#cb1176-1" aria-hidden="true" tabindex="-1"></a>residuos<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))<span class="sc">$</span>residuals</span>
<span id="cb1176-2"><a href="chap-regresion.html#cb1176-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(residuos)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6 
##  0.2198430  5.3437561 -2.4397724 -2.2852573 -1.0789864  0.1476858</code></pre>
<ul>
<li>Los residuos también se obtienen a partir del resultado de <code>lm</code> con el mismo sufijo <code>$residuals</code>:</li>
</ul>
<div class="sourceCode" id="cb1178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1178-1"><a href="chap-regresion.html#cb1178-1" aria-hidden="true" tabindex="-1"></a>recta_regresion<span class="ot">=</span><span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso)</span>
<span id="cb1178-2"><a href="chap-regresion.html#cb1178-2" aria-hidden="true" tabindex="-1"></a>Residuos<span class="ot">=</span>recta_regresion<span class="sc">$</span>residuals</span>
<span id="cb1178-3"><a href="chap-regresion.html#cb1178-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Residuos)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6 
##  0.2198430  5.3437561 -2.4397724 -2.2852573 -1.0789864  0.1476858</code></pre>
<ul>
<li>Los valores <span class="math inline">\(\widehat{y}_i\)</span> de la variable dependiente predichos por el modelo sobre los sujetos de la muestra se obtienen añadiendo al resultado de <code>lm</code> el sufijo <code>$fitted.values</code>:</li>
</ul>
<div class="sourceCode" id="cb1180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1180-1"><a href="chap-regresion.html#cb1180-1" aria-hidden="true" tabindex="-1"></a>estimados<span class="ot">=</span>recta_regresion<span class="sc">$</span>fitted.values</span>
<span id="cb1180-2"><a href="chap-regresion.html#cb1180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(estimados)</span></code></pre></div>
<pre><code>##        1        2        3        4        5        6 
## 76.78016 52.65624 55.43977 70.28526 60.07899 75.85231</code></pre>
<p>Recordemos que en este caso, el valor del coeficiente de determinación <span class="math inline">\(R^2\)</span> no ha sido muy alto. Sin embargo, hemos observado que visualmente la gran mayoría de observaciones se ajustan a la recta de regresión salvo la observación anómala 12. A continuación, calcularemos la recta de regresión sin tener en cuenta esta observación mediante el uso del parámetro <code>subset</code> de la función <code>lm</code>.</p>
<div class="sourceCode" id="cb1182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1182-1"><a href="chap-regresion.html#cb1182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso,<span class="at">subset=</span><span class="sc">-</span><span class="dv">12</span>))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = peso ~ pesonotif, data = datospeso, subset = -12)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.5296 -1.1010 -0.1322  1.1287  6.3891 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.73380    0.81479   3.355 0.000967 ***
## pesonotif    0.95837    0.01214  78.926  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.254 on 180 degrees of freedom
## Multiple R-squared:  0.9719,	Adjusted R-squared:  0.9718 
## F-statistic:  6229 on 1 and 180 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb1184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1184-1"><a href="chap-regresion.html#cb1184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(datospeso<span class="sc">$</span>pesonotif, datospeso<span class="sc">$</span>peso, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">xlab=</span><span class="st">&quot;peso notificado&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;peso medido&quot;</span>)</span>
<span id="cb1184-2"><a href="chap-regresion.html#cb1184-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1184-3"><a href="chap-regresion.html#cb1184-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso,<span class="at">subset=</span><span class="sc">-</span><span class="dv">12</span>), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-585"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-585-1.png" alt="Gráfico de los pares de observaciones (pesonotif,peso) junto con las  rectas de regresión teniendo en cuenta el valor anómalo (roja continua) y sin tenerlo en cuenta (azul discontinua)." width="480" />
<p class="caption">
Figura 10.2: Gráfico de los pares de observaciones (pesonotif,peso) junto con las rectas de regresión teniendo en cuenta el valor anómalo (roja continua) y sin tenerlo en cuenta (azul discontinua).
</p>
</div>
<p>Excluyendo la observación 12 del cálculo de la recta de regresión hemos obtenido un coeficiente de determinación mucho mayor que el inicial. Por otro lado, en el gráfico vemos como la observación anómala “atrae” la recta de regresión disminuyendo su pendiente.</p>
<p>Hemos utilizado la función <code>lm</code> para calcular la nueva recta de regresión. Otra posibilidad hubiera sido usar la función <code>update</code>, que permite recalcular la recta de regresión a partir de una recta de regresión anterior. Su sintaxis es la siguiente:</p>
<div class="sourceCode" id="cb1185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1185-1"><a href="chap-regresion.html#cb1185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">update</span>(x, formula., <span class="at">subset=</span>...)</span></code></pre></div>
<p>donde</p>
<ul>
<li><p><code>x</code> es un modelo de regresión lineal, es decir, la salida de una función <code>lm</code>.</p></li>
<li><p><code>formula.</code> es un parámetro opcional que indica un cambio en la <code>formula</code> especificada para obtener el nuevo modelo: si no cambiamos la fórmula, no hay que añadirlo. Es muy útil en regresión lineal múltiple para eliminar una de las variables consideradas. En este caso entraríamos como <code>formula.</code> la expresión <code>.~.-X</code>, donce <code>X</code> es la variable que queremos eliminar. Esta construcción indica que se ha de utilizar la misma <code>formula</code> que en el modelo <code>x</code> pero ahora sin tener en cuenta la variable independiente <code>X</code>.</p></li>
<li><p><code>subset</code> también es un parámetro opcional y tiene el mismo significado que en la función <code>lm</code>.</p></li>
</ul>
<p>Naturalmente, se tiene que especificar al menos uno de estos dos parámetros opcionales, o del contrario no estaremos modificando el modelo lineal <code>x</code>.</p>
<p>La salida de la función <code>update</code> es similar a la de <code>lm</code>. Así, con la instrucción siguiente, se obtiene el coeficiente de determinación anterior:</p>
<div class="sourceCode" id="cb1186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1186-1"><a href="chap-regresion.html#cb1186-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">update</span>(recta_regresion,<span class="at">subset=</span><span class="sc">-</span><span class="dv">12</span>))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9719157</code></pre>
<p>Vamos a calcular a continuación los valores de <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2_{adj}\)</span> de los modelos considerados en el Ejemplo <a href="chap-regresion.html#exm:exempUSA">10.2</a>.</p>
<div class="sourceCode" id="cb1188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1188-1"><a href="chap-regresion.html#cb1188-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ,<span class="at">data=</span>USA))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.5119194</code></pre>
<div class="sourceCode" id="cb1190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1190-1"><a href="chap-regresion.html#cb1190-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ,<span class="at">data=</span>USA))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.5019585</code></pre>
<div class="sourceCode" id="cb1192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1192-1"><a href="chap-regresion.html#cb1192-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ<span class="sc">+</span>veteranos,<span class="at">data=</span>USA))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.5154579</code></pre>
<div class="sourceCode" id="cb1194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1194-1"><a href="chap-regresion.html#cb1194-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ<span class="sc">+</span>veteranos,<span class="at">data=</span>USA))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.4952686</code></pre>
<p>Sobre el uso de los valores <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2_{adj}\)</span> hay varias consideraciones a realizar. En primer lugar, hay que tener en cuenta que el valor de <span class="math inline">\(R^2\)</span> se mantendrá o crecerá si añadimos nuevas variables independientes al modelo. Esto es debido a que se plantea un modelo más general que incluye el anterior y por lo tanto, siempre se explicará como mínimo el mismo porcentaje de variabilidad de <span class="math inline">\(y\)</span>. Así se puede observar en este ejemplo, en el que el modelo <code>obama~grad_univ+veteranos</code> obtiene un valor mayor de <span class="math inline">\(R^2\)</span> que <code>obama~grad_univ</code>. Teniendo en cuenta este hecho, y con el objetivo de conseguir un equilibrio entre la complejidad del modelo y el ajuste a los datos, se recomienda usar los valores de <span class="math inline">\(R^2_{adj}\)</span> para comparar modelos de regresión lineal múltiple. Este coeficiente penaliza la adición de una nueva variable a no ser que esta adición suponga una mejora sustancial del ajuste del modelo a los datos. Así, como el modelo <code>obama~grad_univ</code> tiene un valor de <span class="math inline">\(R^2_{adj}\)</span> mayor, se considera que es un modelo mejor al que contempla también la variable <code>veteranos</code>.</p>
<p>Veamos finalmente qué ocurre si consideramos todas las variables sociales, demográficas y económicas para explicar el porcentaje de voto a Obama en un estado. Para simplificar nuestra tarea, definimos el <em>data frame</em> <code>USA2</code> que contiene solo estas variables, eliminando de la tabla <code>USA</code> original las variables que dan el estado, la región y el número de diputados.</p>
<div class="sourceCode" id="cb1196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1196-1"><a href="chap-regresion.html#cb1196-1" aria-hidden="true" tabindex="-1"></a>USA2<span class="ot">=</span>USA[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">21</span>)]</span>
<span id="cb1196-2"><a href="chap-regresion.html#cb1196-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>.,<span class="at">data=</span>USA2))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.8278411</code></pre>
<p>El modelo mejora de forma muy significativa. Hemos usado la fórmula <code>obama~.</code> para considerar el resto de variables de <code>USA2</code> como variables independientes.</p>
</div>
<div id="intervalos-de-confianza-en-el-modelo-de-regresión-lineal" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Intervalos de confianza en el modelo de regresión lineal</h2>
<p>Nuestro siguiente objetivo es calcular intervalos de confianza para los coeficientes <span class="math inline">\(\beta_i\)</span> del modelo lineal así como para el valor esperado <span class="math inline">\(\mu_{Y|{x_1 \ldots x_k}}\)</span> y el valor estimado <span class="math inline">\(y_0\)</span> de <span class="math inline">\(Y\)</span> sobre un sujeto en el que <span class="math inline">\((X_1,\ldots,X_k)=(x_1,\ldots,x_k)\)</span>.</p>
<p>La función de R que calcula intervalos de confianza para los coeficientes <span class="math inline">\(\beta_i\)</span> es <code>confint</code>. Su sintaxis básica es</p>
<div class="sourceCode" id="cb1198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1198-1"><a href="chap-regresion.html#cb1198-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(objeto, parm, <span class="at">level=</span>...)</span></code></pre></div>
<p>donde:</p>
<ul>
<li><p><code>objeto</code> es el resultado de una función <code>lm</code>.</p></li>
<li><p><code>parm</code> permite indicar para qué parámetros se tienen que calcular los intervalos de confianza. Tanto se puede igualar a un vector de números (empezando a contar por el término independiente) como a un vector con los nombres de las variables independientes correspondientes a dichos parámetros. Por defecto se calculan los intervalos de confianza para todos los parámetros.</p></li>
<li><p><code>level</code> es el nivel de confianza. Por defecto, se calculan intervalos de confianza al 95%.</p></li>
</ul>
<p>Veamos una aplicación de la función <code>confint</code>. Vamos a calcular los intervalos de confianza del 95% para los parámetros <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> del Ejemplo <a href="chap-regresion.html#exm:exempDavis">10.1</a>. Recordad que hemos llamado <code>recta_regresion</code> al resultado correspondiente de la función <code>lm</code>.</p>
<div class="sourceCode" id="cb1199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1199-1"><a href="chap-regresion.html#cb1199-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(recta_regresion)</span></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -0.6560394 11.328560
## pesonotif    0.8384665  1.017219</code></pre>
<p>La salida de la función es una matriz cuyas filas son los extremos inferior y superior de los intervalos de confianza de los coeficientes deseados. Las filas se indican con el nombre de la variable dependiente correspondiente o con <code>(Intercept)</code> en el caso del término independiente, y las columnas se indican mediante el nivel del cuantil utilizado para el cálculo del intervalo. Así, el intervalo de confianza para <span class="math inline">\(\beta_0\)</span> es (-0.656, 11.329) y para <span class="math inline">\(\beta_1\)</span>, (0.838, 1.017).</p>
<p>Si solo queremos calcular el intervalo de confianza para <span class="math inline">\(\beta_1\)</span> podemos usar cualquiera de las tres instrucciones siguientes (aunque la tercera en realidad calculará todos los intervalos de confianza y solo nos mostrará el de <span class="math inline">\(\beta_1\)</span>):</p>
<div class="sourceCode" id="cb1201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1201-1"><a href="chap-regresion.html#cb1201-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(recta_regresion, <span class="at">parm=</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>##               2.5 %   97.5 %
## pesonotif 0.8384665 1.017219</code></pre>
<div class="sourceCode" id="cb1203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1203-1"><a href="chap-regresion.html#cb1203-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(recta_regresion, <span class="at">parm=</span><span class="st">&quot;pesonotif&quot;</span>)</span></code></pre></div>
<pre><code>##               2.5 %   97.5 %
## pesonotif 0.8384665 1.017219</code></pre>
<div class="sourceCode" id="cb1205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1205-1"><a href="chap-regresion.html#cb1205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(recta_regresion)[<span class="dv">2</span>,]</span></code></pre></div>
<pre><code>##     2.5 %    97.5 % 
## 0.8384665 1.0172191</code></pre>
<p>Una de las utilidades básicas de los intervalos de confianza es poder contrastar si la variable correspondiente aporta información al modelo o no. Este hecho, además de venir determinado por el p-valor obtenido en la tabla de coeficientes en la salida de <code>lm</code>, también se puede decidir comprobando si 0 pertenece al intervalo de confianza para el coeficiente. En caso afirmativo, no se puede descartar que la <span class="math inline">\(\beta_i\)</span> correspondiente sea 0 y en consecuencia, podría ocurrir que la variable <span class="math inline">\(X_i\)</span> no influyera en el modelo. En este ejemplo concreto, 0 no pertenece al intervalo de confianza del 95% para <span class="math inline">\(\beta_1\)</span>, y por lo tanto podemos concluir (con un nivel de significación del 5%) que el peso de un individuo está relacionado con el peso que afirma que tiene. Fijaos en que 0 sí que pertenece al intervalo de confianza del 95% para <span class="math inline">\(\beta_0\)</span>, por lo que con este nivel de significación no podemos rechazar que <span class="math inline">\(\beta_0=0\)</span>, pero esto no afecta la conclusión anterior.</p>
<p>Si hacemos lo mismo para la regresión lineal del voto de Obama en función de las variables <code>grad_univ</code> y <code>veteranos</code>, obtenemos:</p>
<div class="sourceCode" id="cb1207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1207-1"><a href="chap-regresion.html#cb1207-1" aria-hidden="true" tabindex="-1"></a>recta_reg<span class="ot">=</span><span class="fu">lm</span>(obama<span class="sc">~</span>grad_univ<span class="sc">+</span>veteranos,<span class="at">data=</span>USA)</span>
<span id="cb1207-2"><a href="chap-regresion.html#cb1207-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(recta_reg)</span></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -9.6169060 37.080465
## grad_univ    0.9650792  1.855656
## veteranos   -2.6293525  1.433104</code></pre>
<div class="sourceCode" id="cb1209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1209-1"><a href="chap-regresion.html#cb1209-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(recta_reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obama ~ grad_univ + veteranos, data = USA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -28.0415  -5.0620   0.7336   6.1104  20.2152 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  13.7318    11.6126   1.182    0.243    
## grad_univ     1.4104     0.2215   6.368 6.85e-08 ***
## veteranos    -0.5981     1.0102  -0.592    0.557    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.391 on 48 degrees of freedom
## Multiple R-squared:  0.5155,	Adjusted R-squared:  0.4953 
## F-statistic: 25.53 on 2 and 48 DF,  p-value: 2.805e-08</code></pre>
<p>El intervalo de confianza para el coeficiente <span class="math inline">\(\beta_2\)</span>, el correspondiente a la variable <code>veteranos</code>, contiene el 0 y por lo tanto, no se puede descartar que esta variable de hecho no influya en el modelo. Observad que el p-valor de esta variable en la tabla de coeficientes es muy grande, por lo que podemos llegar a esta conclusión a partir de este p-valor. Esto es coherente con la disminución del valor de <span class="math inline">\(R^2_{adj}\)</span> cuando añadíamos la variable <code>veteranos</code> al modelo. El ajuste mejora pero no compensa el aumento de complejidad y de hecho, no está claro que esta variable influya en la variable de respuesta.</p>
<p>Llegados a este punto, vamos a introducir la función <code>predict</code> que sirve para calcular intervalos de confianza para las estimaciones de la variable dependiente. La sintaxis de esta función es la siguiente:</p>
<div class="sourceCode" id="cb1211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1211-1"><a href="chap-regresion.html#cb1211-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(objeto, newdata, <span class="at">interval=</span>..., <span class="at">level=</span>...)</span></code></pre></div>
<p>donde:</p>
<ul>
<li><p><code>objeto</code> es una salida de la función <code>lm</code>.</p></li>
<li><p><code>newdata</code> es un <em>data frame</em> del que la función <code>predict</code> toma los valores de las variables independientes de los individuos para los que queremos predecir el valor de la variable dependiente. Por lo tanto, el <em>data frame</em> que entremos en este parámetro tiene que tener como columnas las variables independientes del modelo, y <code>predict</code> calculará un intervalo de confianza para cada una de sus filas.</p></li>
<li><p><code>interval</code> es un parámetro con tres posibles valores:</p>
<ul>
<li><p><code>"none"</code>, con el que simplemente se calcula el valor de la variable dependiente que predice la función lineal de regresión para cada individuo descrito en <code>newdata</code>.</p></li>
<li><p><code>"confidence"</code>, con el que se calcula el intervalo de confianza para el valor <em>esperado</em> de la variable dependiente para cada individuo descrito en <code>newdata</code>.</p></li>
<li><p><code>"prediction"</code>, con el que se calcula el intervalo de confianza para el valor de la variable dependiente <em>predicho</em> por la función de regresión para los individuos cada individuo descrito en <code>newdata</code>.</p></li>
</ul></li>
<li><p><code>level</code>, como siempre, indica el nivel de confianza y por defecto vale 0.95.</p></li>
</ul>
<p>Volvamos a la recta de regresión encontrada en el Ejemplo <a href="chap-regresion.html#exm:exempDavis">10.1</a>. Vamos a calcular algunos intervalos de confianza para estimaciones de pesos a partir de valores notificados. Supongamos que tenemos dos individuos de nuestra población de interés, un dice que pesa 70 kg y el otro que pesa 100 kg. Entramos estos datos en un <em>data frame</em> de única variable <code>pesonotif</code>:</p>
<div class="sourceCode" id="cb1212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1212-1"><a href="chap-regresion.html#cb1212-1" aria-hidden="true" tabindex="-1"></a>individuos<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">pesonotif=</span><span class="fu">c</span>(<span class="dv">70</span>,<span class="dv">100</span>))</span></code></pre></div>
<p>Entonces:</p>
<ul>
<li>Estimamos que pesan</li>
</ul>
<div class="sourceCode" id="cb1213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1213-1"><a href="chap-regresion.html#cb1213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(recta_regresion,individuos,<span class="at">interval=</span><span class="st">&quot;none&quot;</span>),<span class="dv">1</span>)</span></code></pre></div>
<pre><code>##    1    2 
## 70.3 98.1</code></pre>
<ul>
<li>Los intervalos de confianza del 95% para lo que esperamos que pesen son:</li>
</ul>
<div class="sourceCode" id="cb1215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1215-1"><a href="chap-regresion.html#cb1215-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(recta_regresion,individuos,<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>),<span class="dv">1</span>)</span></code></pre></div>
<pre><code>##    fit  lwr   upr
## 1 70.3 69.0  71.6
## 2 98.1 94.8 101.4</code></pre>
<ul>
<li>Los intervalos de confianza del 95% para lo que predecimos que pesan son:</li>
</ul>
<div class="sourceCode" id="cb1217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1217-1"><a href="chap-regresion.html#cb1217-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(recta_regresion,individuos,<span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>),<span class="dv">1</span>)</span></code></pre></div>
<pre><code>##    fit  lwr   upr
## 1 70.3 53.6  86.9
## 2 98.1 81.2 115.1</code></pre>
<p>Como podéis ver, la salida de la función <code>predict</code> es una matriz cuyas filas corresponden a los individuos representados en el <em>data frame </em>que le entramos, en el mismo orden que las filas de ese <em>data frame</em> (o un vector, si el data frame tiene una sola fila) y tres columnas:</p>
<ul>
<li><code>fit</code>: los valores predichos por la función de regresión.</li>
<li><code>lwr</code> y <code>upr</code>: los extremos inferior (<em>lower</em>) y superior (<em>upper</em>), respectivamente, de los intervalos de confianza que se han pedido.</li>
</ul>
<p>Así, por ejemplo, tenemos que si una persona dice que pesa 100 kg, entonces nuestra recta de regresión predice que pesará 98.1 kg con un intervalo de confianza para esta predicción que va de 81.2 a 115.1 kg. Además, tenemos una confianza del 95% en que, de media, los individuos que dicen que pesan 100 kg en realidad pesan entre 94.8 y 101.4 kg.</p>
<p>Observad que los intervalos de confianza obtenidos con <code>interval="prediction"</code> son más anchos que los obtenidos con <code>interval="confidence"</code>. Naturalmente, tenemos una mayor incertidumbre a la hora de predecir el peso de un individuo concreto que dice que pesa <em>X</em> que al predecir el peso medio de todos los individuos que dicen que pesan <em>X</em>, lo que se traduce en las anchuras de los intervalos de confianza.</p>
<p>Veamos una aplicación real de estos intervalos de confianza. Vamos a suponer que el porcentaje de voto demócrata en las elecciones presidenciales del 2016 iba a seguir el mismo modelo que en las elecciones del 2012 y que podemos estimar el porcentaje de voto demócrata a partir de las variables socio-económicas y demográficas de los estados. Disponemos de los valores de las variables independientes para el estado de Virginia correspondientes al año 2015 (últimos valores publicados con anterioridad a las elecciones del 2016), y vamos a calcular los intervalos de confianza para el porcentaje de voto demócrata y para su valor esperado en el estado de Virginia:</p>
<div class="sourceCode" id="cb1219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1219-1"><a href="chap-regresion.html#cb1219-1" aria-hidden="true" tabindex="-1"></a>virginia2015<span class="ot">=</span>virginia2015<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">densidad=</span><span class="fl">81.4</span>,<span class="at">veteranos=</span><span class="fl">9.4</span>,<span class="at">mujeres=</span><span class="fl">50.8</span>,</span>
<span id="cb1219-2"><a href="chap-regresion.html#cb1219-2" aria-hidden="true" tabindex="-1"></a><span class="at">grad_instituto=</span><span class="fl">88.5</span>,<span class="at">grad_univ=</span><span class="fl">36.7</span>,<span class="at">afro=</span><span class="fl">19.7</span>,<span class="at">asia=</span><span class="fl">6.3</span>,<span class="at">hispanos=</span><span class="fl">8.9</span>,</span>
<span id="cb1219-3"><a href="chap-regresion.html#cb1219-3" aria-hidden="true" tabindex="-1"></a><span class="at">blancos=</span><span class="fl">63.1</span>,<span class="at">evangelicos=</span><span class="dv">30</span>,<span class="at">protestantes=</span><span class="dv">16</span>,<span class="at">relig_afro=</span><span class="dv">12</span>,<span class="at">catolicos=</span><span class="dv">12</span>,</span>
<span id="cb1219-4"><a href="chap-regresion.html#cb1219-4" aria-hidden="true" tabindex="-1"></a><span class="at">mormones=</span><span class="dv">2</span>, <span class="at">jubilados=</span><span class="fl">13.8</span>,<span class="at">paro=</span><span class="fl">4.3</span>,<span class="at">salario=</span><span class="dv">66155</span>)</span>
<span id="cb1219-5"><a href="chap-regresion.html#cb1219-5" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>.,<span class="at">data=</span>USA2),virginia2015,<span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 49.87625 37.00499 62.74752</code></pre>
<div class="sourceCode" id="cb1221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1221-1"><a href="chap-regresion.html#cb1221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(<span class="fu">lm</span>(obama<span class="sc">~</span>.,<span class="at">data=</span>USA2),virginia2015,<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 49.87625 41.73612 58.01638</code></pre>
<p>El modelo predice que en 2016 el partido demócrata iba a obtener un 49.88% de los votos, con un intervalo de confianza del 95% del 37% al 62.75%. Además, un intervalo de confianza del 95% para el valor <em>esperado</em> de este porcentaje de votos (es decir, la media de los porcentajes de votos que obendría el partido demócrata en estados con los mismos datos socio-económicos y demográficos que Virginia en 2015 si repitiésemos muchísimas veces las elecciones) va del 41.74% al 58.02%. El porcentaje de voto demócrata en Virginia en las elecciones del 2016 fue del 49.73%, así que la predicción del modelo en este caso es bastante acertada.</p>
</div>
<div id="sec:seleccion" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Selección del modelo en base al ajuste de los datos</h2>
<p>En los modelos de regresión lineal múltiple, es decir, en aquellas situaciones en las que existen varias variables independientes candidatas a intervenir en el modelo de regresión lineal, surge la pregunta de qué modelo se debe seleccionar en base al ajuste de los datos. No existe una respuesta definitiva a esta cuestión debido a la complejidad del tema. Aunque un modelo sea efectivo a la hora de ajustar los datos y por lo tanto, tenga un valor grande de <span class="math inline">\(R^2\)</span>, puede ocurrir que algunas de las variables independientes seleccionadas no sean en realidad relevantes en el modelo. Son las conocidas como <strong>variables redundantes</strong>. Estas variables dificultan la interpretación del modelo y es conveniente eliminarlas. Sin embargo, surge la duda de determinar de forma objetiva cuál es el mejor modelo, en el sentido de cuál es el modelo más sencillo que explique la mayor cantidad de varianza posible. Así, llegamos a la cuestión de cómo comparar dos modelos de regresión múltiple con un número distinto de variables. Tenemos disponibles tres métodos para este fin:</p>
<ul>
<li><p>Comparación de los <span class="math inline">\(R^2_{adj}\)</span>: Ya hemos hablado de este método en la Sección <a href="chap-regresion.html#sec:1">10.1</a>. Recordemos que en base a este criterio, el modelo con un mayor <span class="math inline">\(R^2_{adj}\)</span> es el óptimo.</p></li>
<li><p>Las medidas <strong>AIC</strong> (<em>Akaike’s Information Criterion</em>) y <strong>BIC</strong> (<em>Bayesian Information Criterion</em>): La medida AIC, definida como
<span class="math display">\[
AIC=n\ln(SS_e/n)+2k,
\]</span>
donde <span class="math inline">\(SS_e\)</span> indica la suma de los cuadrados de los errores, cuantifica cuánta información de la variable dependiente se pierde con el modelo y el número de variables utilizado. En cambio, la medida BIC, definida como
<span class="math display">\[
BIC=n\ln(SS_e/n)+k\ln(n),
\]</span>
también tiene en cuenta el tamaño de la muestra al penalizar el número de variables independientes. Cuánto menor sea el valor de AIC o BIC, mejor se considera el modelo.</p></li>
</ul>
<p>Las medidas AIC y BIC se calculan con la función de R</p>
<div class="sourceCode" id="cb1223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1223-1"><a href="chap-regresion.html#cb1223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(x,k)[<span class="dv">2</span>]</span></code></pre></div>
<p>donde <code>x</code> es un modelo lineal obtenido mediante la función <code>lm</code> y <code>k</code> es el peso que afecta al número de variables del modelo. El valor de <em>k</em> por defecto es 2 y corresponde al criterio AIC. Si se indica <code>k=log(n)</code>, donde <em>n</em> es el número de observaciones, <code>extractAIC</code> calcula la medida BIC.</p>
<p>Los tres criterios no son equivalentes y por lo tanto, pueden darse resultados contradictorios entre ellos. En ese caso, conviene escoger uno de los criterios y explicar la preferencia por él, o realizar más análisis para determinar qué modelo es mejor.</p>
<p>Estudiemos a continuación los siguientes modelos de regresión lineal múltiple a partir de los datos del Ejemplo <a href="chap-regresion.html#exm:exempUSA">10.2</a>:</p>
<div class="sourceCode" id="cb1224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1224-1"><a href="chap-regresion.html#cb1224-1" aria-hidden="true" tabindex="-1"></a>modelo1<span class="ot">=</span><span class="fu">lm</span>(obama<span class="sc">~</span>.,<span class="at">data=</span>USA2)</span>
<span id="cb1224-2"><a href="chap-regresion.html#cb1224-2" aria-hidden="true" tabindex="-1"></a>modelo2<span class="ot">=</span><span class="fu">update</span>(modelo1,.<span class="sc">~</span>.<span class="sc">-</span>jubilados)</span>
<span id="cb1224-3"><a href="chap-regresion.html#cb1224-3" aria-hidden="true" tabindex="-1"></a>modelo3<span class="ot">=</span><span class="fu">update</span>(modelo1,.<span class="sc">~</span>.<span class="sc">-</span>paro)</span></code></pre></div>
<p>El modelo 1 considera todas las variables socio-económicas y demográficas de los estados norteamericanos, mientras que los modelos 2 y 3 no tienen en cuenta, respectivamente, las variables <code>jubilados</code> y <code>paro</code>. Veamos los valores de <span class="math inline">\(R^2_{adj}\)</span>, AIC y BIC para decidir cuál de estos tres modelos es el mejor. Organizaremos estos valores en un <em>data frame</em> para facilitar su comparación y usaremos la función <code>kable</code> del paquete <strong>knitr</strong> para que nos muestre el data frame en el documento final como una tabla bien formateada.</p>
<div class="sourceCode" id="cb1225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1225-1"><a href="chap-regresion.html#cb1225-1" aria-hidden="true" tabindex="-1"></a>R2.adj<span class="ot">=</span><span class="fu">c</span>(<span class="fu">summary</span>(modelo1)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb1225-2"><a href="chap-regresion.html#cb1225-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo2)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb1225-3"><a href="chap-regresion.html#cb1225-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo3)<span class="sc">$</span>adj.r.squared)</span>
<span id="cb1225-4"><a href="chap-regresion.html#cb1225-4" aria-hidden="true" tabindex="-1"></a>AIC<span class="ot">=</span><span class="fu">c</span>(<span class="fu">extractAIC</span>(modelo1)[<span class="dv">2</span>],</span>
<span id="cb1225-5"><a href="chap-regresion.html#cb1225-5" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(modelo2)[<span class="dv">2</span>],</span>
<span id="cb1225-6"><a href="chap-regresion.html#cb1225-6" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(modelo3)[<span class="dv">2</span>])</span>
<span id="cb1225-7"><a href="chap-regresion.html#cb1225-7" aria-hidden="true" tabindex="-1"></a>BIC<span class="ot">=</span><span class="fu">c</span>(<span class="fu">extractAIC</span>(modelo1,<span class="at">k=</span><span class="fu">log</span>(<span class="fu">dim</span>(USA2)[<span class="dv">1</span>]))[<span class="dv">2</span>],</span>
<span id="cb1225-8"><a href="chap-regresion.html#cb1225-8" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(modelo2,<span class="at">k=</span><span class="fu">log</span>(<span class="fu">dim</span>(USA2)[<span class="dv">1</span>]))[<span class="dv">2</span>],</span>
<span id="cb1225-9"><a href="chap-regresion.html#cb1225-9" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(modelo3,<span class="at">k=</span><span class="fu">log</span>(<span class="fu">dim</span>(USA2)[<span class="dv">1</span>]))[<span class="dv">2</span>])</span>
<span id="cb1225-10"><a href="chap-regresion.html#cb1225-10" aria-hidden="true" tabindex="-1"></a>Medidas<span class="ot">=</span><span class="fu">data.frame</span>(R2.adj,AIC,BIC,<span class="at">row.names=</span><span class="fu">c</span>(<span class="st">&quot;modelo1&quot;</span>,<span class="st">&quot;modelo2&quot;</span>,<span class="st">&quot;modelo3&quot;</span>))</span>
<span id="cb1225-11"><a href="chap-regresion.html#cb1225-11" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Medidas)<span class="ot">=</span><span class="fu">c</span>(<span class="st">&quot;Coef. Det. ajustado&quot;</span>,<span class="st">&quot;AIC&quot;</span>,<span class="st">&quot;BIC&quot;</span>)</span>
<span id="cb1225-12"><a href="chap-regresion.html#cb1225-12" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Medidas)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Coef. Det. ajustado</th>
<th align="right">AIC</th>
<th align="right">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>modelo1</td>
<td align="right">0.8278411</td>
<td align="right">175.9132</td>
<td align="right">210.6861</td>
</tr>
<tr class="even">
<td>modelo2</td>
<td align="right">0.8328691</td>
<td align="right">173.9240</td>
<td align="right">206.7651</td>
</tr>
<tr class="odd">
<td>modelo3</td>
<td align="right">0.7722827</td>
<td align="right">189.6997</td>
<td align="right">222.5408</td>
</tr>
</tbody>
</table>
<p>En este caso, los tres indicadores coinciden en que el modelo que no tiene en cuenta la variable <code>jubilados</code> es el mejor de los tres: es el que tiene mayor valor de <span class="math inline">\(R^2_{adj}\)</span> y menor valor de las medidas AIC y BIC.</p>
<p>En un problema en el que se dispongan de <em>k</em> variables independientes, existen <span class="math inline">\(2^{k}-1\)</span> modelos de regresión lineal múltiple que deberían ser evaluados para encontrar cuál es la mejor combinación de variables. El proceso manual es tedioso y el número de casos es demasiado elevado. Para ayudarnos en esta tarea, en R disponemos de la función</p>
<div class="sourceCode" id="cb1226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1226-1"><a href="chap-regresion.html#cb1226-1" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(x,<span class="at">direction=</span>...,<span class="at">scope=</span>...,<span class="at">k=</span>..., <span class="at">trace=</span>...)</span></code></pre></div>
<p>que, a partir de un modelo lineal dado <code>x</code>, va probando diferentes modelos añadiendo o eliminando variables independientes hasta encontrar un modelo óptimo (entre todos los modelos que se puedan obtener de esta manera). Sus otros argumentos son:</p>
<ul>
<li><p><code>direction</code> indica la metodología que ha de utilizar R para generar los nuevos modelos a evaluar en la siguiente iteración. Tiene 3 valores posibles:</p>
<ul>
<li><code>"backward"</code> indica que en cada iteración se han de evaluar y comparar el modelo obtenido en la iteración anterior y todos los modelos obtenidos a partir de él eliminando una de sus variables independientes;</li>
<li><code>"forward"</code> indica que en cada iteración se han de evaluar y comparar el modelo obtenido en la iteración anterior y todos los modelos obtenidos a partir de él añadiéndole una nueva variable independiente;</li>
<li><code>"both"</code> indica que en cada iteración se han de evaluar y comparar el modelo obtenido en la iteración anterior y todos los modelos obtenidos a partir de él añadiéndole una nueva variable independiente o eliminando una de sus variables independientes.</li>
</ul></li>
<li><p><code>scope</code> define el rango de modelos que se tienen que considerar. Se introduce con el formato <code>list(lower=formula1,upper=formula2)</code> donde <code>formula1</code> y <code>formula2</code> son los modelos que constituyen los extremos del rango a considerar en el sentido de que los modelos que se tendrán en cuenta han de contener las variables independientes de la <code>formula1</code> y sus variables independientes han de aparecer a la derecha de la tilde en la <code>formula2</code>.</p></li>
<li><p><code>k</code> tiene el mismo significado que en la función <code>extractAIC</code> e indica si la evaluación de los modelos se realiza en base al AIC (entrando <code>k=2</code>, el valor por defecto) o al BIC (entrando <code>k=log(n)</code> con <code>n</code> el el número de observaciones).</p></li>
<li><p><code>trace</code> es un parámetro lógico. Su valor por defecto es <code>TRUE</code> y va mostrando en la consola la información de cada iteración. Igualado a <code>FALSE</code> solo da el modelo final.</p></li>
</ul>
<p>Esta función realiza un proceso iterativo de eliminación o adición de variables consiguiendo en cada paso del algoritmo un modelo con un valor de AIC (o BIC) menor al modelo obtenido en el paso anterior. El proceso se para cuando no encuentra ningún modelo mejor.</p>
<p>Ejecutemos esta función con el modelo que considera todas las variables socio-económicas y demográficas, usando el AIC para valorar los modelos y con <code>direction="backward"</code>, es decir, eliminando variables una a una. Omitimos la información en consola de algunas iteraciones intermedias (indicado en la salida con <code>[...]</code>) para ahorrar espacio vertical.</p>
<div class="sourceCode" id="cb1227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1227-1"><a href="chap-regresion.html#cb1227-1" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(modelo1,<span class="at">direction=</span><span class="st">&quot;backward&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1228-1"><a href="chap-regresion.html#cb1228-1" aria-hidden="true" tabindex="-1"></a>Start<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">175.91</span></span>
<span id="cb1228-2"><a href="chap-regresion.html#cb1228-2" aria-hidden="true" tabindex="-1"></a>obama <span class="sc">~</span> densidad <span class="sc">+</span> veteranos <span class="sc">+</span> mujeres <span class="sc">+</span> grad_instituto <span class="sc">+</span> grad_univ <span class="sc">+</span> </span>
<span id="cb1228-3"><a href="chap-regresion.html#cb1228-3" aria-hidden="true" tabindex="-1"></a>    afro <span class="sc">+</span> asia <span class="sc">+</span> hispanos <span class="sc">+</span> blancos <span class="sc">+</span> evangelicos <span class="sc">+</span> protestantes <span class="sc">+</span> </span>
<span id="cb1228-4"><a href="chap-regresion.html#cb1228-4" aria-hidden="true" tabindex="-1"></a>    relig_afro <span class="sc">+</span> catolicos <span class="sc">+</span> mormones <span class="sc">+</span> jubilados <span class="sc">+</span> paro <span class="sc">+</span> salario</span>
<span id="cb1228-5"><a href="chap-regresion.html#cb1228-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-6"><a href="chap-regresion.html#cb1228-6" aria-hidden="true" tabindex="-1"></a>                 Df Sum of Sq     RSS    AIC</span>
<span id="cb1228-7"><a href="chap-regresion.html#cb1228-7" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> jubilados       <span class="dv">1</span>     <span class="fl">0.168</span>  <span class="fl">792.69</span> <span class="fl">173.92</span></span>
<span id="cb1228-8"><a href="chap-regresion.html#cb1228-8" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> afro            <span class="dv">1</span>     <span class="fl">1.209</span>  <span class="fl">793.73</span> <span class="fl">173.99</span></span>
<span id="cb1228-9"><a href="chap-regresion.html#cb1228-9" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> catolicos       <span class="dv">1</span>     <span class="fl">9.637</span>  <span class="fl">802.16</span> <span class="fl">174.53</span></span>
<span id="cb1228-10"><a href="chap-regresion.html#cb1228-10" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> relig_afro      <span class="dv">1</span>    <span class="fl">12.544</span>  <span class="fl">805.07</span> <span class="fl">174.71</span></span>
<span id="cb1228-11"><a href="chap-regresion.html#cb1228-11" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> veteranos       <span class="dv">1</span>    <span class="fl">12.555</span>  <span class="fl">805.08</span> <span class="fl">174.72</span></span>
<span id="cb1228-12"><a href="chap-regresion.html#cb1228-12" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> blancos         <span class="dv">1</span>    <span class="fl">13.715</span>  <span class="fl">806.24</span> <span class="fl">174.79</span></span>
<span id="cb1228-13"><a href="chap-regresion.html#cb1228-13" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> salario         <span class="dv">1</span>    <span class="fl">14.878</span>  <span class="fl">807.40</span> <span class="fl">174.86</span></span>
<span id="cb1228-14"><a href="chap-regresion.html#cb1228-14" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> protestantes    <span class="dv">1</span>    <span class="fl">24.473</span>  <span class="fl">817.00</span> <span class="fl">175.46</span></span>
<span id="cb1228-15"><a href="chap-regresion.html#cb1228-15" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> hispanos        <span class="dv">1</span>    <span class="fl">25.006</span>  <span class="fl">817.53</span> <span class="fl">175.50</span></span>
<span id="cb1228-16"><a href="chap-regresion.html#cb1228-16" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="fl">792.52</span> <span class="fl">175.91</span></span>
<span id="cb1228-17"><a href="chap-regresion.html#cb1228-17" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_instituto  <span class="dv">1</span>    <span class="fl">32.482</span>  <span class="fl">825.01</span> <span class="fl">175.96</span></span>
<span id="cb1228-18"><a href="chap-regresion.html#cb1228-18" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> evangelicos     <span class="dv">1</span>    <span class="fl">43.177</span>  <span class="fl">835.70</span> <span class="fl">176.62</span></span>
<span id="cb1228-19"><a href="chap-regresion.html#cb1228-19" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mujeres         <span class="dv">1</span>    <span class="fl">57.840</span>  <span class="fl">850.36</span> <span class="fl">177.51</span></span>
<span id="cb1228-20"><a href="chap-regresion.html#cb1228-20" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_univ       <span class="dv">1</span>    <span class="fl">73.797</span>  <span class="fl">866.32</span> <span class="fl">178.45</span></span>
<span id="cb1228-21"><a href="chap-regresion.html#cb1228-21" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> densidad        <span class="dv">1</span>    <span class="fl">84.717</span>  <span class="fl">877.24</span> <span class="fl">179.09</span></span>
<span id="cb1228-22"><a href="chap-regresion.html#cb1228-22" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mormones        <span class="dv">1</span>    <span class="fl">85.509</span>  <span class="fl">878.03</span> <span class="fl">179.14</span></span>
<span id="cb1228-23"><a href="chap-regresion.html#cb1228-23" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> asia            <span class="dv">1</span>   <span class="fl">173.269</span>  <span class="fl">965.79</span> <span class="fl">184.00</span></span>
<span id="cb1228-24"><a href="chap-regresion.html#cb1228-24" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> paro            <span class="dv">1</span>   <span class="fl">287.526</span> <span class="fl">1080.05</span> <span class="fl">189.70</span></span>
<span id="cb1228-25"><a href="chap-regresion.html#cb1228-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-26"><a href="chap-regresion.html#cb1228-26" aria-hidden="true" tabindex="-1"></a>Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">173.92</span></span>
<span id="cb1228-27"><a href="chap-regresion.html#cb1228-27" aria-hidden="true" tabindex="-1"></a>obama <span class="sc">~</span> densidad <span class="sc">+</span> veteranos <span class="sc">+</span> mujeres <span class="sc">+</span> grad_instituto <span class="sc">+</span> grad_univ <span class="sc">+</span> </span>
<span id="cb1228-28"><a href="chap-regresion.html#cb1228-28" aria-hidden="true" tabindex="-1"></a>    afro <span class="sc">+</span> asia <span class="sc">+</span> hispanos <span class="sc">+</span> blancos <span class="sc">+</span> evangelicos <span class="sc">+</span> protestantes <span class="sc">+</span> </span>
<span id="cb1228-29"><a href="chap-regresion.html#cb1228-29" aria-hidden="true" tabindex="-1"></a>    relig_afro <span class="sc">+</span> catolicos <span class="sc">+</span> mormones <span class="sc">+</span> paro <span class="sc">+</span> salario</span>
<span id="cb1228-30"><a href="chap-regresion.html#cb1228-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-31"><a href="chap-regresion.html#cb1228-31" aria-hidden="true" tabindex="-1"></a>                 Df Sum of Sq     RSS    AIC</span>
<span id="cb1228-32"><a href="chap-regresion.html#cb1228-32" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> afro            <span class="dv">1</span>     <span class="fl">1.349</span>  <span class="fl">794.04</span> <span class="fl">172.01</span></span>
<span id="cb1228-33"><a href="chap-regresion.html#cb1228-33" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> catolicos       <span class="dv">1</span>     <span class="fl">9.740</span>  <span class="fl">802.43</span> <span class="fl">172.55</span></span>
<span id="cb1228-34"><a href="chap-regresion.html#cb1228-34" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> blancos         <span class="dv">1</span>    <span class="fl">13.567</span>  <span class="fl">806.26</span> <span class="fl">172.79</span></span>
<span id="cb1228-35"><a href="chap-regresion.html#cb1228-35" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> veteranos       <span class="dv">1</span>    <span class="fl">13.870</span>  <span class="fl">806.56</span> <span class="fl">172.81</span></span>
<span id="cb1228-36"><a href="chap-regresion.html#cb1228-36" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> relig_afro      <span class="dv">1</span>    <span class="fl">13.991</span>  <span class="fl">806.68</span> <span class="fl">172.82</span></span>
<span id="cb1228-37"><a href="chap-regresion.html#cb1228-37" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> salario         <span class="dv">1</span>    <span class="fl">14.765</span>  <span class="fl">807.46</span> <span class="fl">172.87</span></span>
<span id="cb1228-38"><a href="chap-regresion.html#cb1228-38" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> protestantes    <span class="dv">1</span>    <span class="fl">24.346</span>  <span class="fl">817.04</span> <span class="fl">173.47</span></span>
<span id="cb1228-39"><a href="chap-regresion.html#cb1228-39" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> hispanos        <span class="dv">1</span>    <span class="fl">24.992</span>  <span class="fl">817.68</span> <span class="fl">173.51</span></span>
<span id="cb1228-40"><a href="chap-regresion.html#cb1228-40" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="fl">792.69</span> <span class="fl">173.92</span></span>
<span id="cb1228-41"><a href="chap-regresion.html#cb1228-41" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_instituto  <span class="dv">1</span>    <span class="fl">33.638</span>  <span class="fl">826.33</span> <span class="fl">174.04</span></span>
<span id="cb1228-42"><a href="chap-regresion.html#cb1228-42" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> evangelicos     <span class="dv">1</span>    <span class="fl">43.398</span>  <span class="fl">836.09</span> <span class="fl">174.64</span></span>
<span id="cb1228-43"><a href="chap-regresion.html#cb1228-43" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> densidad        <span class="dv">1</span>    <span class="fl">84.719</span>  <span class="fl">877.41</span> <span class="fl">177.10</span></span>
<span id="cb1228-44"><a href="chap-regresion.html#cb1228-44" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mormones        <span class="dv">1</span>    <span class="fl">86.199</span>  <span class="fl">878.89</span> <span class="fl">177.19</span></span>
<span id="cb1228-45"><a href="chap-regresion.html#cb1228-45" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_univ       <span class="dv">1</span>    <span class="fl">96.666</span>  <span class="fl">889.36</span> <span class="fl">177.79</span></span>
<span id="cb1228-46"><a href="chap-regresion.html#cb1228-46" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mujeres         <span class="dv">1</span>   <span class="fl">114.224</span>  <span class="fl">906.92</span> <span class="fl">178.79</span></span>
<span id="cb1228-47"><a href="chap-regresion.html#cb1228-47" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> asia            <span class="dv">1</span>   <span class="fl">180.199</span>  <span class="fl">972.89</span> <span class="fl">182.37</span></span>
<span id="cb1228-48"><a href="chap-regresion.html#cb1228-48" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> paro            <span class="dv">1</span>   <span class="fl">300.135</span> <span class="fl">1092.83</span> <span class="fl">188.30</span></span>
<span id="cb1228-49"><a href="chap-regresion.html#cb1228-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-50"><a href="chap-regresion.html#cb1228-50" aria-hidden="true" tabindex="-1"></a>Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">172.01</span></span>
<span id="cb1228-51"><a href="chap-regresion.html#cb1228-51" aria-hidden="true" tabindex="-1"></a>obama <span class="sc">~</span> densidad <span class="sc">+</span> veteranos <span class="sc">+</span> mujeres <span class="sc">+</span> grad_instituto <span class="sc">+</span> grad_univ <span class="sc">+</span> </span>
<span id="cb1228-52"><a href="chap-regresion.html#cb1228-52" aria-hidden="true" tabindex="-1"></a>    asia <span class="sc">+</span> hispanos <span class="sc">+</span> blancos <span class="sc">+</span> evangelicos <span class="sc">+</span> protestantes <span class="sc">+</span> </span>
<span id="cb1228-53"><a href="chap-regresion.html#cb1228-53" aria-hidden="true" tabindex="-1"></a>    relig_afro <span class="sc">+</span> catolicos <span class="sc">+</span> mormones <span class="sc">+</span> paro <span class="sc">+</span> salario</span>
<span id="cb1228-54"><a href="chap-regresion.html#cb1228-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-55"><a href="chap-regresion.html#cb1228-55" aria-hidden="true" tabindex="-1"></a>                 Df Sum of Sq     RSS    AIC</span>
<span id="cb1228-56"><a href="chap-regresion.html#cb1228-56" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> catolicos       <span class="dv">1</span>    <span class="fl">10.218</span>  <span class="fl">804.26</span> <span class="fl">170.66</span></span>
<span id="cb1228-57"><a href="chap-regresion.html#cb1228-57" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> salario         <span class="dv">1</span>    <span class="fl">14.423</span>  <span class="fl">808.46</span> <span class="fl">170.93</span></span>
<span id="cb1228-58"><a href="chap-regresion.html#cb1228-58" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> veteranos       <span class="dv">1</span>    <span class="fl">15.412</span>  <span class="fl">809.45</span> <span class="fl">170.99</span></span>
<span id="cb1228-59"><a href="chap-regresion.html#cb1228-59" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> protestantes    <span class="dv">1</span>    <span class="fl">22.997</span>  <span class="fl">817.04</span> <span class="fl">171.47</span></span>
<span id="cb1228-60"><a href="chap-regresion.html#cb1228-60" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> blancos         <span class="dv">1</span>    <span class="fl">23.551</span>  <span class="fl">817.59</span> <span class="fl">171.50</span></span>
<span id="cb1228-61"><a href="chap-regresion.html#cb1228-61" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> relig_afro      <span class="dv">1</span>    <span class="fl">24.048</span>  <span class="fl">818.09</span> <span class="fl">171.53</span></span>
<span id="cb1228-62"><a href="chap-regresion.html#cb1228-62" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="fl">794.04</span> <span class="fl">172.01</span></span>
<span id="cb1228-63"><a href="chap-regresion.html#cb1228-63" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_instituto  <span class="dv">1</span>    <span class="fl">34.693</span>  <span class="fl">828.73</span> <span class="fl">172.19</span></span>
<span id="cb1228-64"><a href="chap-regresion.html#cb1228-64" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> hispanos        <span class="dv">1</span>    <span class="fl">39.340</span>  <span class="fl">833.38</span> <span class="fl">172.48</span></span>
<span id="cb1228-65"><a href="chap-regresion.html#cb1228-65" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> evangelicos     <span class="dv">1</span>    <span class="fl">42.987</span>  <span class="fl">837.03</span> <span class="fl">172.70</span></span>
<span id="cb1228-66"><a href="chap-regresion.html#cb1228-66" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mormones        <span class="dv">1</span>    <span class="fl">87.616</span>  <span class="fl">881.66</span> <span class="fl">175.35</span></span>
<span id="cb1228-67"><a href="chap-regresion.html#cb1228-67" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> densidad        <span class="dv">1</span>    <span class="fl">92.800</span>  <span class="fl">886.84</span> <span class="fl">175.65</span></span>
<span id="cb1228-68"><a href="chap-regresion.html#cb1228-68" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_univ       <span class="dv">1</span>    <span class="fl">95.935</span>  <span class="fl">889.98</span> <span class="fl">175.83</span></span>
<span id="cb1228-69"><a href="chap-regresion.html#cb1228-69" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mujeres         <span class="dv">1</span>   <span class="fl">113.018</span>  <span class="fl">907.06</span> <span class="fl">176.80</span></span>
<span id="cb1228-70"><a href="chap-regresion.html#cb1228-70" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> asia            <span class="dv">1</span>   <span class="fl">239.541</span> <span class="fl">1033.58</span> <span class="fl">183.46</span></span>
<span id="cb1228-71"><a href="chap-regresion.html#cb1228-71" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> paro            <span class="dv">1</span>   <span class="fl">309.656</span> <span class="fl">1103.70</span> <span class="fl">186.80</span></span>
<span id="cb1228-72"><a href="chap-regresion.html#cb1228-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-73"><a href="chap-regresion.html#cb1228-73" aria-hidden="true" tabindex="-1"></a>[...]                 </span>
<span id="cb1228-74"><a href="chap-regresion.html#cb1228-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-75"><a href="chap-regresion.html#cb1228-75" aria-hidden="true" tabindex="-1"></a>Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">165.22</span></span>
<span id="cb1228-76"><a href="chap-regresion.html#cb1228-76" aria-hidden="true" tabindex="-1"></a>obama <span class="sc">~</span> densidad <span class="sc">+</span> mujeres <span class="sc">+</span> grad_instituto <span class="sc">+</span> grad_univ <span class="sc">+</span> asia <span class="sc">+</span> </span>
<span id="cb1228-77"><a href="chap-regresion.html#cb1228-77" aria-hidden="true" tabindex="-1"></a>    hispanos <span class="sc">+</span> evangelicos <span class="sc">+</span> mormones <span class="sc">+</span> paro</span>
<span id="cb1228-78"><a href="chap-regresion.html#cb1228-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-79"><a href="chap-regresion.html#cb1228-79" aria-hidden="true" tabindex="-1"></a>                 Df Sum of Sq     RSS    AIC</span>
<span id="cb1228-80"><a href="chap-regresion.html#cb1228-80" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="fl">879.45</span> <span class="fl">165.22</span></span>
<span id="cb1228-81"><a href="chap-regresion.html#cb1228-81" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> hispanos        <span class="dv">1</span>     <span class="fl">37.14</span>  <span class="fl">916.59</span> <span class="fl">165.33</span></span>
<span id="cb1228-82"><a href="chap-regresion.html#cb1228-82" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_univ       <span class="dv">1</span>     <span class="fl">70.03</span>  <span class="fl">949.47</span> <span class="fl">167.13</span></span>
<span id="cb1228-83"><a href="chap-regresion.html#cb1228-83" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> evangelicos     <span class="dv">1</span>     <span class="fl">84.02</span>  <span class="fl">963.47</span> <span class="fl">167.87</span></span>
<span id="cb1228-84"><a href="chap-regresion.html#cb1228-84" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> densidad        <span class="dv">1</span>    <span class="fl">103.52</span>  <span class="fl">982.97</span> <span class="fl">168.90</span></span>
<span id="cb1228-85"><a href="chap-regresion.html#cb1228-85" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> grad_instituto  <span class="dv">1</span>    <span class="fl">119.32</span>  <span class="fl">998.77</span> <span class="fl">169.71</span></span>
<span id="cb1228-86"><a href="chap-regresion.html#cb1228-86" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mujeres         <span class="dv">1</span>    <span class="fl">285.19</span> <span class="fl">1164.63</span> <span class="fl">177.54</span></span>
<span id="cb1228-87"><a href="chap-regresion.html#cb1228-87" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> paro            <span class="dv">1</span>    <span class="fl">305.27</span> <span class="fl">1184.71</span> <span class="fl">178.42</span></span>
<span id="cb1228-88"><a href="chap-regresion.html#cb1228-88" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> mormones        <span class="dv">1</span>    <span class="fl">492.00</span> <span class="fl">1371.45</span> <span class="fl">185.88</span></span>
<span id="cb1228-89"><a href="chap-regresion.html#cb1228-89" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span> asia            <span class="dv">1</span>    <span class="fl">775.31</span> <span class="fl">1654.76</span> <span class="fl">195.46</span></span>
<span id="cb1228-90"><a href="chap-regresion.html#cb1228-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-91"><a href="chap-regresion.html#cb1228-91" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb1228-92"><a href="chap-regresion.html#cb1228-92" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> obama <span class="sc">~</span> densidad <span class="sc">+</span> mujeres <span class="sc">+</span> grad_instituto <span class="sc">+</span> grad_univ <span class="sc">+</span> </span>
<span id="cb1228-93"><a href="chap-regresion.html#cb1228-93" aria-hidden="true" tabindex="-1"></a>    asia <span class="sc">+</span> hispanos <span class="sc">+</span> evangelicos <span class="sc">+</span> mormones <span class="sc">+</span> paro, <span class="at">data =</span> USA2)</span>
<span id="cb1228-94"><a href="chap-regresion.html#cb1228-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1228-95"><a href="chap-regresion.html#cb1228-95" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb1228-96"><a href="chap-regresion.html#cb1228-96" aria-hidden="true" tabindex="-1"></a>   (Intercept)        densidad         mujeres  grad_instituto       grad_univ  </span>
<span id="cb1228-97"><a href="chap-regresion.html#cb1228-97" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span><span class="fl">3.263e+02</span>       <span class="fl">1.555e-03</span>       <span class="fl">5.087e+00</span>       <span class="fl">1.056e+00</span>       <span class="fl">4.207e-01</span>  </span>
<span id="cb1228-98"><a href="chap-regresion.html#cb1228-98" aria-hidden="true" tabindex="-1"></a>          asia        hispanos     evangelicos        mormones            paro  </span>
<span id="cb1228-99"><a href="chap-regresion.html#cb1228-99" aria-hidden="true" tabindex="-1"></a>     <span class="fl">7.629e-01</span>       <span class="fl">1.379e-01</span>      <span class="sc">-</span><span class="fl">1.596e-01</span>      <span class="sc">-</span><span class="fl">3.967e-01</span>       <span class="fl">1.854e+00</span>  </span></code></pre></div>
<p>Al inicio del algoritmo, tenemos en <code>Start</code> el modelo inicial, entrado a la función <code>step</code>, y su valor de AIC. A continuación, en cada paso se disponen en una tabla las variables y el valor de AIC que obtendría el modelo si se eliminara la variable en cuestión. Las variables aparecen en la tabla ordenadas en orden ascendente del AIC que se obtiene al eliminarlas, y el modelo actual se indica por medio de <code>&lt;none&gt;</code> (no se elimina <em>ninguna</em> variable). Así, en la primera iteración se eliminará la variable <code>jubilados</code> ya que su eliminación proporciona un modelo con un valor mínimo AIC=173.92 que es menor que el valor del modelo inicial. Luego, al principio de cada iteración sucesiva se indica la formula correspondiente al modelo en ese momento. En la segunda iteración, ya se ha eliminado la variable <code>jubilados</code>, se calculan los AIC y como la variable <code>afro</code> da un valor mínimo de AIC, será la variable que se eliminará. Y así sucesivamente.</p>
<p>El algoritmo finaliza cuando si se elimina cualquiera de las variables restantes, aumenta el AIC empeorando el modelo: corresponde a la situación en la que la variable <code>&lt;none&gt;</code> aparece en la primera fila de la tabla de valores AIC. En este ejemplo, se eliminan <code>jubilados</code>, <code>afro</code> y <code>catolicos</code>, <code>veteranos</code>, <code>protestantes</code>, <code>salario</code>, <code>religion_afro</code> y <code>blancos</code> resultando un modelo de regresión con nueve variables independientes y con un valor de AIC=165.22. La última parte de la salida de la función nos da las variables y los coeficientes de la función de regresión correspondiente. El vector de coeficientes de la función lineal resultante se puede obtener, usando <code>trace=FALSE</code>, con el sufijo <code>$coefficients</code> y el modelo con el sufijo <code>$call</code>.</p>
<div class="sourceCode" id="cb1229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1229-1"><a href="chap-regresion.html#cb1229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(modelo1,<span class="at">direction=</span><span class="st">&quot;backward&quot;</span>,<span class="at">trace=</span><span class="cn">FALSE</span>)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##    (Intercept)       densidad        mujeres grad_instituto      grad_univ 
##  -3.262501e+02   1.555251e-03   5.086534e+00   1.056493e+00   4.206862e-01 
##           asia       hispanos    evangelicos       mormones           paro 
##   7.628660e-01   1.379246e-01  -1.595779e-01  -3.966677e-01   1.854289e+00</code></pre>
<div class="sourceCode" id="cb1231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1231-1"><a href="chap-regresion.html#cb1231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(modelo1,<span class="at">direction=</span><span class="st">&quot;backward&quot;</span>,<span class="at">trace=</span><span class="cn">FALSE</span>)<span class="sc">$</span>call</span></code></pre></div>
<pre><code>## lm(formula = obama ~ densidad + mujeres + grad_instituto + grad_univ + 
##     asia + hispanos + evangelicos + mormones + paro, data = USA2)</code></pre>
<p>Ejecutemos a continuación la función <code>step</code> pero ahora con <code>direction="forward"</code> desde un modelo sin variables independientes (que se indica con ~1) y un rango que permita llegar al modelo completo. Para ahorrar espacio vertical, vamos a omitir de la salida la información de las iteraciones que realiza R.</p>
<div class="sourceCode" id="cb1233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1233-1"><a href="chap-regresion.html#cb1233-1" aria-hidden="true" tabindex="-1"></a>modelo_vacio<span class="ot">=</span> <span class="fu">lm</span>(obama<span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>USA2)</span>
<span id="cb1233-2"><a href="chap-regresion.html#cb1233-2" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(modelo_vacio,<span class="at">direction=</span><span class="st">&quot;forward&quot;</span>,<span class="at">scope=</span><span class="fu">list</span>(<span class="at">lower=</span>modelo_vacio, <span class="at">upper=</span>modelo1),<span class="at">trace=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obama ~ grad_univ + paro + jubilados + asia + mormones + 
##     densidad + evangelicos + mujeres + protestantes, data = USA2)
## 
## Coefficients:
##  (Intercept)     grad_univ          paro     jubilados          asia  
##   -1.365e+02     8.494e-01     2.043e+00     7.263e-01     7.332e-01  
##     mormones      densidad   evangelicos       mujeres  protestantes  
##   -2.833e-01     1.134e-03    -1.956e-01     2.678e+00     1.972e-01</code></pre>
<p>En esta aplicación de <code>step</code> se vuelve a obtener un modelo lineal con 9 variables independientes, aunque diferente al obtenido en la aplicación anterior ya que las variables <code>protestantes</code> y <code>jubilados</code> son ahora consideradas en lugar de <code>grad_instituto</code> e <code>hispanos</code>.</p>
<p>Evidentemente la función <code>step</code> no considera todos los modelos posibles. Para considerar todos los modelos posibles con un número máximo de variables independientes, se puede utilizar la función <code>regsubsets</code> del paquete <strong>leaps</strong>. La sintaxis de la función es la siguiente:</p>
<div class="sourceCode" id="cb1235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1235-1"><a href="chap-regresion.html#cb1235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">regsubsets</span>(x, <span class="at">nbest=</span>..., <span class="at">nvmax=</span>...)</span></code></pre></div>
<p>donde:</p>
<ul>
<li><p><code>x</code> es un modelo lineal obtenido mediante la función <code>lm</code>.</p></li>
<li><p><code>nbest</code> es la cantidad de modelos que queremos que nos muestre para cada número de variables independientes considerado, por defecto un modelo para cada número de variables.</p></li>
<li><p><code>nvmax</code> es el número máximo de variables independientes que queremos que se consideren.</p></li>
</ul>
<p>La función evalúa todos los modelos lineales con <em>k</em> variables aleatorias, para <em>k</em> entre 1 y <code>nvmax</code>, en base a su valor de BIC. Para cada valor de <em>k</em>, se muestran los <code>nbest</code> modelos con un menor valor de BIC. Para una visualización sencilla de los resultados, se puede utilizar la función <code>plot</code>.</p>
<p>A modo de ejemplo, vamos a determinar cuál és el mejor modelo lineal con hasta 9 variables independientes, que es la cantidad de variables que se han obtenido con las dos ejecuciones de <code>step</code>, para los datos del Ejemplo <a href="chap-regresion.html#exm:exempUSA">10.2</a>.</p>
<div class="sourceCode" id="cb1236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1236-1"><a href="chap-regresion.html#cb1236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb1236-2"><a href="chap-regresion.html#cb1236-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">regsubsets</span>(obama<span class="sc">~</span>.,<span class="at">data=</span>USA2,<span class="at">nbest=</span><span class="dv">1</span>,<span class="at">nvmax=</span><span class="dv">9</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-611"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-611-1.png" alt="Variables independientes involucradas en el mejor modelo según BIC para una cantidad fija de variables independientes entre 1 y 9. Los modelos se ordenan por filas en base al valor BIC." width="480" />
<p class="caption">
Figura 10.3: Variables independientes involucradas en el mejor modelo según BIC para una cantidad fija de variables independientes entre 1 y 9. Los modelos se ordenan por filas en base al valor BIC.
</p>
</div>
<p>En el gráfico resultante, se han coloreado, por filas, las variables que intervienen en los distintos modelos. Las filas están ordenadas según el valor BIC del modelo que representan. Así, el mejor modelo con una única variable independiente corresponde a la fila inferior y es el que solo usa la variable <code>grad_univ</code>. Para <em>k</em>=9, resulta que el mejor modelo corresponde al obtenido con la función <code>step</code> con <code>direction="backward"</code> (fila 5 desde la parte inferior). Sin embargo, el mejor modelo según esta función es el correspondiente a la fila superior y que considera las 8 variables <code>mujeres</code>, <code>grad_univ</code>, <code>asia</code>, <code>evangelicos</code>, <code>protestantes</code>, <code>mormones</code> y <code>paro</code>.</p>
</div>
<div id="sec:diagn" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Diagnósticos de regresión</h2>
<p>Para acabar esta lección, vamos a tratar la verificación de los requisitos que dotan de significación al modelo de regresión lineal. Como sabéis, la estimación y la inferencia a partir de un modelo de regresión lineal tienen sentido solo cuando se satisfacen una serie de varias hipótesis. Estas hipótesis tienen que ser comprobadas utilizando los llamados <strong>diagnósticos de regresión</strong>. Los problemas potenciales que puede sufrir un modelo de regresión lineal se clasifican en tres categorías:</p>
<ul>
<li><p><strong>Relativos a los residuos</strong>: Los errores del modelo han de seguir una distribución normal con media 0 y varianza <span class="math inline">\(\sigma^2\)</span> constante (en el sentido de que no dependa del valor de las variables independientes) y ser incorrelados.</p></li>
<li><p><strong>Relativos al modelo</strong>: Los puntos han de ajustarse a la estructura lineal considerada.</p></li>
<li><p><strong>Relativos a las observaciones anómalas</strong>: Puede que algunas de las observaciones no se ajusten al modelo, comprometiendo su validez general.</p></li>
</ul>
<p>El primer paso para llevar a cabo los diagnósticos de regresión es utilizar la función <code>plot</code> con entrada el modelo lineal generado por la función <code>lm</code>. Esta instrucción generará cuatro gráficos:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Residuos vs valores predichos</strong> (<em>Residuals vs Fitted</em>): Puede ser utilizado para comprobar la hipótesis de linealidad del modelo. El gráfico representa los puntos <span class="math inline">\((\hat{y}_i,e_i)\)</span>, donde recordemos que <span class="math inline">\(e_i\)</span> e <span class="math inline">\(\hat{y}_i\)</span> son, respectivamente, el valor estimado de la variable dependiente en el sujeto <em>i</em>-ésimo de la muestra y el error cometido en esta estimación, añadiendo una regresión local (o <strong>regresión móvil</strong>) de estos puntos, representada por una curva de color rojo, que permite comprobar si existe algún tipo de patrón o tendencia en los mismos. Si la curva se acerca a la recta horizontal <span class="math inline">\(y=0\)</span> es indicativo de que los errores son muy pequeños y que por lo tanto se puede asumir la linealidad del modelo.</p></li>
<li><p><strong>Q-Q-plot</strong> (<em>Normal Q-Q</em>): Como ya explicamos en la Sección <a href="#sec:qqplot"><strong>??</strong></a>, este gráfico sirve para examinar la normalidad de los residuos. Recordemos que se puede aceptar la normalidad si los Q-Q-puntos están próximos a la recta cuartil-cuartil, representada en este gráfico por una línea discontinua.</p></li>
<li><p><strong>Escala-Localización</strong> (<em>Scale-Location</em>): El tercer gráfico sirve para comprobar la <strong>homocedasticidad</strong> del modelo, es decir, si la varianza de los errores es constante y no depende del valor de las variables independientes. Si se cumple la condición de homocedasticidad, se dice que el modelo es <strong>homocedástico</strong>, mientras que si no la cumple, se dice que es <strong>heterocedástico</strong>. En el gráfico se representan los puntos <span class="math inline">\((\hat{y}_i,\sqrt{e_i^*})\)</span> donde <span class="math inline">\(e_i^*\)</span> son los llamados <strong>residuos estandarizados</strong>. No entraremos en detalles de cómo se calculan los residuos estandarizados pero, de forma simplificada, son el cociente entre <span class="math inline">\(e_i\)</span> y una estimación de su desviación típica. Este gráfico incluye también, como en el caso del primero, la regresión móvil de los puntos y podremos aceptar que se satisface la homocedasticidad si esta curva es horizontal y los puntos se distribuyen de forma homogénea a su alrededor.</p></li>
<li><p><strong>Residuos vs Apalancamiento</strong> (<em>Residuals vs Leverage</em>): El cuarto gráfico se utiliza para identificar observaciones <strong>influyentes</strong>, es decir, los valores extremos que podrían influir de forma significativa en el modelo lineal cuando son incluidos o excluidos del modelo. Estas observaciones suelen ser <em>outliers</em> (valores atípicos, anómalos) y <em>leverage points</em> (puntos de apalancamiento). Expliquemos el significado de estos términos.</p>
<ul>
<li><p><strong>Outlier</strong>: Es una observación que tiene un valor anómalo de la variable dependiente condicionado a los valores de las variables independientes, y por lo tanto un residuo muy grande.</p></li>
<li><p><strong>Leverage point</strong>: Sin entrar en detalles, el <em>leverage</em> es una medida de la anomalía de los valores de las variables independientes, y un <em>leverage point</em> es un punto con alto valor de <em>leverage</em>. Los <em>leverage points</em> son puntos que están lejos del rango mayoritario de los valores de las variables independientes.</p></li>
</ul>
<p>El gráfico representa los puntos <span class="math inline">\((e_i^*,h_i)\)</span>, donde los <span class="math inline">\(e_i^*\)</span> son los residuos estandarizados de los que ya hemos hablado y los <span class="math inline">\(h_i\)</span> indican el grado de <em>leverage</em> de cada observación. Esto permite reconocer los <em>outliers</em> y los <em>leverage points</em> ya que los primeros se identifican como aquellas observaciones tales que <span class="math inline">\(|e_i^*|&gt;3\)</span>, mientras que los segundos se definen como aquellos puntos para los que <span class="math inline">\(h_i&gt;2(k+1)/n\)</span> donde <em>k</em> es el número de variables independientes y <em>n</em> el de observaciones.</p>
<p>Para identificar las observaciones influyentes también se utiliza la conocida como <strong>distancia de Cook</strong>. No vamos a definirla, pero existe el consenso de que si la distancia de Cook de un punto es mayor que 1, la observación correspondiente es influyente, mientras que si está entre 0.5 y 1 podría serlo y debe ser investigada . En este gráfico también se incluyen unas curvas discontinuas que marcan las regiones de los puntos con distancia de Cook entre 0 y 0.5, entre 0.5 y 1 y mayores que 1.</p></li>
</ol>
<p>En todos los gráficos anteriores, se identifican por defecto las tres observaciones más extremas según el criterio que evalúa cada gráfico. Estas observaciones podrían ser problemáticas y deberían ser evaluadas de forma individual para comprobar si la observación tiene algún tipo de característica diferencial o si simplemente es un error de entrada de datos.</p>
<p>Realicemos el diagnóstico de regresión de los Ejemplos <a href="chap-regresion.html#exm:exempDavis">10.1</a> y <a href="chap-regresion.html#exm:exempUSA">10.2</a>. Empecemos por el primero. Vamos a tomar los gráficos que produce por defecto R. Si queréis modificarlos, por ejemplo traduciendo los textos a otro idioma, consultad la Ayuda de la función <code>plot.lm</code>.</p>
<div class="sourceCode" id="cb1237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1237-1"><a href="chap-regresion.html#cb1237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1237-2"><a href="chap-regresion.html#cb1237-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">data=</span>datospeso))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-612"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-612-1.png" alt="Gráficos del diagnóstico de regresión del modelo lineal del Ejemplo \@ref(exm:exempDavis)." width="960" />
<p class="caption">
Figura 10.4: Gráficos del diagnóstico de regresión del modelo lineal del Ejemplo <a href="chap-regresion.html#exm:exempDavis">10.1</a>.
</p>
</div>
<p>Como ya se podía intuir, la observación 12, que era muy optimista con respecto al peso real (o un olvido de la cifra de las centenas), distorsiona claramente el análisis destacando en cada gráfico y es la única observación que podría ser influyente según el cuarto gráfico. Veamos qué ocurre si eliminamos esta observación que claramente constituye un caso muy especial que no responde a la lógica.</p>
<div class="sourceCode" id="cb1238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1238-1"><a href="chap-regresion.html#cb1238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1238-2"><a href="chap-regresion.html#cb1238-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">subset=</span><span class="sc">-</span><span class="dv">12</span>,<span class="at">data=</span>datospeso))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-613"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-613-1.png" alt="Gráficos del diagnóstico de regresión del modelo lineal del Ejemplo \@ref(exm:exempDavis)  sin la observación 12." width="960" />
<p class="caption">
Figura 10.5: Gráficos del diagnóstico de regresión del modelo lineal del Ejemplo <a href="chap-regresion.html#exm:exempDavis">10.1</a> sin la observación 12.
</p>
</div>
<p>Para este modelo los gráficos son mucho más interpretables. El primer gráfico muestra que la linealidad del modelo es razonable, aunque es cierto que existen pequeñas desviaciones respecto a una línea horizontal. El segundo gráfico claramente demuestra que los residuos no siguen una distribución normal. Comprobemos esta hipótesis aplicando el test de Shapiro-Wilk a los residuos del modelo:</p>
<div class="sourceCode" id="cb1239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1239-1"><a href="chap-regresion.html#cb1239-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">lm</span>(peso<span class="sc">~</span>pesonotif,<span class="at">subset=</span><span class="sc">-</span><span class="dv">12</span>,<span class="at">data=</span>datospeso)<span class="sc">$</span>residuals)</span></code></pre></div>
<pre><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  lm(peso ~ pesonotif, subset = -12, data = datospeso)$residuals
## W = 0.98104, p-value = 0.01416</code></pre>
<p>Podemos rechazar con un nivel de significación del 5% que los residuos siguen una distribución normal. Por otra parte, el tercer gráfico nos indica que el modelo presenta heterocedasticidad al haber regiones considerables sin puntos y con una curva roja claramente no horizontal. Finalmente, no hay ninguna observación influyente en base al cuarto gráfico. En conclusión, parece ser que fallan dos hipótesis imprescindibles para realizar cualquier inferencia o estimación con este modelo lineal: la normalidad y la homocedasticidad de los residuos.</p>
<p>A continuación, analicemos los gráficos generados en el diagnóstico de regresión del modelo obtenido por la función <code>regsubsets</code> en la Sección <a href="chap-regresion.html#sec:seleccion">10.3</a> para los datos del Ejemplo <a href="chap-regresion.html#exm:exempUSA">10.2</a>.</p>
<div class="sourceCode" id="cb1241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1241-1"><a href="chap-regresion.html#cb1241-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1241-2"><a href="chap-regresion.html#cb1241-2" aria-hidden="true" tabindex="-1"></a>modelo_obama<span class="ot">=</span><span class="fu">lm</span>(obama<span class="sc">~</span>mujeres<span class="sc">+</span>grad_univ<span class="sc">+</span>asia<span class="sc">+</span>evangelicos<span class="sc">+</span>protestantes<span class="sc">+</span>mormones<span class="sc">+</span>paro,</span>
<span id="cb1241-3"><a href="chap-regresion.html#cb1241-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>USA2)</span>
<span id="cb1241-4"><a href="chap-regresion.html#cb1241-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_obama)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-615"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-615-1.png" alt="Gráficos del diagnóstico de regresión del modelo lineal obtenido con la función `regsubsets` a partir de los datos del Ejemplo \@ref(exm:exempUSA)." width="960" />
<p class="caption">
Figura 10.6: Gráficos del diagnóstico de regresión del modelo lineal obtenido con la función <code>regsubsets</code> a partir de los datos del Ejemplo <a href="chap-regresion.html#exm:exempUSA">10.2</a>.
</p>
</div>
<p>El primer gráfico no aporta pruebas muy evidentes de que el modelo no es lineal. Cuando puedan surgir dudas, para los modelos de regresión lineal múltiple, se puede utilizar la función <code>crPlots</code> del paquete <strong>car</strong>. Esta función, que se aplica a un modelo lineal, representa los gráficos de residuos parciales útiles para detectar la no linealidad en un modelo de regresión. Se definen los residuos parciales <span class="math inline">\(e_{ij}\)</span> para una variable independiente <span class="math inline">\(x_j\)</span> como
<span class="math display">\[
e_{ij}=e_i+b_jx_{ij}.
\]</span>
Los residuos parciales se dibujan contra los valores de <span class="math inline">\(x_j\)</span> y se calcula su recta de regresión lineal simple, representada en azul en el gráfico. Además, se realiza una recta de regresión no paramétrica suave (las variables independientes no están predeterminadas y se construyen con los datos), representada en color morado. Si estas curvas divergen considerablemente en alguna de las variables independientes, no se cumple la linealidad del modelo. En nuestro caso coinciden en general y podemos suponer que el modelo sí es lineal:</p>
<div class="sourceCode" id="cb1242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1242-1"><a href="chap-regresion.html#cb1242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">crPlots</span>(modelo_obama)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-617"></span>
<img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-617-1.png" alt="Gráficos de residuos parciales del modelo lineal obtenido con la función `regsubsets` a partir de los datos del Ejemplo \@ref(exm:exempUSA)." width="960" />
<p class="caption">
Figura 10.7: Gráficos de residuos parciales del modelo lineal obtenido con la función <code>regsubsets</code> a partir de los datos del Ejemplo <a href="chap-regresion.html#exm:exempUSA">10.2</a>.
</p>
</div>
<p>El Q-Q-plot parece indicar normalidad de los residuos. Lo comprobamos con el test de Shapiro-Wilk:</p>
<div class="sourceCode" id="cb1243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1243-1"><a href="chap-regresion.html#cb1243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(modelo_obama<span class="sc">$</span>residuals)</span></code></pre></div>
<pre><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  modelo_obama$residuals
## W = 0.96359, p-value = 0.1187</code></pre>
<p>Sin embargo, parece que nuevamente el modelo presenta heterocedasticidad. También se aprecia la existencia de una observación influyente, la observación 12. Esta observación corresponde al estado de Hawaii, que además de ser el único estado no continental de Estados Unidos, tiene un porcentaje de población de origen asiático mucho más elevado que el resto de estados.</p>
</div>
<div id="guía-rápida" class="section level2" number="10.5">
<h2><span class="header-section-number">10.5</span> Guía rápida</h2>
<ul>
<li><p><code>lm(fórmula)</code> realiza la regresión lineal de la variable dependiente en la parte izquierda de la <code>fórmula</code> respecto de las variables independientes indicadas a la derecha de la misma. El parámetro opcional <code>data</code> sirve para indicar el <em>data frame</em> del que se extraen las variables de la <code>fórmula</code> y el parámetro opcional <code>subset</code> sirve para indicar el subconjunto de filas del <em>data frame</em> que se ha de usar como muestra. Su salida es una <code>list</code> y sus dos componentes más interesantes son:</p>
<ul>
<li><code>coefficients</code>: los coeficientes de la función de regresión lineal.</li>
<li><code>residuals</code>: los errores o residuos.</li>
<li><code>fitted.values</code>: los valores estimados de la variable dependiente en los puntos de la muestra.</li>
</ul></li>
<li><p><code>summary(lm(...))</code> muestra la información calculada con la función <code>lm</code>. Las componentes más interesantes de su salida son las siguientes:</p>
<ul>
<li><code>r.squared</code>: el coeficiente de determinación <span class="math inline">\(R^2\)</span>.</li>
<li><code>adj.r.squared</code>: el coeficiente de determinación ajustado <span class="math inline">\(R^2_{adj}\)</span>.</li>
<li><code>coefficients[,1]</code>: los coeficientes de la función de regresión lineal.</li>
<li><code>coefficients[,4]</code>: los p-valores de los contrastes bilaterales de nulidad para dichos coeficientes.</li>
<li><code>sigma</code>: la estimación de la desviación típica común de los residuos.</li>
<li><code>p.value</code>: el p-valor del ANOVA asociado a la regresión lineal realizada.</li>
</ul></li>
<li><p><code>update</code> permite recalcular una función de regresión lineal modificando la fórmula que describe su modelo (con el parámetro <code>formula.</code>) o reduciendo la muestra usada (con el parámetro <code>subset</code>).</p></li>
<li><p><code>confint</code> calcula los intervalos de confianza de los coeficientes de una función de regresión lineal. Se aplica a una salida de la función <code>lm</code> y admite además los parámetros <code>parm</code>, para especificar de qué coeficientes se piden los intervalos de confianza (por defecto, de todos) y <code>level</code> para indicar el nivel de confianza (por defecto, del 95%).</p></li>
<li><p><code>predict</code> calcula intervalos de confianza de predicciones usando una función de regresión lineal. Se aplica a una salida de la función <code>lm</code> y a los parámetros siguientes:</p>
<ul>
<li><p><code>newdata</code>: un <em>data frame</em> cuyas filas dan los valores de las variables independientes de los puntos sobre los que queremos calcular los intervalos de confianza.</p></li>
<li><p><code>ìnterval</code>: indica de qué queremos calcular los intervalos de confianza. Admite 3 posibles valores: <code>none</code>, con el que no calcula intervalos de confianza, solo predicciones de valores; <code>confidence</code>, con el que calcula intervalos de confianza de valores esperados; y <code>prediction</code>, con el que calcula intervalos de confianza de valores predichos.</p></li>
<li><p><code>level</code>, como siempre, indica el nivel de confianza y su valor por defecto es 95%.</p></li>
</ul></li>
<li><p><code>extractAIC(...)[2]</code> calcula la medida AIC (por defecto) o BIC (entrando el parámetro <code>k=log(n)</code>) de un modelo de regresión lineal.</p></li>
<li><p><code>step</code> prueba de manera iterativa una serie de modelos de regresión lineal obtenidos añadiendo o quitando variables independientes al que se le entra y da el mejor modelo de los que considera (por defecto, el de menor valor de AIC). Sus parámetros principales son:</p>
<ul>
<li><p><code>direction</code>: indica la metodología que ha de utilizar R para generar los nuevos modelos a evaluar en la siguiente iteración. Sus valores posibles son: <code>"backward"</code>, que indica que en cada iteración se evalúan y comparan el modelo obtenido en la iteración anterior y todos los modelos obtenidos a partir de él eliminando una de sus variables independientes; <code>"forward"</code>, que indica que en cada iteración se evalúan y comparan el modelo obtenido en la iteración anterior y todos los modelos obtenidos a partir de él añadiendole una nueva variable independiente; y <code>"both"</code>, que indica que en cada iteración se prueban la unión de todos lo modelos que usarían las dos opciones anteriores.</p></li>
<li><p><code>scope</code>: define el rango de modelos que se van a considerar.</p></li>
<li><p><code>k</code>: tiene el mismo significado que en la función <code>extractAIC</code>.</p></li>
<li><p><code>trace</code>: igualado a <code>FALSE</code>, no da en consola información de las iteraciones, solo el modelo obtenido al final.</p></li>
</ul></li>
<li><p><code>regsubsets</code> del paquete <strong>leaps</strong> prueba de manera sistemática todos los modelos de regresión lineal con un número máximo de variables independientes y da para cada uno número de variables considerado los mejores modelos según el criterio BIC. Se aplica a una salida de la función <code>lm</code> y a los dos parámetros siguientes:</p>
<ul>
<li><p><code>nvmax</code>: indica el número máximo de variables independientes que queremos que se consideren.</p></li>
<li><p><code>nbest</code>: indica la cantidad de modelos que ha de mostrar para cada número de variables independientes considerado, por defecto 1.</p></li>
</ul></li>
<li><p><code>plot(regsubsets(...))</code> del paquete <strong>leaps</strong> representa gráficamente de manera adecuada el resultado de una aplicación de la función <code>regsubsets</code>.</p></li>
<li><p><code>plot(lm(...))</code> produce los gráficos <em>Residuals vs Fitted</em>, <em>Normal Q-Q</em>, <em>Scale-Location</em> y <em>Residuals vs Leverage</em> que permiten realizar el diagnóstico del modelo lineal calculado con la función <code>lm</code>.</p></li>
<li><p><code>crPlots(lm(...))</code> genera el gráfico de residuos parciales del modelo lineal calculado con la función <code>lm</code>.</p></li>
<li><p><code>kable</code> del paquete <strong>knitr</strong> produce tablas y <em>data frames</em> bien formateados al compilar el fichero <em>R Markdown</em>.</p></li>
<li><p><code>na.omit</code> aplicado a un <em>data frame</em> elimina las filas que contienen algún valor NA.</p></li>
</ul>
</div>
<div id="ejercicios" class="section level2" number="10.6">
<h2><span class="header-section-number">10.6</span> Ejercicios</h2>
<div id="test" class="section level3 unnumbered">
<h3>Test</h3>
<p><em>(1)</em> El <em>data frame</em> <code>BostonHousing</code> del paquete <strong>mlBench</strong> contiene información de propiedades inmobiliarias de la ciudad de Boston en el año 1970. Cada propiedad está caracterizada por 13 variables que indican las características de la misma, así como por la variable <code>medv</code> que representa una estimación del valor de la propiedad en miles de dólares. Realizad una regresión lineal múltiple de la variable <code>medv</code> en función del resto de variables excepto las variables <code>chas</code> y <code>rad</code>. Tenéis que dar el coeficiente de la variable <code>crim</code> en la ecuación lineal encontrada redondeado a 4 cifras decimales sin ceros innecesarios a la derecha y decir si podéis rechazar (con un SI) o no (con un NO), con un nivel de significación del 5%, que el coeficiente de esta variable sea 0. Dad el coeficiente y la conclusión en este orden, separados por un único espacio en blanco.</p>
<p><em>(2)</em> El <em>data frame</em> <code>BostonHousing</code> del paquete <strong>mlBench</strong> contiene información de propiedades inmobiliarias de la ciudad de Boston en el año 1970. Cada propiedad está caracterizada por 13 variables que indican las características de la misma, así como por la variable <code>medv</code> que representa una estimación del valor de la propiedad en miles de dólares. Sin tener en cuenta las variables <code>chas</code> y <code>rad</code>, encontrad el mejor modelo lineal con exactamente 3 variables independientes en base al valor de la medida BIC y calculad el valor de <span class="math inline">\(R^2_{adj}\)</span> del mismo. Además, tenéis que decir si la variable <code>ptratio</code> se usa (con un SI) o no (con un NO) en el modelo. Dad el valor de <span class="math inline">\(R^2_{adj}\)</span> redondeado a 4 cifras decimales sin ceros innecesarios a la derecha y la respuesta a la pregunta planteada en este orden, separados por un único espacio en blanco.</p>
<p><em>(3)</em> El <em>data frame</em> <code>abalone</code>, disponible en el paquete <strong>AppliedPredictiveModeling</strong>, contiene información de 4177 abulones (también conocidos como orejas de mar). Dispone de la variable <code>Type</code> de tipo factor que diferencia entre especímenes machos (M), hembras (F) y jóvenes (I) y el resto son variables numéricas. Teniendo en cuenta sólo los especímenes hembra, encontrad el modelo lineal que explica la variable <code>Rings</code> en función del resto de variables numéricas y determinad si los residuos son normales (con un SI) o no (con un NO) con un nivel de significación del 5% utilizando el test de Shapiro-Wilk. Determinad también las observaciones que pueden influyentes en el modelo, entendidas como aquéllas con distancia de Cook mayor que 0.5. Dad el p-valor del contraste de normalidad redondeado a 4 cifras decimales sin ceros innecesarios a la derecha, la conclusión del contraste y las observaciones influyentes en orden creciente, separados por un único espacio en blanco. En el caso que no haya observaciones influyentes, contestad NO.</p>
<p><em>(4)</em> El <em>data frame</em> <code>abalone</code>, disponible en el paquete <strong>AppliedPredictiveModeling</strong>, contiene información de 4177 abulones (también conocidos como orejas de mar). Dispone de la variable <code>Type</code> de tipo factor que diferencia entre especímenes machos (M), hembras (F) y jóvenes (I). Encontrad el mejor modelo lineal que explica la variable <code>Rings</code> mediante la función <code>step</code> partiendo del modelo completo con todas las variables numéricas con parámetro <code>direction="backward"</code>. A partir de este modelo, dad en este orden los intervalos de confianza para el valor estimado y para el valor esperado de <code>Rings</code> de una oreja de mar con las siguientes características: <code>LongestShell</code>=0.44, <code>Diameter</code>=0.45, <code>Height</code>=0.15, <code>WholeWeight</code>=0.8, <code>ShuckedWeight</code>=0.36, <code>VisceraWeight</code>=0.2, <code>ShellWeight</code>=0.4. Dad en primer lugar el extremo izquierdo y a continuación el extremo derecho del intervalo para el valor predicho y a continuación, de forma análoga para el valor esperado, todos los valores sucesivos separados por un único espacio en blanco y redondeados a tres decimales sin ceros innecesarios a la derecha.</p>
</div>
<div id="respuestas-al-test" class="section level3 unnumbered">
<h3>Respuestas al test</h3>
<p><em>(1)</em> -0.0701 SI</p>
<p>Nosotros lo hemos resuelto mediante</p>
<div class="sourceCode" id="cb1245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1245-1"><a href="chap-regresion.html#cb1245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb1245-2"><a href="chap-regresion.html#cb1245-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BostonHousing)  <span class="co">#Cargamos la tabla de datos</span></span>
<span id="cb1245-3"><a href="chap-regresion.html#cb1245-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(BostonHousing)   <span class="co">#Consultamos la tabla de datos</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:	506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : num  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ b      : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
<div class="sourceCode" id="cb1247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1247-1"><a href="chap-regresion.html#cb1247-1" aria-hidden="true" tabindex="-1"></a>boston<span class="ot">=</span>BostonHousing[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">9</span>)] <span class="co">#Eliminamos las variables chas y rad </span></span>
<span id="cb1247-2"><a href="chap-regresion.html#cb1247-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(medv<span class="sc">~</span>.,<span class="at">data=</span>boston))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.3315  -2.8771  -0.6792   1.6858  27.4744 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.970e+01  5.051e+00   5.879 7.59e-09 ***
## crim        -7.010e-02  3.269e-02  -2.144 0.032482 *  
## zn           3.989e-02  1.409e-02   2.831 0.004835 ** 
## indus       -4.198e-02  6.080e-02  -0.691 0.490195    
## nox         -1.458e+01  3.899e+00  -3.740 0.000206 ***
## rm           4.188e+00  4.255e-01   9.843  &lt; 2e-16 ***
## age         -1.868e-03  1.359e-02  -0.137 0.890696    
## dis         -1.503e+00  2.059e-01  -7.301 1.15e-12 ***
## tax          8.334e-04  2.386e-03   0.349 0.727038    
## ptratio     -8.738e-01  1.323e-01  -6.607 1.02e-10 ***
## b            8.843e-03  2.763e-03   3.200 0.001461 ** 
## lstat       -5.267e-01  5.224e-02 -10.083  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.899 on 494 degrees of freedom
## Multiple R-squared:  0.7225,	Adjusted R-squared:  0.7163 
## F-statistic: 116.9 on 11 and 494 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>(2)</em> 0.6767 SI</p>
<p>Nosotros lo hemos resuelto mediante</p>
<div class="sourceCode" id="cb1249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1249-1"><a href="chap-regresion.html#cb1249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">regsubsets</span>(medv<span class="sc">~</span>.,<span class="at">data=</span>boston,<span class="at">nbest=</span><span class="dv">1</span>,<span class="at">nvmax=</span><span class="dv">3</span>)) </span></code></pre></div>
<p><img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-621-1.png" width="480" style="display: block; margin: auto;" />
La fila con tres variables independientes es la superior y vemos que involucra las variables <code>rm</code>, <code>ptratio</code> y <code>lstat</code>. Ahora realizamos la regresión lineal correspondiente y calculamos el valor de <span class="math inline">\(R^2_{adj}\)</span>:</p>
<div class="sourceCode" id="cb1250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1250-1"><a href="chap-regresion.html#cb1250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">summary</span>(<span class="fu">lm</span>(medv<span class="sc">~</span>rm<span class="sc">+</span>ptratio<span class="sc">+</span>lstat,<span class="at">data=</span>boston))<span class="sc">$</span>adj.r.squared,<span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.6767</code></pre>
<p><em>(3)</em> 0 NO 2052</p>
<p>Nosotros lo hemos resuelto mediante</p>
<div class="sourceCode" id="cb1252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1252-1"><a href="chap-regresion.html#cb1252-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling)</span>
<span id="cb1252-2"><a href="chap-regresion.html#cb1252-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(abalone) <span class="co">#Cargamos la tabla de datos</span></span>
<span id="cb1252-3"><a href="chap-regresion.html#cb1252-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(abalone) <span class="co">#Consultamos la tabla de datos</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:	4177 obs. of  9 variables:
##  $ Type         : Factor w/ 3 levels &quot;F&quot;,&quot;I&quot;,&quot;M&quot;: 3 3 1 3 2 2 1 1 3 1 ...
##  $ LongestShell : num  0.455 0.35 0.53 0.44 0.33 0.425 0.53 0.545 0.475 0.55 ...
##  $ Diameter     : num  0.365 0.265 0.42 0.365 0.255 0.3 0.415 0.425 0.37 0.44 ...
##  $ Height       : num  0.095 0.09 0.135 0.125 0.08 0.095 0.15 0.125 0.125 0.15 ...
##  $ WholeWeight  : num  0.514 0.226 0.677 0.516 0.205 ...
##  $ ShuckedWeight: num  0.2245 0.0995 0.2565 0.2155 0.0895 ...
##  $ VisceraWeight: num  0.101 0.0485 0.1415 0.114 0.0395 ...
##  $ ShellWeight  : num  0.15 0.07 0.21 0.155 0.055 0.12 0.33 0.26 0.165 0.32 ...
##  $ Rings        : int  15 7 9 10 7 8 20 16 9 19 ...</code></pre>
<div class="sourceCode" id="cb1254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1254-1"><a href="chap-regresion.html#cb1254-1" aria-hidden="true" tabindex="-1"></a>abaloneF<span class="ot">=</span>abalone[abalone<span class="sc">$</span>Type<span class="sc">==</span><span class="st">&quot;F&quot;</span>,<span class="sc">-</span><span class="dv">1</span>] <span class="co"># Nos quedamos con las hembras y eliminamos el factor Type</span></span>
<span id="cb1254-2"><a href="chap-regresion.html#cb1254-2" aria-hidden="true" tabindex="-1"></a>modelo<span class="ot">=</span><span class="fu">lm</span>(Rings<span class="sc">~</span>.,<span class="at">data=</span>abaloneF) <span class="co">#Calculamos la regresión lineal</span></span>
<span id="cb1254-3"><a href="chap-regresion.html#cb1254-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">shapiro.test</span>(modelo<span class="sc">$</span>residuals)<span class="sc">$</span>p.value,<span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb1256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1256-1"><a href="chap-regresion.html#cb1256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1256-2"><a href="chap-regresion.html#cb1256-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo)</span>
<span id="cb1256-3"><a href="chap-regresion.html#cb1256-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="AprendeR-Parte-II_files/figure-html/unnamed-chunk-623-1.png" width="960" style="display: block; margin: auto;" />
Vemos la única observación influyente es la 2052.</p>
<p><em>(4)</em> 7.096 15.83 11.053 11.873</p>
<p>Nosotros lo hemos resuelto mediante</p>
<div class="sourceCode" id="cb1257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1257-1"><a href="chap-regresion.html#cb1257-1" aria-hidden="true" tabindex="-1"></a>abalone2<span class="ot">=</span>abalone[,<span class="sc">-</span><span class="dv">1</span>] <span class="co">#Eliminamos el factor Type</span></span>
<span id="cb1257-2"><a href="chap-regresion.html#cb1257-2" aria-hidden="true" tabindex="-1"></a>modelo_completo<span class="ot">=</span><span class="fu">lm</span>(Rings<span class="sc">~</span>.,<span class="at">data=</span>abalone2) <span class="co">#Calculamos la regresión lineal</span></span>
<span id="cb1257-3"><a href="chap-regresion.html#cb1257-3" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(modelo_completo,<span class="at">direction=</span><span class="st">&quot;backward&quot;</span>,<span class="at">trace=</span><span class="cn">FALSE</span>) <span class="co">#Realizamos el step pedido</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Rings ~ Diameter + Height + WholeWeight + ShuckedWeight + 
##     VisceraWeight + ShellWeight, data = abalone2)
## 
## Coefficients:
##   (Intercept)       Diameter         Height    WholeWeight  ShuckedWeight  
##         2.896         11.634         11.790          9.256        -20.271  
## VisceraWeight    ShellWeight  
##        -9.931          8.606</code></pre>
<div class="sourceCode" id="cb1259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1259-1"><a href="chap-regresion.html#cb1259-1" aria-hidden="true" tabindex="-1"></a>modelo_step<span class="ot">=</span><span class="fu">update</span>(modelo_completo,.<span class="sc">~</span>.<span class="sc">-</span>LongestShell) <span class="co">#Modificamos la regresión lineal</span></span>
<span id="cb1259-2"><a href="chap-regresion.html#cb1259-2" aria-hidden="true" tabindex="-1"></a>datos<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">LongestShell=</span><span class="fl">0.44</span>,<span class="at">Diameter=</span><span class="fl">0.45</span>,<span class="at">Height=</span><span class="fl">0.15</span>,<span class="at">WholeWeight=</span><span class="fl">0.8</span>,</span>
<span id="cb1259-3"><a href="chap-regresion.html#cb1259-3" aria-hidden="true" tabindex="-1"></a><span class="at">ShuckedWeight=</span><span class="fl">0.36</span>,<span class="at">VisceraWeight=</span><span class="fl">0.2</span>,<span class="at">ShellWeight=</span><span class="fl">0.4</span>) <span class="co">#Nuevo individuo</span></span>
<span id="cb1259-4"><a href="chap-regresion.html#cb1259-4" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(modelo_step,datos,<span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>),<span class="dv">3</span>) <span class="co">#Intervalo de confianza del valor predicho</span></span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">fit</th>
<th align="right">lwr</th>
<th align="right">upr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">11.463</td>
<td align="right">7.096</td>
<td align="right">15.83</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1260-1"><a href="chap-regresion.html#cb1260-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(modelo_step,datos,<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>),<span class="dv">3</span>) <span class="co">#Intervalo de confianza del valor esperado</span></span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">fit</th>
<th align="right">lwr</th>
<th align="right">upr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">11.463</td>
<td align="right">11.053</td>
<td align="right">11.873</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>Véase C. Davis. “Body image and weight preocuppation: A comparison between exercising and non-exercising women.” <em>Appetite</em> 15 (1990), pp. 13-21.<a href="chap-regresion.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-ANOVA.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
